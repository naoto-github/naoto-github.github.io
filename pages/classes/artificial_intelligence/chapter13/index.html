<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    強化学習・山登りゲーム | MLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="MLAB" />

  
  <link href="https://fonts.googleapis.com/css?family=M+PLUS+Rounded+1c:500&amp;subset=japanese" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">

  
  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v6.0"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  <meta property="og:title" content="強化学習・山登りゲーム" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/artificial_intelligence/chapter13/" />



  <meta property="og:image" content="https://i.gyazo.com/6357d8a28d99610207123448f3eb799a.png" />



  <meta property="og:site_name" content="MLAB" />



  <meta property="og:description" content="ノートブックの作成  Jupyter Notebook を起動し，新規にノートブックを作成してください． ノートブックのタイトルは AI-3 とします． ノートブックの作成方法は第1回の資料を参照してください．
 山登りゲーム（MountainCar）  山登りゲームは，車両を山の上の旗がある場所まで移動させることが目的です（旗の位置は0.5）． ユーザは，下記の状態を観測することが出来ます．
 車両の位置（-1.2 〜 0.6） 車両の速度（-0.07 〜 0.07）  また，ユーザは，車両に対し，下記のいずれかの行動をとることが出来ます．
 後方に加速（0） 加速なし（1） 前方に加速（2）  下記の条件を満たしたとき，ゲームは失敗となります．
 旗に到達できず200ステップが経過する  今回は，この山登りゲームをQ学習で解いてみましょう． 基本的には前回のバランスゲームの実装方法と同じです．
[学習前] 
[学習後] 
 山登りゲームの実装  まずは必要なライブラリの導入と，山登りゲーム（MountainCar-v0）の初期化をします．
import gym import numpy as np env = gym.make(&#39;MountainCar-v0&#39;) # 環境の初期化 次に，200ステップに限定して，ランダムな行動選択を行なった結果を確認しましょう． 車両は谷底をウロウロするだけで，山を登ることはありません．
env.reset() # 環境のリセット for i in range(200): action = env.action_space.sample() # ランダムに行動選択 observation, reward, done, info = env." />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="強化学習・山登りゲーム" />



  <meta name="twitter:description" content="ノートブックの作成  Jupyter Notebook を起動し，新規にノートブックを作成してください． ノートブックのタイトルは AI-3 とします． ノートブックの作成方法は第1回の資料を参照してください．
 山登りゲーム（MountainCar）  山登りゲームは，車両を山の上の旗がある場所まで移動させることが目的です（旗の位置は0.5）． ユーザは，下記の状態を観測することが出来ます．
 車両の位置（-1.2 〜 0.6） 車両の速度（-0.07 〜 0.07）  また，ユーザは，車両に対し，下記のいずれかの行動をとることが出来ます．
 後方に加速（0） 加速なし（1） 前方に加速（2）  下記の条件を満たしたとき，ゲームは失敗となります．
 旗に到達できず200ステップが経過する  今回は，この山登りゲームをQ学習で解いてみましょう． 基本的には前回のバランスゲームの実装方法と同じです．
[学習前] 
[学習後] 
 山登りゲームの実装  まずは必要なライブラリの導入と，山登りゲーム（MountainCar-v0）の初期化をします．
import gym import numpy as np env = gym.make(&#39;MountainCar-v0&#39;) # 環境の初期化 次に，200ステップに限定して，ランダムな行動選択を行なった結果を確認しましょう． 車両は谷底をウロウロするだけで，山を登ることはありません．
env.reset() # 環境のリセット for i in range(200): action = env.action_space.sample() # ランダムに行動選択 observation, reward, done, info = env." />



  <meta name="twitter:image" content="https://i.gyazo.com/6357d8a28d99610207123448f3eb799a.png" />



</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    <p class="nav-info">Mukai's Lab. at Sugiyama Women's University</p>    
    <a href="/">
    <h2 class="nav-title">
	     <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
	     <span>MLAB</span>
        

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/pages/classes/">授業資料</a>
  </li>
  
  
  
  <li>
    <a href="/pages/tech/">技術メモ</a>
  </li>
  
  
  <li>	
    <a href="https://sites.google.com/g.sugiyama-u.ac.jp/mlab?pli=1&authuser=1" target="_blank">学内専用</a>
  </li>  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    <div class="post-info">
  <span>written by</span>
  Naoto Mukai
  
  
  
  <span>on&nbsp;</span><time datetime="2020-03-12 18:47:35 &#43;0900 JST">March 12, 2020</time>
</div>

    <h1 class="post-title">強化学習・山登りゲーム</h1>
<div class="post-line"></div>

    

    <p><a href="https://gyazo.com/6357d8a28d99610207123448f3eb799a"><img src="https://i.gyazo.com/6357d8a28d99610207123448f3eb799a.png" alt="Image from Gyazo"></a></p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  ノートブックの作成
</h1>

<p><strong>Jupyter Notebook</strong> を起動し，新規にノートブックを作成してください．
ノートブックのタイトルは <strong>AI-3</strong> とします．
ノートブックの作成方法は<a href="https://mukai-lab.info/pages/classes/artificial_intelligence/chapter1/">第1回の資料</a>を参照してください．</p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  山登りゲーム（MountainCar）
</h1>

<p>山登りゲームは，車両を山の上の旗がある場所まで移動させることが目的です（旗の位置は0.5）．
ユーザは，下記の状態を観測することが出来ます．</p>
<ul>
<li>車両の位置（-1.2 〜 0.6）</li>
<li>車両の速度（-0.07 〜 0.07）</li>
</ul>
<p>また，ユーザは，車両に対し，下記のいずれかの行動をとることが出来ます．</p>
<ul>
<li>後方に加速（0）</li>
<li>加速なし（1）</li>
<li>前方に加速（2）</li>
</ul>
<p>下記の条件を満たしたとき，ゲームは失敗となります．</p>
<ul>
<li>旗に到達できず200ステップが経過する</li>
</ul>
<p>今回は，この山登りゲームをQ学習で解いてみましょう．
基本的には前回のバランスゲームの実装方法と同じです．</p>
<p><strong>[学習前]</strong>
<a href="https://gyazo.com/32d02f4759157860ece14f06590baefd"><img src="https://i.gyazo.com/32d02f4759157860ece14f06590baefd.gif" alt="Image from Gyazo"></a></p>
<p><strong>[学習後]</strong>
<a href="https://gyazo.com/960bd92b1c260d91c5ced82ccf7e7ca8"><img src="https://i.gyazo.com/960bd92b1c260d91c5ced82ccf7e7ca8.gif" alt="Image from Gyazo"></a></p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  山登りゲームの実装
</h1>

<p>まずは必要なライブラリの導入と，山登りゲーム（MountainCar-v0）の初期化をします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> gym
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np

env <span style="color:#f92672">=</span> gym<span style="color:#f92672">.</span>make(<span style="color:#e6db74">&#39;MountainCar-v0&#39;</span>) <span style="color:#75715e"># 環境の初期化</span>
</code></pre></div><p>次に，200ステップに限定して，ランダムな行動選択を行なった結果を確認しましょう．
車両は谷底をウロウロするだけで，山を登ることはありません．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">env<span style="color:#f92672">.</span>reset() <span style="color:#75715e"># 環境のリセット</span>

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">200</span>):
    action <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>action_space<span style="color:#f92672">.</span>sample() <span style="color:#75715e"># ランダムに行動選択</span>
    observation, reward, done, info <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>step(action)
    
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Step {}&#34;</span><span style="color:#f92672">.</span>format(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;状態: {}&#34;</span><span style="color:#f92672">.</span>format(observation))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;終了判定: {}&#34;</span><span style="color:#f92672">.</span>format(done))
    
    env<span style="color:#f92672">.</span>render() <span style="color:#75715e"># 環境の描画</span>
</code></pre></div><p><a href="https://gyazo.com/dd845bdbbdd2136f120f023868e1b4ad"><img src="https://i.gyazo.com/dd845bdbbdd2136f120f023868e1b4ad.gif" alt="Image from Gyazo"></a></p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  Q学習の実装
</h1>

<h3 id="qテーブルの作成">Qテーブルの作成</h3>
<p>最初に <strong>価値$Q(s,a)$</strong> を記録しておくQテーブル（辞書型）を作成します．
前回のバランスゲームと全く同じです．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">q_table <span style="color:#f92672">=</span> {} <span style="color:#75715e"># Qテーブル</span>

<span style="color:#75715e"># Q値の設定</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">setQ</span>(state, action, value):
    q_table[(state, action)] <span style="color:#f92672">=</span> value
                     
<span style="color:#75715e"># Q値の取得</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getQ</span>(state, action):

    <span style="color:#75715e"># テーブルに状態が存在しないとき</span>
    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span>(state, action) <span style="color:#f92672">in</span> q_table:
        q_table[(state, action)] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>

    <span style="color:#66d9ef">return</span> q_table[(state, action)]
</code></pre></div><h3 id="状態の離散化">状態の離散化</h3>
<p>次に状態の離散化を行います．
山登りゲームでは，車両の位置，車両の速度の2つの状態を <strong>連続値</strong> で取得します．
しかし，このままではQテーブルに記録できないため，区間を定め <strong>離散値</strong> に変換します．
バランスゲームでは6区間でしたが，今回は40区間に分割することにします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">BIN_NUMBER <span style="color:#f92672">=</span> <span style="color:#ae81ff">40</span> <span style="color:#75715e"># 離散値の数</span>

<span style="color:#75715e"># 離散値の範囲</span>
bins <span style="color:#f92672">=</span> []
bins<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">1.2</span>, <span style="color:#ae81ff">0.6</span>, BIN_NUMBER)) <span style="color:#75715e"># 車両の位置</span>
bins<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.07</span>, <span style="color:#ae81ff">0.07</span>, BIN_NUMBER)) <span style="color:#75715e"># 車両の速度</span>

<span style="color:#75715e"># 観測データを状態（離散値）に変換</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">digitize</span>(observation):

    state <span style="color:#f92672">=</span> []
    
    state<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>digitize(observation[<span style="color:#ae81ff">0</span>], bins[<span style="color:#ae81ff">0</span>]))
    state<span style="color:#f92672">.</span>append(np<span style="color:#f92672">.</span>digitize(observation[<span style="color:#ae81ff">1</span>], bins[<span style="color:#ae81ff">1</span>]))
    
    <span style="color:#66d9ef">return</span> tuple(state)
</code></pre></div><p>どのように離散値に変換されるか確認してみましょう．
この例では，$(17,20)$ -&gt; $(17,20)$ -&gt; $(17,19)$と状態が変化していることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">env<span style="color:#f92672">.</span>reset() <span style="color:#75715e"># 環境のリセット</span>

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
    action <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>action_space<span style="color:#f92672">.</span>sample() <span style="color:#75715e"># ランダムに行動選択</span>
    observation, reward, done, info <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>step(action)

    <span style="color:#66d9ef">print</span>(observation)
    <span style="color:#66d9ef">print</span>(digitize(observation))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-txt" data-lang="txt">[-4.21336289e-01  2.46770426e-04]
(17, 20)
[-0.42184451 -0.00050822]
(17, 20)
[-0.4241041  -0.00225958]
(17, 19)
</code></pre></div><h3 id="報酬と更新式">報酬と更新式</h3>
<p>報酬を<code>getReward</code>関数で定義します．
200ステップ以内に旗に到達できれば$r=200$を与えます．
一方，旗に到達できない場合は常に$r=-1$のペナルティを与えます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 報酬の取得</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getReward</span>(step, done):

    <span style="color:#66d9ef">if</span> done:
        <span style="color:#66d9ef">if</span> step <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">200</span>:
            reward <span style="color:#f92672">=</span> <span style="color:#ae81ff">200</span> <span style="color:#75715e"># 目標ステップ以内に旗に到達</span>
        <span style="color:#66d9ef">else</span>:
            reward <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        reward <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>

    <span style="color:#66d9ef">return</span> reward
</code></pre></div><p>Qテーブルの更新式を<code>updateQTable</code>関数で定義します．
このとき，学習率$\alpha=0.1$，割引率$\gamma=0.9$とします．
ここで，Qテーブルのキーは状態$s$と行動$a$のペアとなることに注意してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span> <span style="color:#75715e"># 学習率</span>
gamma <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span> <span style="color:#75715e"># 割引率</span>

<span style="color:#75715e"># Q値の更新</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">updateQTable</span>(state, action, next_state, reward):

    max_value <span style="color:#f92672">=</span> max(getQ(next_state, <span style="color:#ae81ff">0</span>), getQ(next_state, <span style="color:#ae81ff">1</span>), getQ(next_state, <span style="color:#ae81ff">2</span>))

    value <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha) <span style="color:#f92672">*</span> getQ(state, action) <span style="color:#f92672">+</span> alpha <span style="color:#f92672">*</span> (reward <span style="color:#f92672">+</span> gamma <span style="color:#f92672">*</span> max_value)

    setQ(state, action, value)
</code></pre></div><h3 id="行動の選択">行動の選択</h3>
<p>行動の選択には前回と同じ$\epsilon$グリーティ手法を採用します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># εグリーディ手法で行動選択</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">greedyAction</span>(state, epsilon):    
    
    <span style="color:#66d9ef">if</span> epsilon <span style="color:#f92672">&gt;</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand():
        action <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>action_space<span style="color:#f92672">.</span>sample()
    <span style="color:#66d9ef">else</span>:
        action <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax([getQ(state, <span style="color:#ae81ff">0</span>), getQ(state, <span style="color:#ae81ff">1</span>), getQ(state, <span style="color:#ae81ff">2</span>)])

    <span style="color:#66d9ef">return</span> action
</code></pre></div><h3 id="qテーブルの学習">Qテーブルの学習</h3>
<p>これで準備が整いました．
200ステップのエピソード（ゲーム）を10000回繰り返してQテーブルを学習します．
このとき，$\epsilon=0.2$に設定しておきましょう．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">env<span style="color:#f92672">.</span>reset() <span style="color:#75715e"># 環境のリセット</span>
q_table <span style="color:#f92672">=</span> {}

<span style="color:#66d9ef">for</span> episode <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10000</span>):

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;エピソード [{}]&#34;</span><span style="color:#f92672">.</span>format(episode))
    
    observation <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>reset()
    
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">200</span>):
        
        <span style="color:#75715e"># 状態の取得</span>
        state <span style="color:#f92672">=</span> digitize(observation)
        
        <span style="color:#75715e"># εグリーディ手法で行動選択</span>
        action <span style="color:#f92672">=</span> greedyAction(state, <span style="color:#ae81ff">0.2</span>)

        <span style="color:#75715e"># 次の状態に遷移</span>
        observation, reward, done, info <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>step(action)

        <span style="color:#75715e"># 次の状態</span>
        next_state <span style="color:#f92672">=</span> digitize(observation)        
        
        <span style="color:#75715e"># 報酬の取得</span>
        reward <span style="color:#f92672">=</span> getReward((i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>), done)

        <span style="color:#75715e"># Q値の更新</span>
        updateQTable(state, action, next_state, reward)

        <span style="color:#66d9ef">if</span> done:
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Step {}&#34;</span><span style="color:#f92672">.</span>format(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>))        
            <span style="color:#66d9ef">break</span>  
</code></pre></div><p>学習したQテーブルを用いて実行しましょう．
このとき，$\epsilon=0$に設定しておきましょう．
うまく学習できていれば200ステップ以内に山を登り旗に到達出来るはずです．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">env<span style="color:#f92672">.</span>reset() <span style="color:#75715e"># 環境のリセット</span>

observation <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>reset()
    
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">200</span>):
        
    <span style="color:#75715e"># 状態の取得</span>
    state <span style="color:#f92672">=</span> digitize(observation)
        
    <span style="color:#75715e"># εグリーディ手法で行動選択</span>
    action <span style="color:#f92672">=</span> greedyAction(state, <span style="color:#ae81ff">0</span>)

    <span style="color:#75715e"># 次の状態に遷移</span>
    observation, reward, done, info <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>step(action)

    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Step {}&#34;</span><span style="color:#f92672">.</span>format(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;状態: {}&#34;</span><span style="color:#f92672">.</span>format(observation))
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;終了判定: {}&#34;</span><span style="color:#f92672">.</span>format(done))
    
    env<span style="color:#f92672">.</span>render() <span style="color:#75715e"># 環境の描画</span>
    
    <span style="color:#66d9ef">if</span> done:
        <span style="color:#66d9ef">break</span>
</code></pre></div><p><a href="https://gyazo.com/57db372642952fe2b9a0bdc5eaeab09a"><img src="https://i.gyazo.com/57db372642952fe2b9a0bdc5eaeab09a.gif" alt="Image from Gyazo"></a></p>
<!-- <h1>
  <img class="head-image" src="/logo/logo.png">
  課題
</h1>
 -->
<!-- より早く車両が旗に到達する工夫を考え実装しなさい． -->
<!-- 作成したノートブックを **HTML(.html)** 形式でダウンロードし提出しなさい． -->

<h3>参考書籍</h3>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=477416013X&linkId=a3e3de6cdd05f8a87e01091a9529a212&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4061538233&linkId=9b22cb2b9a07a725897b3598e4bb4418&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4339023957&linkId=8f5ccc75e9cf345c48d02210a3230069&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=427422371X&linkId=d5436c8655f90c573302f07ed9cb9ddf&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    <div class="horizontal">

  
  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/artificial_intelligence/chapter13/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fmukai-lab.info%2Fwww%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
  
  
  <div style="padding: 6px; margin-top:1px">
    <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-show-count="false">Tweet</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>

  
  
</div>



  </div>

  <div class="pagination">
    <a href="/" class="top" ><span>Top</span></a>
    <a href='javascript:history.back()' class="top" style="margin-left: 30px"><span>Back</span></a>
  </div>

  

  
  

  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; <time datetime="2020-10-22 10:43:09.741786 &#43;0900 JST m=&#43;0.176078888">2020</time> Naoto Mukai. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.</span>
  </div>
</footer>


    </body>
</html>
