<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    強化学習・フローズンレイク | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  <script src="./freetile/jquery.freetile.min.js"></script>  

  
  

  <meta property="og:title" content="強化学習・フローズンレイク" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/artificial_intelligence/chapter13/" />



  <meta property="og:image" content="https://i.gyazo.com/b55214411b1c141e7adcf916743f172f.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="Q学習とは  Q学習 は状態$S$と行動$a$の組み合わせに対する 価値$Q(s,a)$ を学習するためのアルゴリズムです． 下記は，状態$s$で行動$a$を選択し，報酬$r$を獲得したときの更新式です． また，$Q(s&#39;, a&#39;)$は，状態$s$から遷移した先の状態$s&#39;$において，行動$a&#39;$を選択したときの価値を表しています． ここで，$\alpha$は学習率，$\gamma$は割引率と呼ばれるパラメータであり， $0 \leq \alpha \leq 1$，$0 \leq \gamma \leq 1$の範囲で設定します． 学習率は学習の収束に影響し，小さいとゆっくりと学習し，大きいと速く学習します（収束の安定性とトレードオフ）． また，割引率は将来得られるであろう報酬を割り引いて評価するために用います．
$$ Q&#39;(s,a) = (1 - \alpha)Q(s,a) &#43; \alpha(r &#43; \gamma \max_{a&#39; \in A(s&#39;)} Q(s&#39;, a&#39;)) $$
   パラメータ 意味     $s$ 状態   $a$ 行動   $Q(s,a)$ 状態$s$で行動$a$を選択する価値   $r$ 報酬   $A(s)$ 状態$s$で選択可能な行動の集合   $\alpha$ 学習率   $\gamma$ 割引率    ノートブックの作成  Google Colaboratory を起動し，新規にノートブックを作成してください． ノートブックのタイトルは AI-13 とします． ノートブックの作成方法は第1回の資料を参照してください．" />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="強化学習・フローズンレイク" />



  <meta name="twitter:description" content="Q学習とは  Q学習 は状態$S$と行動$a$の組み合わせに対する 価値$Q(s,a)$ を学習するためのアルゴリズムです． 下記は，状態$s$で行動$a$を選択し，報酬$r$を獲得したときの更新式です． また，$Q(s&#39;, a&#39;)$は，状態$s$から遷移した先の状態$s&#39;$において，行動$a&#39;$を選択したときの価値を表しています． ここで，$\alpha$は学習率，$\gamma$は割引率と呼ばれるパラメータであり， $0 \leq \alpha \leq 1$，$0 \leq \gamma \leq 1$の範囲で設定します． 学習率は学習の収束に影響し，小さいとゆっくりと学習し，大きいと速く学習します（収束の安定性とトレードオフ）． また，割引率は将来得られるであろう報酬を割り引いて評価するために用います．
$$ Q&#39;(s,a) = (1 - \alpha)Q(s,a) &#43; \alpha(r &#43; \gamma \max_{a&#39; \in A(s&#39;)} Q(s&#39;, a&#39;)) $$
   パラメータ 意味     $s$ 状態   $a$ 行動   $Q(s,a)$ 状態$s$で行動$a$を選択する価値   $r$ 報酬   $A(s)$ 状態$s$で選択可能な行動の集合   $\alpha$ 学習率   $\gamma$ 割引率    ノートブックの作成  Google Colaboratory を起動し，新規にノートブックを作成してください． ノートブックのタイトルは AI-13 とします． ノートブックの作成方法は第1回の資料を参照してください．" />



  <meta name="twitter:image" content="https://i.gyazo.com/b55214411b1c141e7adcf916743f172f.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
  
  <li>
    <a href="/tech/">Tech</a>
  </li>
  
  
  
  <li>
    <a href="/projects/">Projects</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    
    <h1 class="post-title">強化学習・フローズンレイク</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/b55214411b1c141e7adcf916743f172f"><img src="https://i.gyazo.com/b55214411b1c141e7adcf916743f172f.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  Q学習とは
</h1>

<p><strong>Q学習</strong> は状態$S$と行動$a$の組み合わせに対する <strong>価値$Q(s,a)$</strong> を学習するためのアルゴリズムです．
下記は，状態$s$で行動$a$を選択し，報酬$r$を獲得したときの更新式です．
また，$Q(s', a')$は，状態$s$から遷移した先の状態$s'$において，行動$a'$を選択したときの価値を表しています．
ここで，$\alpha$は学習率，$\gamma$は割引率と呼ばれるパラメータであり，
$0 \leq \alpha \leq 1$，$0 \leq \gamma \leq 1$の範囲で設定します．
学習率は学習の収束に影響し，小さいとゆっくりと学習し，大きいと速く学習します（収束の安定性とトレードオフ）．
また，割引率は将来得られるであろう報酬を割り引いて評価するために用います．</p>
<p>$$
Q'(s,a) = (1 - \alpha)Q(s,a) + \alpha(r + \gamma \max_{a' \in A(s')} Q(s', a'))
$$</p>
<table>
<thead>
<tr>
<th>パラメータ</th>
<th>意味</th>
</tr>
</thead>
<tbody>
<tr>
<td>$s$</td>
<td>状態</td>
</tr>
<tr>
<td>$a$</td>
<td>行動</td>
</tr>
<tr>
<td>$Q(s,a)$</td>
<td>状態$s$で行動$a$を選択する価値</td>
</tr>
<tr>
<td>$r$</td>
<td>報酬</td>
</tr>
<tr>
<td>$A(s)$</td>
<td>状態$s$で選択可能な行動の集合</td>
</tr>
<tr>
<td>$\alpha$</td>
<td>学習率</td>
</tr>
<tr>
<td>$\gamma$</td>
<td>割引率</td>
</tr>
</tbody>
</table>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  ノートブックの作成
</h1>

<p><strong>Google Colaboratory</strong> を起動し，新規にノートブックを作成してください．
ノートブックのタイトルは <strong>AI-13</strong> とします．
ノートブックの作成方法は<a href="https://mukai-lab.info/pages/classes/artificial_intelligence/chapter1/">第1回の資料</a>を参照してください．</p>
<p>最初に<strong>OpenAI Gym</strong> をインストールします．
セルで下記のコマンドを実行してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-txt" data-lang="txt">&gt; !pip install gym
</code></pre></div><p>また，OpenAI Gymに加え，下記のライブラリも導入しておきましょう．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> gym
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> random
<span style="color:#f92672">import</span> time
<span style="color:#f92672">from</span> google.colab <span style="color:#f92672">import</span> output
</code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  フローズンレイク（FrozenLake）
</h1>

<p><a href="https://gym.openai.com/envs/FrozenLake-v0/">フローズンレイク（FrozenLake）</a>をQ学習を利用して解いてみましょう．</p>
<h2 id="環境の初期化">環境の初期化</h2>
<p>前回と同様に対象とする環境を作成します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">env <span style="color:#f92672">=</span> gym<span style="color:#f92672">.</span>make(<span style="color:#e6db74">&#39;FrozenLake-v0&#39;</span>, map_name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;4x4&#34;</span>, is_slippery<span style="color:#f92672">=</span>False)
</code></pre></div><p>また，実行結果の理解を簡単にするために，辞書<code>ACTION</code>，関数<code>toString()</code>も定義します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">ACTION <span style="color:#f92672">=</span> {
  <span style="color:#ae81ff">0</span>: <span style="color:#e6db74">&#34;LEFT&#34;</span>,
  <span style="color:#ae81ff">1</span>: <span style="color:#e6db74">&#34;DOWN&#34;</span>,
  <span style="color:#ae81ff">2</span>: <span style="color:#e6db74">&#34;RIGHT&#34;</span>,
  <span style="color:#ae81ff">3</span>: <span style="color:#e6db74">&#34;UP&#34;</span>
}

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">toString</span>(histories):
  moves <span style="color:#f92672">=</span> []
  <span style="color:#66d9ef">for</span> observation, action <span style="color:#f92672">in</span> histories:
    moves<span style="color:#f92672">.</span>append((observation, ACTION[action]))
  <span style="color:#66d9ef">return</span> moves
</code></pre></div><h2 id="q学習">Q学習</h2>
<h3 id="qテーブル">Qテーブル</h3>
<p>価値$Q(s,a)$を記録するための辞書を作成します．
$s$は$0,1,\cdots,15$の16パターン，
$a$は$0,1,2,3$の4パターンが存在するため，
$16\times4=64$パターンの$Q$を記録する必要があります．
全ての$Q$は<code>0.01</code>で初期化しておきます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">qtable <span style="color:#f92672">=</span> {
    <span style="color:#ae81ff">0</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">1</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">2</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">3</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">4</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">5</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">6</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">7</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">8</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">9</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">10</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">11</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">12</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">13</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">14</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>],
    <span style="color:#ae81ff">15</span>: [<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.01</span>]
}
</code></pre></div><p>$Q$を設定するための関数<code>setQ()</code>と，
$Q$を取得するための関数<code>getQ()</code>を定義しておきます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">setQ</span>(state, action, value):
  qtable[state][action] <span style="color:#f92672">=</span> value

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">getQ</span>(state, action):
  <span style="color:#66d9ef">return</span> qtable[state][action]
</code></pre></div><h3 id="q値の更新">Q値の更新</h3>
<p>$Q$の更新式を表す<code>updateQ()</code>を定義します．
割引率$\alpha$は<code>0.1</code>，割引率$\gamma$は<code>0.9</code>に設定します．
<code>np.max()</code>で最大の$Q$を選択していることに注意してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span> <span style="color:#75715e"># 学習率</span>
gamma <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span> <span style="color:#75715e"># 割引率</span>

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">updateQ</span>(state, action, next_state, reward):
  max_value <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>max([getQ(next_state, <span style="color:#ae81ff">0</span>), getQ(next_state, <span style="color:#ae81ff">1</span>), getQ(next_state, <span style="color:#ae81ff">2</span>), getQ(next_state, <span style="color:#ae81ff">3</span>)])
  value <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha) <span style="color:#f92672">*</span> getQ(state, action) <span style="color:#f92672">+</span> alpha <span style="color:#f92672">*</span> (reward <span style="color:#f92672">+</span> gamma <span style="color:#f92672">*</span> max_value)
  setQ(state, action, value)
</code></pre></div><h3 id="行動戦略">行動戦略</h3>
<p>プレイヤーの行動は$\epsilon$-グリーディ戦略で決定します．
$\epsilon$-グリーディ戦略では，確率$\epsilon$でランダムに行動を選択し，
確率$1-\epsilon$で$Q$が最大となる行動を選択します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">greedyAction</span>(state, epsilon):    

    <span style="color:#66d9ef">if</span> epsilon <span style="color:#f92672">&gt;</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand():
        action <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>choice([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])
    <span style="color:#66d9ef">else</span>:
        action <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax([getQ(state, <span style="color:#ae81ff">0</span>), getQ(state, <span style="color:#ae81ff">1</span>), getQ(state, <span style="color:#ae81ff">2</span>), getQ(state, <span style="color:#ae81ff">3</span>)])

    <span style="color:#66d9ef">return</span> action
</code></pre></div><h3 id="学習プロセス">学習プロセス</h3>
<p>プレイヤーの行動を繰り返すことで$Q$を学習します．
プレイヤーは終了判定が<code>True</code>になるまで，最大100回まで行動を繰り返します．
このプレイヤーの行動を1000回繰り返します．
<code>15(=G)</code>に到達したときに得られる報酬<code>1</code>が伝播し，価値<code>Q(s,a)</code>が設定されます．
また，$\epsilon$は<code>0.2</code>に設定しています．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">epsilon <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>

<span style="color:#66d9ef">for</span> episode <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1000</span>):
  state <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>reset()

  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
    action <span style="color:#f92672">=</span> greedyAction(state, epsilon)
    next_state, reward, done, info <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>step(action)
    updateQ(state, action, next_state, reward)
    state <span style="color:#f92672">=</span> next_state

    <span style="color:#66d9ef">if</span> done:
      <span style="color:#66d9ef">break</span>
</code></pre></div><p>学習した<code>Q</code>を利用してプレイヤーを行動させます．
$\epsilon$を<code>0</code>に設定し，常に$Q$が最大の行動を選択します．
この結果，DOWN，DOWN，RIGHT，DOWN，RIGHT，RIGHTの順に行動し，
<strong>15(=G)</strong> に到達していることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Q値で移動</span>
epsilon <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>

state <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>reset()

histories <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">100</span>):
  action <span style="color:#f92672">=</span> greedyAction(state, epsilon)
  next_state, reward, done, info <span style="color:#f92672">=</span> env<span style="color:#f92672">.</span>step(action)
  histories<span style="color:#f92672">.</span>append((state, action))
  state <span style="color:#f92672">=</span> next_state
  output<span style="color:#f92672">.</span>clear()
  env<span style="color:#f92672">.</span>render()
  time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">1</span>)

  <span style="color:#66d9ef">if</span> done:
    <span style="color:#66d9ef">break</span>

<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;actions={toString(histories)}&#34;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;next_state={next_state}&#34;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;reward={reward}&#34;</span>)
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;done={done}&#34;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">  (Right)
SFFF
FHFH
FFFH
HFFG
actions=[(0, &#39;DOWN&#39;), (4, &#39;DOWN&#39;), (8, &#39;RIGHT&#39;), (9, &#39;DOWN&#39;), (13, &#39;RIGHT&#39;), (14, &#39;RIGHT&#39;)]
next_state=15
reward=1.0
done=True
</code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  完成したノートブックの確認
</h1>

<p><a href="https://colab.research.google.com/drive/1rzuPN_uOO7Bp0b0mFwOAZNNcgi7D75g6?usp=sharing"><i class="fas fa-external-link-alt"></i>ノートブックの確認</a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>

<p><code>map_name</code>を<code>8x8</code>としたときの解を導出しなさい．</p>
<p>Google Colaboratoryで作成した <strong>AI-13.ipynb</strong> を保存し，
<strong>共有用のリンク</strong> と <strong>ノートブック（.ipynb）</strong> をダウンロードして提出しなさい．
提出の前に必ず下記の設定を行うこと．</p>
<ul>
<li>ノートブックの設定で「セルの出力を除外する」のチェックを外す</li>
<li>ノートブックの変更内容を保存して固定</li>
<li>共有設定で「学校法人椙山女学園大学」を「閲覧者」に設定</li>
</ul>

<h3>参考書籍</h3>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=477416013X&linkId=a3e3de6cdd05f8a87e01091a9529a212&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4061538233&linkId=9b22cb2b9a07a725897b3598e4bb4418&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4339023957&linkId=8f5ccc75e9cf345c48d02210a3230069&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=427422371X&linkId=d5436c8655f90c573302f07ed9cb9ddf&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/artificial_intelligence/chapter13/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
