<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    単純パーセプトロン | MLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  
  
  
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="MLAB" />

  
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v6.0"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  <script src="./freetile/jquery.freetile.min.js"></script>  

  
  

  <meta property="og:title" content="単純パーセプトロン" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter2/" />



  <meta property="og:image" content="https://i.gyazo.com/3f226be10ad378ed9019012ad07ced11.png" />



  <meta property="og:site_name" content="MLAB" />



  <meta property="og:description" content="単純パーセプトロン  パーセプトロン とは，動物の神経細胞（ニューロン）の発火現象を数理的に表現したモデルのことです． ウォーレン・マカロック氏とウォルター・ピッツ氏が提案した 形式ニューロン を2層のネットワーク状に接続したものは 単純パーセプトロン と呼ばれます． 単純パーセプトロンの1層目のニューロンは，入力データを伝えるだけの役割であるため，実質的には1つの形式ニューロンと考えることができます．

ここでは，2入力，1出力の単純パーセプトロンを考えます． 下記の式に従って，入力された$x_1$と$x_2$から，中間出力$y$を得ます． ここで，$w_1$と$w_2$は入力に対する 重み です． また，$w_0$は バイアス と呼ばれ，出力の閾値として用いられます．
$$ y = w_1 \times x_1 &#43; w_2 \times x_2 &#43; w_0 $$
この中間出力$y$に対して，活性化関数 $f$と呼ばれる特殊な関数を適用して， 得られた値を最終的なニューロンの出力$z$とします．
$$ z = f(y) $$
一般に$n$入力の単純パーセプトロンは，入力${\bf x}$と重み${\bf w}$は下記のようにベクトルで表現されます． ここで，$x_0=1$はバイアス$w_0$を導入するために用いられます． パーセプトロンが多層になると，ベクトル表現が必須となりますので，慣れておきましょう．
$$ {\bf x} = (1, x_1, \cdots, x_n) \\
{\bf w} = (w_0, w_1, \cdots, w_n) \\
y = {\bf x} \cdot {\bf w} \\" />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="単純パーセプトロン" />



  <meta name="twitter:description" content="単純パーセプトロン  パーセプトロン とは，動物の神経細胞（ニューロン）の発火現象を数理的に表現したモデルのことです． ウォーレン・マカロック氏とウォルター・ピッツ氏が提案した 形式ニューロン を2層のネットワーク状に接続したものは 単純パーセプトロン と呼ばれます． 単純パーセプトロンの1層目のニューロンは，入力データを伝えるだけの役割であるため，実質的には1つの形式ニューロンと考えることができます．

ここでは，2入力，1出力の単純パーセプトロンを考えます． 下記の式に従って，入力された$x_1$と$x_2$から，中間出力$y$を得ます． ここで，$w_1$と$w_2$は入力に対する 重み です． また，$w_0$は バイアス と呼ばれ，出力の閾値として用いられます．
$$ y = w_1 \times x_1 &#43; w_2 \times x_2 &#43; w_0 $$
この中間出力$y$に対して，活性化関数 $f$と呼ばれる特殊な関数を適用して， 得られた値を最終的なニューロンの出力$z$とします．
$$ z = f(y) $$
一般に$n$入力の単純パーセプトロンは，入力${\bf x}$と重み${\bf w}$は下記のようにベクトルで表現されます． ここで，$x_0=1$はバイアス$w_0$を導入するために用いられます． パーセプトロンが多層になると，ベクトル表現が必須となりますので，慣れておきましょう．
$$ {\bf x} = (1, x_1, \cdots, x_n) \\
{\bf w} = (w_0, w_1, \cdots, w_n) \\
y = {\bf x} \cdot {\bf w} \\" />



  <meta name="twitter:image" content="https://i.gyazo.com/3f226be10ad378ed9019012ad07ced11.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>MLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/pages/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
  
  <li>
    <a href="/pages/tech/">Techs</a>
  </li>
  
  
  
  <li>
    <a href="https://sites.google.com/g.sugiyama-u.ac.jp/mlab?pli=1&amp;authuser=1">Members</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    <div class="post-info">
  <span>written by</span>
  Naoto Mukai
  
  
  
  <span>on&nbsp;</span><time datetime="2020-06-26 18:13:38 &#43;0900 JST">June 26, 2020</time>
</div>

    <h1 class="post-title">単純パーセプトロン</h1>
<div class="post-line"></div>

    

    <p><a href="https://gyazo.com/3f226be10ad378ed9019012ad07ced11"><img src="https://i.gyazo.com/3f226be10ad378ed9019012ad07ced11.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  単純パーセプトロン
</h1>

<p><strong>パーセプトロン</strong> とは，動物の神経細胞（ニューロン）の発火現象を数理的に表現したモデルのことです．
ウォーレン・マカロック氏とウォルター・ピッツ氏が提案した
<strong>形式ニューロン</strong> を2層のネットワーク状に接続したものは <strong>単純パーセプトロン</strong> と呼ばれます．
単純パーセプトロンの1層目のニューロンは，入力データを伝えるだけの役割であるため，実質的には1つの形式ニューロンと考えることができます．</p>
<p><a href="https://gyazo.com/f91bcd6ecf9e7f301b49fa3b947bff75"><img src="https://i.gyazo.com/f91bcd6ecf9e7f301b49fa3b947bff75.png" alt="Image from Gyazo"></a></p>
<p>ここでは，2入力，1出力の単純パーセプトロンを考えます．
下記の式に従って，入力された$x_1$と$x_2$から，中間出力$y$を得ます．
ここで，$w_1$と$w_2$は入力に対する <strong>重み</strong> です．
また，$w_0$は <strong>バイアス</strong> と呼ばれ，出力の閾値として用いられます．</p>
<p>$$
y = w_1 \times x_1 + w_2 \times x_2 + w_0
$$</p>
<p>この中間出力$y$に対して，<strong>活性化関数</strong> $f$と呼ばれる特殊な関数を適用して，
得られた値を最終的なニューロンの出力$z$とします．</p>
<p>$$
z = f(y)
$$</p>
<p>一般に$n$入力の単純パーセプトロンは，入力${\bf x}$と重み${\bf w}$は下記のようにベクトルで表現されます．
ここで，$x_0=1$はバイアス$w_0$を導入するために用いられます．
パーセプトロンが多層になると，ベクトル表現が必須となりますので，慣れておきましょう．</p>
<p>$$
{\bf x} = (1, x_1, \cdots, x_n) \\<br>
{\bf w} = (w_0, w_1, \cdots, w_n) \\<br>
y = {\bf x} \cdot {\bf w} \\<br>
z = f(y)
$$</p>
<p>活性化関数$f$には下記のような種類があります．</p>
<ul>
<li>ステップ関数</li>
<li>シグモイド関数</li>
<li>ReLU(Rectified Linear Unit)関数</li>
</ul>
<p>下図はステップ関数のグラフです．
ステップ関数は入力$y$が0以上なら1，0未満であれば0を出力する関数です．</p>
<p><a href="https://gyazo.com/5c370bbf48a57be928ac113e3c6d5c0d"><img src="https://i.gyazo.com/5c370bbf48a57be928ac113e3c6d5c0d.png" alt="Image from Gyazo"></a></p>
<p>下図はシグモイド関数のグラフです．
シグモイド関数は，ステップ関数とは異なり滑らかに変化する連続関数であり，
0から1の範囲を出力します．</p>
<p>$$
f(y) = \frac{1}{1 + e^{-y}}
$$</p>
<p><a href="https://gyazo.com/e3f577d0c7f3e27ffb068120584170e1"><img src="https://i.gyazo.com/e3f577d0c7f3e27ffb068120584170e1.png" alt="Image from Gyazo"></a></p>
<p>下図はReLU関数のグラフです．
ReLU関数は入力$y$が0以上なら入力$y$をそのまま出力し，
0未満であれば0を出力する関数です．</p>
<p><a href="https://gyazo.com/f7cf68061c120cfc53001ef8b7edc961"><img src="https://i.gyazo.com/f7cf68061c120cfc53001ef8b7edc961.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  単純パーセプトロンの実装
</h1>

<p>ノートブックを作成し，ノートブックのタイトルを<strong>NN-2</strong> に設定します．
それでは，単純パーセプトロンを <strong>PyTorch</strong> を利用して実装してみましょう．
まずは，PyTorchとNumpyをインポートします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> torch.nn <span style="color:#f92672">as</span> nn
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
</code></pre></div><p>単純パーセプトロンのネットワークを生成します．
<code>nn.Sequential</code>は，パーセプトロンの層を追加した順番に並べます．
最初に2入力・1出力の層<code>nn.Linear(2, 1）</code>を作成します．
その出力をシグモイド関数<code>nn.Sigmoid()</code>に伝え，最終的な出力を得ています．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 単純パーセプトロン</span>
network <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>),
    nn<span style="color:#f92672">.</span>Sigmoid()
)
<span style="color:#66d9ef">print</span>(network)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Sequential(
  (<span style="color:#ae81ff">0</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span>True)
  (<span style="color:#ae81ff">1</span>): Sigmoid()
)
</code></pre></div><p>重みやバイアスなどのパラメータ$w$は，ランダムに初期化されています．
ここでは，下記のようにパラメータを強制的に変更します．</p>
<p>$$
{\bf w} = (w_0, w_1, w_2) = (-0.5, 0, 1)
$$</p>
<p>パーセプトロンの各層には，配列として参照することが可能です．
<code>network[0]</code>は先程作成した2入力・1出力の層です．
重みを変更するには，<code>network[0].weight.data</code>の<code>fill_</code>メソッドを利用します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 重みの変更</span>
network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">0</span>)
network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>fill_(<span style="color:#ae81ff">1</span>)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Parameter containing:
tensor([[<span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">1.</span>]], requires_grad<span style="color:#f92672">=</span>True)
</code></pre></div><p>バイアスを変更するには，<code>network[0].bias.data</code>の<code>fill_</code>メソッドを利用します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># バイアスの変更</span>
network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>fill_(<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span>)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Parameter containing:
tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5000</span>], requires_grad<span style="color:#f92672">=</span>True)
</code></pre></div><p>単純パーセプトロンの入力${\bf x}=(x_1, x_2)$をテンソルとして作成します（ここではバイアスは除きます）．</p>
<p>$$
{\bf x} = (x_1, x_2) = (1, 1)
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 入力</span>
x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
<span style="color:#66d9ef">print</span>(x)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([<span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1.</span>])
</code></pre></div><p>単純パーセプトロンに${\bf x}$を入力し，出力$z$を得ます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">z <span style="color:#f92672">=</span> network(x)
<span style="color:#66d9ef">print</span>(z)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([<span style="color:#ae81ff">0.6225</span>], grad_fn<span style="color:#f92672">=&lt;</span>SigmoidBackward<span style="color:#f92672">&gt;</span>)
</code></pre></div><p>出力$z$は <strong>0.6225</strong> になりました．
この値が正しいか確認してみましょう．
定義に従って計算すると，PyTorchで作成した単純パーセプトロンと出力が一致していることが分かります．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sigmoid</span>(x):
    <span style="color:#66d9ef">return</span>  <span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">*</span> x))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>]) <span style="color:#75715e">#入力</span>
w <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>]) <span style="color:#75715e">#重みとバイアス</span>
y <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>dot(w) <span style="color:#75715e">#中間出力</span>
z <span style="color:#f92672">=</span> sigmoid(y) <span style="color:#75715e">#シグモイド関数</span>
<span style="color:#66d9ef">print</span>(z)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#ae81ff">0.6224593312018546</span>
</code></pre></div><h3>参考書籍</h3>








<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07GWHP9YM&linkId=08226226a8fb428fe7bc7d48e47ff8a0&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07FVJKP1L&linkId=9f5d740609362f2de596d41b9b060b30&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07VPDVNKW&linkId=ab58ead321f3b247b4b658408f167d43&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07SPZ4Z82&linkId=dcc9a4aec3676eac587eb38f0412ccdd&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    <div style="display:flex; justify-content:center; margin-top:20px">

  
  <div style="margin:10px; margin-top:3px" class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter2/" data-layout="button" data-size="small">
    <a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.facebook.com%2Fnmukai1978%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a>
  </div>
  
  
  <div style="margin:10px;">
    <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-show-count="false">Tweet</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>
  
  <div style="margin:10px;">
    <a href="https://twitter.com/nmukai1978?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @nmukai1978</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>

</div>





  </div>

  <div class="pagination">
    <a href="/" class="top" ><span>Top</span></a>
    <a href='javascript:history.back()' class="top" style="margin-left: 30px"><span>Back</span></a>
  </div>

  
  

  <h3>スポンサーリンク</h3>








<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1652300955422837"
     data-ad-slot="5881819823"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; <time datetime="2021-02-23 16:07:11.878072 &#43;0900 JST m=&#43;0.237518257">2021</time> Naoto Mukai. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.</span>
  </div>
</footer>


    </body>
</html>
