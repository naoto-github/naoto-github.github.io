<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    物体画像（CIFAR-10）の分類 | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  
  <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  
  
  

  <meta property="og:title" content="物体画像（CIFAR-10）の分類" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter5/" />



  <meta property="og:image" content="https://i.gyazo.com/164f445e9c979bcecb9474bae3f58102.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="物体画像(CIFAR-10) CIFAR-10データセットを利用した物体画像の認識に挑戦しましょう． 60000枚のカラー画像（RGB）を含むデータセットであり， 各画像は$32 \times 32$ピクセルで構成されています． また，各画像は，airplane，automobile，birdなど10のカテゴリに分類されており， 前回学習した多層パーセプトロンを利用して分類を実現します．
ノートブックを作成し，ノートブックのタイトルをchapter5 に設定します． まずはPyTorch，Numpy，Matplotlibに加えて， データセットを提供するTorchvisionをインポートします． CIFAR-10も提供されるデータセットの一つです．
!pip install torch !pip install torchvision import torch import torch.nn as nn import torch.optim as optim import torchvision import torchvision.transforms as transforms import numpy as np import matplotlib.pyplot as plt それでは，CIFAR10のデータセットを読み込みます． 初回のみはローカルへのダウンロードが発生します． 今回は学習用に用いられる50000枚のデータを利用します．
dataset = torchvision.datasets.CIFAR10(root=&#34;./data&#34;, download=True) print(dataset) #出力 Extracting ./data/cifar-10-python.tar.gz to ./data Dataset CIFAR10 Number of datapoints: 50000 Root location: ./data Split: Train データセットには，正解のラベルを表す番号が含まれていますが， ラベルの名前（例，airplane）などは含まれていません． そこで，ラベルの名前を含むリストを作成しておきます． リストの要素番号とラベルの番号が一致していることに注意してください．" />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="物体画像（CIFAR-10）の分類" />



  <meta name="twitter:description" content="物体画像(CIFAR-10) CIFAR-10データセットを利用した物体画像の認識に挑戦しましょう． 60000枚のカラー画像（RGB）を含むデータセットであり， 各画像は$32 \times 32$ピクセルで構成されています． また，各画像は，airplane，automobile，birdなど10のカテゴリに分類されており， 前回学習した多層パーセプトロンを利用して分類を実現します．
ノートブックを作成し，ノートブックのタイトルをchapter5 に設定します． まずはPyTorch，Numpy，Matplotlibに加えて， データセットを提供するTorchvisionをインポートします． CIFAR-10も提供されるデータセットの一つです．
!pip install torch !pip install torchvision import torch import torch.nn as nn import torch.optim as optim import torchvision import torchvision.transforms as transforms import numpy as np import matplotlib.pyplot as plt それでは，CIFAR10のデータセットを読み込みます． 初回のみはローカルへのダウンロードが発生します． 今回は学習用に用いられる50000枚のデータを利用します．
dataset = torchvision.datasets.CIFAR10(root=&#34;./data&#34;, download=True) print(dataset) #出力 Extracting ./data/cifar-10-python.tar.gz to ./data Dataset CIFAR10 Number of datapoints: 50000 Root location: ./data Split: Train データセットには，正解のラベルを表す番号が含まれていますが， ラベルの名前（例，airplane）などは含まれていません． そこで，ラベルの名前を含むリストを作成しておきます． リストの要素番号とラベルの番号が一致していることに注意してください．" />



  <meta name="twitter:image" content="https://i.gyazo.com/164f445e9c979bcecb9474bae3f58102.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    
    <h1 class="post-title">物体画像（CIFAR-10）の分類</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/164f445e9c979bcecb9474bae3f58102"><img src="https://i.gyazo.com/164f445e9c979bcecb9474bae3f58102.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  物体画像(CIFAR-10)
</h1>

<p><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>データセットを利用した物体画像の認識に挑戦しましょう．
60000枚のカラー画像（RGB）を含むデータセットであり，
各画像は$32 \times 32$ピクセルで構成されています．
また，各画像は，airplane，automobile，birdなど10のカテゴリに分類されており，
前回学習した多層パーセプトロンを利用して分類を実現します．</p>
<p>ノートブックを作成し，ノートブックのタイトルを<strong>chapter5</strong> に設定します．
まずはPyTorch，Numpy，Matplotlibに加えて，
データセットを提供する<a href="https://pytorch.org/docs/stable/torchvision/index.html">Torchvision</a>をインポートします．
CIFAR-10も提供されるデータセットの一つです．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>!pip install torch
</span></span><span style="display:flex;"><span>!pip install torchvision
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.optim <span style="color:#66d9ef">as</span> optim
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.transforms <span style="color:#66d9ef">as</span> transforms
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span></code></pre></div><p>それでは，CIFAR10のデータセットを読み込みます．
初回のみはローカルへのダウンロードが発生します．
今回は学習用に用いられる50000枚のデータを利用します．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>print(dataset)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Extracting <span style="color:#f92672">./</span>data<span style="color:#f92672">/</span>cifar<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span><span style="color:#f92672">-</span>python<span style="color:#f92672">.</span>tar<span style="color:#f92672">.</span>gz to <span style="color:#f92672">./</span>data
</span></span><span style="display:flex;"><span>Dataset CIFAR10
</span></span><span style="display:flex;"><span>    Number of datapoints: <span style="color:#ae81ff">50000</span>
</span></span><span style="display:flex;"><span>    Root location: <span style="color:#f92672">./</span>data
</span></span><span style="display:flex;"><span>    Split: Train
</span></span></code></pre></div><p>データセットには，正解のラベルを表す番号が含まれていますが，
ラベルの名前（例，airplane）などは含まれていません．
そこで，ラベルの名前を含むリストを作成しておきます．
<strong>リストの要素番号</strong>と<strong>ラベルの番号</strong>が一致していることに注意してください．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>label_names <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;airplane&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;automobile&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;bird&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;cat&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;deer&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;dog&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;frog&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;horse&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;ship&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;truck&#34;</span>])
</span></span></code></pre></div><p>データセットの最初のデータを取出します．
各データは画像（image）とラベル（label）のタプルで構成されています．
画像を<code>plt.imshow()</code>で表示してみましょう．
また，ラベルは<code>6</code>であり，対応するラベル名前は<code>flog</code>であることがわかります．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(image)
</span></span><span style="display:flex;"><span>print(type(image))
</span></span><span style="display:flex;"><span>print(label)
</span></span><span style="display:flex;"><span>print(label_names[label])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">PIL</span><span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>Image<span style="color:#e6db74">&#39;&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>frog
</span></span></code></pre></div><p><a href="https://gyazo.com/21413c3097a0728fcab718c478301227"><img src="https://i.gyazo.com/21413c3097a0728fcab718c478301227.png" alt="Image from Gyazo"></a></p>
<p>上述で読み込んだ画像は <strong>PIL.Image.Image</strong> であり，
そのままPyTorchでは用いることができません．
そこで，<code>transform=transforms.ToTensor()</code>オプションを設定して，
再度，データセットを読み込みます．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, transform<span style="color:#f92672">=</span>transforms<span style="color:#f92672">.</span>ToTensor())
</span></span><span style="display:flex;"><span>print(dataset)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Files already downloaded <span style="color:#f92672">and</span> verified
</span></span><span style="display:flex;"><span>Dataset CIFAR10
</span></span><span style="display:flex;"><span>    Number of datapoints: <span style="color:#ae81ff">50000</span>
</span></span><span style="display:flex;"><span>    Root location: <span style="color:#f92672">./</span>data
</span></span><span style="display:flex;"><span>    Split: Train
</span></span><span style="display:flex;"><span>    StandardTransform
</span></span><span style="display:flex;"><span>Transform: ToTensor()
</span></span></code></pre></div><p>データセットの最初のデータを取出します．
画像は <strong>torch.Tensor</strong> であり，PyTorchで処理できることが分かります．
また，$3 \times 32 \times 32$のテンソルで構成されており，
それぞれ，RGBの画素値，$X$座標，$Y$座標を表しています．
例えば，$X=10$，$Y=10$の赤色の画素値は<code>0.3137</code>であることが分かります．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(type(image))
</span></span><span style="display:flex;"><span>print(image<span style="color:#f92672">.</span>size())
</span></span><span style="display:flex;"><span>print(image[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">10</span>][<span style="color:#ae81ff">10</span>])
</span></span><span style="display:flex;"><span>print(label)
</span></span><span style="display:flex;"><span>print(label_names[label])
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>Tensor<span style="color:#e6db74">&#39;&gt;</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>Size([<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>])
</span></span><span style="display:flex;"><span>tensor(<span style="color:#ae81ff">0.3137</span>)
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>frog
</span></span></code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  ミニバッチ学習
</h1>

<p>これまでは，学習データの全てを用いて損失（誤差）を計算した後で，
重みやバイアスを1回更新するという方法を採用していました．
この方法は <strong>バッチ学習</strong> と呼ばれています．
バッチ学習は，学習結果が安定しやすいという特徴がありますが，
一方で，局所解に陥りやすいという欠点があります．
そこで，用いられるのが <strong>ミニバッチ学習</strong> と呼ばれる方法です．
$N$個の学習データから，ランダムに$n (\leq N)$個のデータを取り出し，
これを用いて誤差を計算し，重みやバイアスの更新を複数回繰り返すという方法です．
ランダムにデータを選んで学習を進めるため，局所解に陥りにくく，
より良い解を発見できる可能性が向上します．
上記の$n$はバッチサイズと呼ばれます．</p>
<p>それでは，ミニバッチ学習用のデータセットを作成します．
まずは，分類問題の難易度を下げるため，
ラベルが0(airplane)，1(automobile)，2(bird)の3種類のみを抽出します．
これにより，学習データの全データ数は$N=15000$となりました．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>my_dataset <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> dataset:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">or</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>:
</span></span><span style="display:flex;"><span>        my_dataset<span style="color:#f92672">.</span>append((image, label))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(len(my_dataset))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">15000</span>
</span></span></code></pre></div><p>この$N=15000$からミニバッチ用の小さなデータセットを
<code>torch.utils.data.DataLoader()</code>を利用して作成します．
ここでは，バッチサイズ$n=64$としました．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(dataset<span style="color:#f92672">=</span>my_dataset, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>)
</span></span></code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  ネットワークの学習
</h1>

<p>4層で構成される多層パーセプトロンを定義します．
ここでは，入力層は$3072=32 \times 32 \times 3$，中間層（2層目）は$600$，
中間層（3層目）は$600$，出力層は$3$のニューロンが配置されています．
出力層からは3つのラベル（airplane， automobile， bird）の確率が出力されます．
また，活性化関数は，入力層と中間層は <strong>ReLU関数</strong>，出力層は <strong>Softmax関数</strong> を利用しています．
Softmax関数は下記の式で表され，
出力層が各ラベルの確率（割合）を出力するように調整する役割を担います．</p>
<p>$$
f(y_i) = \frac{\exp(y_i)}{\sum_i \exp(y_j)}
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>network <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">600</span>),
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">600</span>, <span style="color:#ae81ff">600</span>),
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">600</span>, <span style="color:#ae81ff">3</span>),
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(network)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Sequential(
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">0</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">3072</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">1</span>): ReLU()
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">2</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">3</span>): ReLU()
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">4</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">5</span>): Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>ここで学習データに対する <strong>正解率（Accuracy）</strong> を算出してみます．
当然，何も学習していないので，正解率は低く，0.321という結果でした．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>counter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> my_dataset:
</span></span><span style="display:flex;"><span>    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>    z <span style="color:#f92672">=</span> network(image)
</span></span><span style="display:flex;"><span>    t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(z)
</span></span><span style="display:flex;"><span>    counter <span style="color:#f92672">=</span> counter<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> (t <span style="color:#f92672">==</span> label) <span style="color:#66d9ef">else</span> counter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>acc <span style="color:#f92672">=</span> counter <span style="color:#f92672">/</span> len(my_dataset)
</span></span><span style="display:flex;"><span>print(acc)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0.321</span>
</span></span></code></pre></div><p>損失関数と最適化関数を定義します．
損失関数は <a href="https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html">ソフトマックス交差エントロピー</a>，最適化関数は <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam">Adam</a> を採用します．
ソフトマックス交差エントロピーは，多値分類問題で利用される損失関数であり，
<code>nn.CrossEntropyLoss()</code>で計算することができます．
この関数には出力結果$z$と，正解のラベル$\hat{z}$を引数として与えますが，
正解のラベルは <strong>One-Hot形式</strong> (例． ${\bf \hat{z}}=(1,0,0）$ )ではなく，
<strong>ラベル形式</strong> (例．$\hat{z}=0$)となることに注意してください．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>Adam(network<span style="color:#f92672">.</span>parameters())
</span></span></code></pre></div><p>それでは，ミニバッチ学習を用いて重みとバイスを学習します．
バッチサイズは$n=64$としたため，1回のエポック（epoch）で
$15000 / 64 \simeq 234$回のミニバッチ学習が行わます．
これを10エポック繰り返します．
画像データ（image）を<code>view()</code>で1次元のテンソルに変換していることに注意してください．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>loss_history <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    loss_epoch <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, (images, labels) <span style="color:#f92672">in</span> enumerate(loader):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        images <span style="color:#f92672">=</span> images<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        z <span style="color:#f92672">=</span> network(images)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> criterion(z, labels)
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        loss_epoch <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74"> </span><span style="color:#e6db74">{</span>loss_epoch <span style="color:#f92672">/</span> i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    loss_history<span style="color:#f92672">.</span>append(loss_epoch <span style="color:#f92672">/</span> i)
</span></span></code></pre></div><p>損失の推移を可視化します．
エポックごとに損失が減少していることが確認できます．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1.2192253230983376</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> <span style="color:#ae81ff">0.9285253609856988</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span> <span style="color:#ae81ff">0.8595439547147506</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">3</span> <span style="color:#ae81ff">0.846264493261647</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span> <span style="color:#ae81ff">0.840729504568964</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">5</span> <span style="color:#ae81ff">0.8289006696297572</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">6</span> <span style="color:#ae81ff">0.8255122416039817</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">7</span> <span style="color:#ae81ff">0.8172445302335625</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">8</span> <span style="color:#ae81ff">0.8131960273807884</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">9</span> <span style="color:#ae81ff">0.8121428805538732</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(loss_history)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;epoch&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;loss&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/68f20188e9f59491c8ccac72b0ec5e59"><img src="https://i.gyazo.com/68f20188e9f59491c8ccac72b0ec5e59.png" alt="Image from Gyazo"></a></p>
<p>最後に正解率を再度計算してみましょう（あくまで学習用データに対する正解率であり，評価用のデータではないことに注意）．
正解率は0.752となり，初期状態の0.321に比べ，かなり向上したことが確認できます．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>counter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> my_dataset:
</span></span><span style="display:flex;"><span>    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>    z <span style="color:#f92672">=</span> network(image)
</span></span><span style="display:flex;"><span>    t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(z)
</span></span><span style="display:flex;"><span>    counter <span style="color:#f92672">=</span> counter<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> (t <span style="color:#f92672">==</span> label) <span style="color:#66d9ef">else</span> counter
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>acc <span style="color:#f92672">=</span> counter <span style="color:#f92672">/</span> len(my_dataset)
</span></span><span style="display:flex;"><span>print(acc)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0.7523333333333333</span>
</span></span></code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>

<p>Google Colaboratoryで作成した <strong>chapter5.ipynb</strong> を保存し，
<strong>共有用のリンク</strong> と <strong>ノートブック（.ipynb）</strong> をダウンロードして提出してください．
提出の前に必ず下記の設定を行ってください．</p>
<ul>
<li>ノートブックの設定で「セルの出力を除外する」のチェックを外す</li>
<li>ノートブックの変更内容を保存して固定</li>
<li>共有設定で「学校法人椙山女学園大学」を「閲覧者」に設定</li>
</ul>
<h3>参考書籍</h3>








<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07GWHP9YM&linkId=08226226a8fb428fe7bc7d48e47ff8a0&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07FVJKP1L&linkId=9f5d740609362f2de596d41b9b060b30&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07VPDVNKW&linkId=ab58ead321f3b247b4b658408f167d43&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07SPZ4Z82&linkId=dcc9a4aec3676eac587eb38f0412ccdd&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter5/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
