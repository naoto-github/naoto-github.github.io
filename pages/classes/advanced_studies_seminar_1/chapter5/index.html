<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    物体画像（CIFAR-10）の分類 | MLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="MLAB" />

  
  <link href="https://fonts.googleapis.com/css?family=M+PLUS+Rounded+1c:500&amp;subset=japanese" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">

  
  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v6.0"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  <meta property="og:title" content="物体画像（CIFAR-10）の分類" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter5/" />



  <meta property="og:image" content="https://i.gyazo.com/164f445e9c979bcecb9474bae3f58102.png" />



  <meta property="og:site_name" content="MLAB" />



  <meta property="og:description" content="物体画像(CIFAR-10)  CIFAR-10データセットを利用した物体画像の認識に挑戦しましょう． 60000枚のカラー画像（RGB）を含むデータセットであり， 各画像は$32 \times 32$ピクセルで構成されています． また，各画像は，airplane，automobile，birdなど10のカテゴリに分類されており， 前回学習した多層パーセプトロンを利用して分類を実現します．
ノートブックを作成し，ノートブックのタイトルをNN-5 に設定します． まずはPyTorch，Numpy，Matplotlibに加えて， データセットを提供するTorchvisionをインポートします． CIFAR-10も提供されるデータセットの一つです．
import torch import torch.nn as nn import torch.optim as optim import torchvision import torchvision.transforms as transforms import numpy as np import matplotlib.pyplot as plt それでは，CIFAR10のデータセットを読み込みます． 初回のみはローカルへのダウンロードが発生します． 今回は学習用に用いられる50000枚のデータを利用します．
dataset = torchvision.datasets.CIFAR10(root=&#34;./data&#34;, download=True) print(dataset) #出力 Files already downloaded and verified Dataset CIFAR10 Number of datapoints: 50000 Root location: ./data Split: Train データセットには，正解のラベルを表す番号が含まれていますが， ラベルの名前（例，airplane）などは含まれていません． そこで，ラベルの名前を含むリストを作成しておきます． リストの要素番号とラベルの番号が一致していることに注意してください．
label_names = np." />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="物体画像（CIFAR-10）の分類" />



  <meta name="twitter:description" content="物体画像(CIFAR-10)  CIFAR-10データセットを利用した物体画像の認識に挑戦しましょう． 60000枚のカラー画像（RGB）を含むデータセットであり， 各画像は$32 \times 32$ピクセルで構成されています． また，各画像は，airplane，automobile，birdなど10のカテゴリに分類されており， 前回学習した多層パーセプトロンを利用して分類を実現します．
ノートブックを作成し，ノートブックのタイトルをNN-5 に設定します． まずはPyTorch，Numpy，Matplotlibに加えて， データセットを提供するTorchvisionをインポートします． CIFAR-10も提供されるデータセットの一つです．
import torch import torch.nn as nn import torch.optim as optim import torchvision import torchvision.transforms as transforms import numpy as np import matplotlib.pyplot as plt それでは，CIFAR10のデータセットを読み込みます． 初回のみはローカルへのダウンロードが発生します． 今回は学習用に用いられる50000枚のデータを利用します．
dataset = torchvision.datasets.CIFAR10(root=&#34;./data&#34;, download=True) print(dataset) #出力 Files already downloaded and verified Dataset CIFAR10 Number of datapoints: 50000 Root location: ./data Split: Train データセットには，正解のラベルを表す番号が含まれていますが， ラベルの名前（例，airplane）などは含まれていません． そこで，ラベルの名前を含むリストを作成しておきます． リストの要素番号とラベルの番号が一致していることに注意してください．
label_names = np." />



  <meta name="twitter:image" content="https://i.gyazo.com/164f445e9c979bcecb9474bae3f58102.png" />



</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    <p class="nav-info">Mukai's Lab. at Sugiyama Women's University</p>    
    <a href="/">
    <h2 class="nav-title">
	     <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
	     <span>MLAB</span>
        

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/pages/classes/">授業資料</a>
  </li>
  
  
  
  <li>
    <a href="/pages/tech/">技術メモ</a>
  </li>
  
  
  <li>	
    <a href="https://sites.google.com/g.sugiyama-u.ac.jp/mlab?pli=1&authuser=1" target="_blank">学内専用</a>
  </li>  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    <div class="post-info">
  <span>written by</span>
  Naoto Mukai
  
  
  
  <span>on&nbsp;</span><time datetime="2020-07-03 14:14:15 &#43;0900 JST">July 3, 2020</time>
</div>

    <h1 class="post-title">物体画像（CIFAR-10）の分類</h1>
<div class="post-line"></div>

    

    <p><a href="https://gyazo.com/164f445e9c979bcecb9474bae3f58102"><img src="https://i.gyazo.com/164f445e9c979bcecb9474bae3f58102.png" alt="Image from Gyazo"></a></p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  物体画像(CIFAR-10)
</h1>

<p><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>データセットを利用した物体画像の認識に挑戦しましょう．
60000枚のカラー画像（RGB）を含むデータセットであり，
各画像は$32 \times 32$ピクセルで構成されています．
また，各画像は，airplane，automobile，birdなど10のカテゴリに分類されており，
前回学習した多層パーセプトロンを利用して分類を実現します．</p>
<p>ノートブックを作成し，ノートブックのタイトルを<strong>NN-5</strong> に設定します．
まずはPyTorch，Numpy，Matplotlibに加えて，
データセットを提供する<a href="https://pytorch.org/docs/stable/torchvision/index.html">Torchvision</a>をインポートします．
CIFAR-10も提供されるデータセットの一つです．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> torch.nn <span style="color:#f92672">as</span> nn
<span style="color:#f92672">import</span> torch.optim <span style="color:#f92672">as</span> optim
<span style="color:#f92672">import</span> torchvision
<span style="color:#f92672">import</span> torchvision.transforms <span style="color:#f92672">as</span> transforms
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
</code></pre></div><p>それでは，CIFAR10のデータセットを読み込みます．
初回のみはローカルへのダウンロードが発生します．
今回は学習用に用いられる50000枚のデータを利用します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, download<span style="color:#f92672">=</span>True)
<span style="color:#66d9ef">print</span>(dataset)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Files already downloaded <span style="color:#f92672">and</span> verified
Dataset CIFAR10
    Number of datapoints: <span style="color:#ae81ff">50000</span>
    Root location: <span style="color:#f92672">./</span>data
    Split: Train
</code></pre></div><p>データセットには，正解のラベルを表す番号が含まれていますが，
ラベルの名前（例，airplane）などは含まれていません．
そこで，ラベルの名前を含むリストを作成しておきます．
<strong>リストの要素番号</strong>と<strong>ラベルの番号</strong>が一致していることに注意してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">label_names <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([
    <span style="color:#e6db74">&#34;airplane&#34;</span>,
    <span style="color:#e6db74">&#34;automobile&#34;</span>,
    <span style="color:#e6db74">&#34;bird&#34;</span>,
    <span style="color:#e6db74">&#34;cat&#34;</span>,
    <span style="color:#e6db74">&#34;deer&#34;</span>,
    <span style="color:#e6db74">&#34;dog&#34;</span>,
    <span style="color:#e6db74">&#34;frog&#34;</span>,
    <span style="color:#e6db74">&#34;horse&#34;</span>,
    <span style="color:#e6db74">&#34;ship&#34;</span>,
    <span style="color:#e6db74">&#34;truck&#34;</span>])
</code></pre></div><p>データセットの最初のデータを取出します．
各データは画像（image）とラベル（label）のタプルで構成されています．
画像を<code>plt.imshow()</code>で表示してみましょう．
また，ラベルは<code>6</code>であり，対応するラベル名前は<code>flog</code>であることがわかります．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
plt<span style="color:#f92672">.</span>imshow(image)
<span style="color:#66d9ef">print</span>(type(image))
<span style="color:#66d9ef">print</span>(label)
<span style="color:#66d9ef">print</span>(label_names[label])
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">PIL</span><span style="color:#f92672">.</span>Image<span style="color:#f92672">.</span>Image<span style="color:#e6db74">&#39;&gt;</span>
<span style="color:#ae81ff">6</span>
frog
</code></pre></div><p><a href="https://gyazo.com/21413c3097a0728fcab718c478301227"><img src="https://i.gyazo.com/21413c3097a0728fcab718c478301227.png" alt="Image from Gyazo"></a></p>
<p>上述で読み込んだ画像は <strong>PIL.Image.Image</strong> であり，
そのままPyTorchでは用いることができません．
そこで，<code>transform=transforms.ToTensor()</code>オプションを設定して，
再度，データセットを読み込みます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, transform<span style="color:#f92672">=</span>transforms<span style="color:#f92672">.</span>ToTensor())
<span style="color:#66d9ef">print</span>(dataset)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Files already downloaded <span style="color:#f92672">and</span> verified
Dataset CIFAR10
    Number of datapoints: <span style="color:#ae81ff">50000</span>
    Root location: <span style="color:#f92672">./</span>data
    Split: Train
    StandardTransform
Transform: ToTensor()
</code></pre></div><p>データセットの最初のデータを取出します．
画像は <strong>torch.Tensor</strong> であり，PyTorchで処理できることが分かります．
また，$3 \times 32 \times 32$のテンソルで構成されており，
それぞれ，RGBの画素値，$X$座標，$Y$座標を表しています．
例えば，$X=10$，$Y=10$の赤色の画素値は<code>0.3137</code>であることが分かります．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
<span style="color:#66d9ef">print</span>(type(image))
<span style="color:#66d9ef">print</span>(image<span style="color:#f92672">.</span>size())
<span style="color:#66d9ef">print</span>(image[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">10</span>][<span style="color:#ae81ff">10</span>])
<span style="color:#66d9ef">print</span>(label)
<span style="color:#66d9ef">print</span>(label_names[label])
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>Tensor<span style="color:#e6db74">&#39;&gt;</span>
torch<span style="color:#f92672">.</span>Size([<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>])
tensor(<span style="color:#ae81ff">0.3137</span>)
<span style="color:#ae81ff">6</span>
frog
</code></pre></div><h1>
  <img class="head-image" src="/logo/logo.png">
  ミニバッチ学習
</h1>

<p>これまでは，学習データの全てを用いて損失（誤差）を計算した後で，
重みやバイアスを1回更新するという方法を採用していました．
この方法は <strong>バッチ学習</strong> と呼ばれています．
バッチ学習は，学習結果が安定しやすいという特徴がありますが，
一方で，局所解に陥りやすいという欠点があります．
そこで，用いられるのが <strong>ミニバッチ学習</strong> と呼ばれる方法です．
$N$個の学習データから，ランダムに$n (\leq N)$個のデータを取り出し，
これを用いて誤差を計算し，重みやバイアスの更新を複数回繰り返すという方法です．
ランダムにデータを選んで学習を進めるため，局所解に陥りにくく，
より良い解を発見できる可能性が向上します．
上記の$n$はバッチサイズと呼ばれます．</p>
<p>それでは，ミニバッチ学習用のデータセットを作成します．
まずは，分類問題の難易度を下げるため，
ラベルが0(airplane)，1(automobile)，2(bird)の3種類のみを抽出します．
これにより，学習データの全データ数は$N=15000$となりました．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">my_dataset <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> dataset:
    <span style="color:#66d9ef">if</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">or</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>:
        my_dataset<span style="color:#f92672">.</span>append((image, label))

<span style="color:#66d9ef">print</span>(len(my_dataset))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#ae81ff">15000</span>
</code></pre></div><p>この$N=15000$からミニバッチ用の小さなデータセットを
<code>torch.utils.data.DataLoader()</code>を利用して作成します．
ここでは，バッチサイズ$n=64$としました．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(dataset<span style="color:#f92672">=</span>my_dataset, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>)
</code></pre></div><h1>
  <img class="head-image" src="/logo/logo.png">
  ネットワークの学習
</h1>

<p>4層で構成される多層パーセプトロンを定義します．
ここでは，入力層は$3072=32 \times 32 \times 3$，中間層（2層目）は$600$，
中間層（3層目）は$600$，出力層は$3$のニューロンが配置されています．
出力層からは3つのラベル（airplane， automobile， bird）の確率が出力されます．
また，活性化関数は中間層は <strong>ReLU関数</strong>，出力層は <strong>Softmax関数</strong> を利用しています．
Softmax関数は下記の式で表され，
出力層が各ラベルの確率（割合）を出力するように調整する役割を担います．</p>
<p>$$
f(y_i) = \frac{\exp(y_i)}{\sum_i \exp(y_j)}
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">network <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">600</span>),
    nn<span style="color:#f92672">.</span>ReLU(),
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">600</span>, <span style="color:#ae81ff">600</span>),
    nn<span style="color:#f92672">.</span>ReLU(),
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">600</span>, <span style="color:#ae81ff">3</span>),
    nn<span style="color:#f92672">.</span>Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
)

<span style="color:#66d9ef">print</span>(network)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Sequential(
  (<span style="color:#ae81ff">0</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">3072</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, bias<span style="color:#f92672">=</span>True)
  (<span style="color:#ae81ff">1</span>): ReLU()
  (<span style="color:#ae81ff">2</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, bias<span style="color:#f92672">=</span>True)
  (<span style="color:#ae81ff">3</span>): ReLU()
  (<span style="color:#ae81ff">4</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">600</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, bias<span style="color:#f92672">=</span>True)
  (<span style="color:#ae81ff">5</span>): Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
)
</code></pre></div><p>ここで学習データに対する <strong>正解率（Accuracy）</strong> を算出してみます．
当然，何も学習していないので，正解率は低く，0.321という結果でした．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">counter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> my_dataset:
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>)
    z <span style="color:#f92672">=</span> network(image)
    t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(z)
    counter <span style="color:#f92672">=</span> counter<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> (t <span style="color:#f92672">==</span> label) <span style="color:#66d9ef">else</span> counter

acc <span style="color:#f92672">=</span> counter <span style="color:#f92672">/</span> len(my_dataset)
<span style="color:#66d9ef">print</span>(acc)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#ae81ff">0.321</span>
</code></pre></div><p>損失関数と最適化関数を定義します．
損失関数は <a href="https://pytorch.org/docs/master/generated/torch.nn.CrossEntropyLoss.html">ソフトマックス交差エントロピー</a>，最適化関数は <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam">Adam</a> を採用します．
ソフトマックス交差エントロピーは，多値分類問題で利用される損失関数であり，
<code>nn.CrossEntropyLoss()</code>で計算することができます．
この関数には出力結果$z$と，正解のラベル$\hat{z}$を引数として与えますが，
正解のラベルは <strong>One-Hot形式</strong> (例． ${\bf \hat{z}}=(1,0,0）$ )ではなく，
<strong>ラベル形式</strong> (例．$\hat{z}=0$)となることに注意してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>Adam(network<span style="color:#f92672">.</span>parameters())
</code></pre></div><p>それでは，ミニバッチ学習を用いて重みとバイスを学習します．
バッチサイズは$n=64$としたため，1回のエポック（epoch）で
$15000 / 64 \simeq 234$回のミニバッチ学習が行わます．
これを10エポック繰り返します．
画像データ（image）を<code>view()</code>で1次元のテンソルに変換していることに注意してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loss_history <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):

    loss_epoch <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>

    <span style="color:#66d9ef">for</span> i, (images, labels) <span style="color:#f92672">in</span> enumerate(loader):

        images <span style="color:#f92672">=</span> images<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>)

        optimizer<span style="color:#f92672">.</span>zero_grad()
        z <span style="color:#f92672">=</span> network(images)

        loss <span style="color:#f92672">=</span> criterion(z, labels)
        loss<span style="color:#f92672">.</span>backward()

        loss_epoch <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()

        optimizer<span style="color:#f92672">.</span>step()

    <span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;{epoch} {loss_epoch / i}&#34;</span>)
    loss_history<span style="color:#f92672">.</span>append(loss_epoch <span style="color:#f92672">/</span> i)
</code></pre></div><p>損失の推移を可視化します．
エポックごとに損失が減少していることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1.2192253230983376</span>
<span style="color:#ae81ff">1</span> <span style="color:#ae81ff">0.9285253609856988</span>
<span style="color:#ae81ff">2</span> <span style="color:#ae81ff">0.8595439547147506</span>
<span style="color:#ae81ff">3</span> <span style="color:#ae81ff">0.846264493261647</span>
<span style="color:#ae81ff">4</span> <span style="color:#ae81ff">0.840729504568964</span>
<span style="color:#ae81ff">5</span> <span style="color:#ae81ff">0.8289006696297572</span>
<span style="color:#ae81ff">6</span> <span style="color:#ae81ff">0.8255122416039817</span>
<span style="color:#ae81ff">7</span> <span style="color:#ae81ff">0.8172445302335625</span>
<span style="color:#ae81ff">8</span> <span style="color:#ae81ff">0.8131960273807884</span>
<span style="color:#ae81ff">9</span> <span style="color:#ae81ff">0.8121428805538732</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>plot(loss_history)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;epoch&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;loss&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/68f20188e9f59491c8ccac72b0ec5e59"><img src="https://i.gyazo.com/68f20188e9f59491c8ccac72b0ec5e59.png" alt="Image from Gyazo"></a></p>
<p>最後に正解率を再度計算してみましょう（あくまで学習用データに対する正解率であり，評価用のデータではないことに注意）．
正解率は0.752となり，初期状態の0.321に比べ，かなり向上したことが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">counter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> my_dataset:
    image <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">32</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span>)
    z <span style="color:#f92672">=</span> network(image)
    t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(z)
    counter <span style="color:#f92672">=</span> counter<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span> <span style="color:#66d9ef">if</span> (t <span style="color:#f92672">==</span> label) <span style="color:#66d9ef">else</span> counter

acc <span style="color:#f92672">=</span> counter <span style="color:#f92672">/</span> len(my_dataset)
<span style="color:#66d9ef">print</span>(acc)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
<span style="color:#ae81ff">0.7523333333333333</span>
</code></pre></div><h3>参考書籍</h3>








<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07GWHP9YM&linkId=08226226a8fb428fe7bc7d48e47ff8a0&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07FVJKP1L&linkId=9f5d740609362f2de596d41b9b060b30&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07VPDVNKW&linkId=ab58ead321f3b247b4b658408f167d43&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07SPZ4Z82&linkId=dcc9a4aec3676eac587eb38f0412ccdd&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    <div class="horizontal">

  
  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter5/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fmukai-lab.info%2Fwww%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
  
  
  <div style="padding: 6px; margin-top:1px">
    <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-show-count="false">Tweet</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>

  
  
</div>



  </div>

  <div class="pagination">
    <a href="/" class="top" ><span>Top</span></a>
    <a href='javascript:history.back()' class="top" style="margin-left: 30px"><span>Back</span></a>
  </div>

  

  
  

  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; <time datetime="2020-12-31 11:16:27.08731 &#43;0900 JST m=&#43;0.294431210">2020</time> Naoto Mukai. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.</span>
  </div>
</footer>


    </body>
</html>
