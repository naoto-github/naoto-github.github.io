<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    パーセプトロンの学習 | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  
  <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  
  
  

  <meta property="og:title" content="パーセプトロンの学習" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter3/" />



  <meta property="og:image" content="https://i.gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="自動微分 PyTorchでは 自動微分 という機能が実装されており， テンソルで作成した式（ 計算グラフ と呼ぶ）の傾き（勾配）が保持されます． この自動微分はパーセプトロンの重みやバイアスの学習に欠かせない機能です．
ノートブックを作成し，ノートブックのタイトルをchapter3 に設定します． まずは，PyTorchをインストールし，PyTorch，Numpy，Matplotlibをインポートします．
!pip install torch !pip install torchvision import torch import torch.nn as nn import numpy as np import matplotlib.pyplot as plt テンソルxを2.0で初期化します． このxを自動微分の対象とするためrequires_grad=Trueをオプションとして設定します．
x = torch.tensor([2.0], requires_grad=True) # x=2 print(x) #出力 tensor([2.], requires_grad=True) 定義したxを用いて計算グラフyを定義します． ここで，$x=2$であるため，$y=9$となります．
$$ y = x^2 &#43; 2x &#43; 1 $$
y = x * x &#43; 2 * x &#43; 1 print(y) #出力 tensor([9.], grad_fn=&lt;AddBackward0&gt;) yをxで微分します． 計算グラフが複数のテンソルで構成される場合は， 全てのテンソルに対する偏微分が計算されます． ここで，$x=2$であるため，$\frac{dy}{dx}=6$となります．" />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="パーセプトロンの学習" />



  <meta name="twitter:description" content="自動微分 PyTorchでは 自動微分 という機能が実装されており， テンソルで作成した式（ 計算グラフ と呼ぶ）の傾き（勾配）が保持されます． この自動微分はパーセプトロンの重みやバイアスの学習に欠かせない機能です．
ノートブックを作成し，ノートブックのタイトルをchapter3 に設定します． まずは，PyTorchをインストールし，PyTorch，Numpy，Matplotlibをインポートします．
!pip install torch !pip install torchvision import torch import torch.nn as nn import numpy as np import matplotlib.pyplot as plt テンソルxを2.0で初期化します． このxを自動微分の対象とするためrequires_grad=Trueをオプションとして設定します．
x = torch.tensor([2.0], requires_grad=True) # x=2 print(x) #出力 tensor([2.], requires_grad=True) 定義したxを用いて計算グラフyを定義します． ここで，$x=2$であるため，$y=9$となります．
$$ y = x^2 &#43; 2x &#43; 1 $$
y = x * x &#43; 2 * x &#43; 1 print(y) #出力 tensor([9.], grad_fn=&lt;AddBackward0&gt;) yをxで微分します． 計算グラフが複数のテンソルで構成される場合は， 全てのテンソルに対する偏微分が計算されます． ここで，$x=2$であるため，$\frac{dy}{dx}=6$となります．" />



  <meta name="twitter:image" content="https://i.gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        <div id="darkModeToggle" onclick="toggleDarkMode()">
  &#9680; 
</div>

        

<main>
  <div class="post">
    
    <h1 class="post-title">パーセプトロンの学習</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c"><img src="https://i.gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  自動微分
</h1>

<p>PyTorchでは <strong>自動微分</strong> という機能が実装されており，
テンソルで作成した式（ <strong>計算グラフ</strong> と呼ぶ）の傾き（勾配）が保持されます．
この自動微分はパーセプトロンの重みやバイアスの学習に欠かせない機能です．</p>
<p>ノートブックを作成し，ノートブックのタイトルを<strong>chapter3</strong> に設定します．
まずは，PyTorchをインストールし，PyTorch，Numpy，Matplotlibをインポートします．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>!pip install torch
</span></span><span style="display:flex;"><span>!pip install torchvision
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span></code></pre></div><p>テンソル<code>x</code>を2.0で初期化します．
この<code>x</code>を自動微分の対象とするため<code>requires_grad=True</code>をオプションとして設定します．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">2.0</span>], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>) <span style="color:#75715e"># x=2</span>
</span></span><span style="display:flex;"><span>print(x)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor([<span style="color:#ae81ff">2.</span>], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><p>定義した<code>x</code>を用いて計算グラフ<code>y</code>を定義します．
ここで，$x=2$であるため，$y=9$となります．</p>
<p>$$
y = x^2 + 2x + 1
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y <span style="color:#f92672">=</span> x <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>print(y)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor([<span style="color:#ae81ff">9.</span>], grad_fn<span style="color:#f92672">=&lt;</span>AddBackward0<span style="color:#f92672">&gt;</span>)
</span></span></code></pre></div><p><code>y</code>を<code>x</code>で微分します．
計算グラフが複数のテンソルで構成される場合は，
全てのテンソルに対する偏微分が計算されます．
ここで，$x=2$であるため，$\frac{dy}{dx}=6$となります．</p>
<p>$$
\frac{dy}{dx} = 2x + 2
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>y<span style="color:#f92672">.</span>backward() <span style="color:#75715e">#微分</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;dy/dx = </span><span style="color:#e6db74">{</span>x<span style="color:#f92672">.</span>grad<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>dy<span style="color:#f92672">/</span>dx <span style="color:#f92672">=</span> tensor([<span style="color:#ae81ff">6.</span>])
</span></span></code></pre></div><p>図で確認してみましょう．
微分は接線の傾きを求める操作です．
$y = x^2 + 2x + 1$の$x=2$における接線の傾きが$6$となります．</p>
<p><a href="https://gyazo.com/9e120824a1ab92d5d8a80f55914d1282"><img src="https://i.gyazo.com/9e120824a1ab92d5d8a80f55914d1282.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  パーセプトロンの学習
</h1>

<h2 id="分類問題">分類問題</h2>
<p>パーセプトロンは <strong>分類</strong> や <strong>回帰</strong> と呼ばれる問題を解くことができます．
ここでは，サンプル$x=(x_1, x_2)$を2つのカテゴリ(0または1)に分類することに挑戦します．</p>
<p>例えば，リストの最初にある$(0.28, 0.34)$はカテゴリ$0$に分類されます．
同様にリストの最後の$(0.94, 0.91)$はカテゴリ$1$に分類されます．
このサンプルをパーセプトロンに学習させることで，任意のサンプルに対するカテゴリを推定します．
このようなサンプルデータは <strong>学習データ（教師データ，訓練データ）</strong> と呼ばれます．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x1 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0.28</span>, <span style="color:#ae81ff">0.35</span>, <span style="color:#ae81ff">0.41</span>, <span style="color:#ae81ff">0.78</span>, <span style="color:#ae81ff">0.89</span>, <span style="color:#ae81ff">0.94</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
</span></span><span style="display:flex;"><span>x2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0.34</span>, <span style="color:#ae81ff">0.21</span>, <span style="color:#ae81ff">0.39</span>, <span style="color:#ae81ff">0.87</span>, <span style="color:#ae81ff">0.76</span>, <span style="color:#ae81ff">0.91</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack([x1, x2], <span style="color:#ae81ff">1</span>) <span style="color:#75715e">#入力</span>
</span></span><span style="display:flex;"><span>label <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)  <span style="color:#75715e">#正解の出力</span>
</span></span><span style="display:flex;"><span>print(x)
</span></span><span style="display:flex;"><span>print(label)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor([[<span style="color:#ae81ff">0.2800</span>, <span style="color:#ae81ff">0.3400</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">0.3500</span>, <span style="color:#ae81ff">0.2100</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">0.4100</span>, <span style="color:#ae81ff">0.3900</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">0.7800</span>, <span style="color:#ae81ff">0.8700</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">0.8900</span>, <span style="color:#ae81ff">0.7600</span>],
</span></span><span style="display:flex;"><span>        [<span style="color:#ae81ff">0.9400</span>, <span style="color:#ae81ff">0.9100</span>]])
</span></span><span style="display:flex;"><span>tensor([<span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1.</span>])
</span></span></code></pre></div><p>学習データを可視化してみます．
左下の3つのサンプルがカテゴリ$0$，右上の3つのサンプルがカテゴリ$1$です．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x1, x2, c<span style="color:#f92672">=</span>label)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x1&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;x2&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/54d57be9de5bd8478351d83cd6cef77f"><img src="https://i.gyazo.com/54d57be9de5bd8478351d83cd6cef77f.png" alt="Image from Gyazo"></a></p>
<h2 id="損失関数誤差関数">損失関数（誤差関数）</h2>
<p>パーセプトロンに学習データを用いて <strong>学習</strong> させるには，
パーセプトロンの出力$z$と正しい出力（ここでは$0$または$1$）との
誤差を測る必要があります．</p>
<p>この誤差を測るための関数は <strong>損失関数（誤差関数）</strong> と呼ばれます．
損失関数には下記のような種類があります．</p>
<ul>
<li>平均2乗誤差(Mean Square Error : MSE)</li>
<li>交差エントロピー(Cross Entropy : CE)</li>
</ul>
<p>ここでは下記の式で表される平均2乗誤差を損失関数$L$として採用します．
ここで，$z_i$は$i$番目のパーセプトロンの出力，$\hat{z_i}$は正しい出力です．
また，$n$は学習データのサンプル数です．</p>
<p>$$
L = \frac{1}{n} \sum_i (z_i - \hat{z_i})^2
$$</p>
<p>それでは，前回と同じ2入力・1出力の単純パーセプトロンを作成します．
活性化関数にはシグモイド関数を採用します．</p>
<p><a href="https://gyazo.com/f91bcd6ecf9e7f301b49fa3b947bff75"><img src="https://i.gyazo.com/f91bcd6ecf9e7f301b49fa3b947bff75.png" alt="Image from Gyazo"></a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 単純パーセプトロン</span>
</span></span><span style="display:flex;"><span>network <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>    nn<span style="color:#f92672">.</span>Sigmoid()
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>print(network)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Sequential(
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">0</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>  (<span style="color:#ae81ff">1</span>): Sigmoid()
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>学習データをパーセプトロンに入力し，出力を確認してみます．
パーセプトロンの重みやバイアスはランダムな値で初期化されているため，
正解の出力とは大きく異ることが分かります．
例えば，$(0.28, 0.34)$を入力すると，$0.4417$が出力されています（正解の出力は$0$）．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>z <span style="color:#f92672">=</span> network(x)
</span></span><span style="display:flex;"><span>z <span style="color:#f92672">=</span> z<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>] <span style="color:#75715e"># リストに変形</span>
</span></span><span style="display:flex;"><span>print(z)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor([<span style="color:#ae81ff">0.4417</span>, <span style="color:#ae81ff">0.4198</span>, <span style="color:#ae81ff">0.4390</span>, <span style="color:#ae81ff">0.4758</span>, <span style="color:#ae81ff">0.4533</span>, <span style="color:#ae81ff">0.4696</span>],
</span></span><span style="display:flex;"><span>       grad_fn<span style="color:#f92672">=&lt;</span>SelectBackward<span style="color:#f92672">&gt;</span>)	   
</span></span></code></pre></div><p>平均2乗誤差の計算グラフを<code>nn.MSELoss()</code>で作成します．
この計算グラフにパーセプトロンの出力$z$と，正しい出力$\hat{z}$(ここでは<code>label</code>)を与えると，
平均2乗誤差は$0.2365$と計算されました．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MSELoss()
</span></span><span style="display:flex;"><span>loss <span style="color:#f92672">=</span> criterion(z, label)
</span></span><span style="display:flex;"><span>print(loss)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor(<span style="color:#ae81ff">0.2365</span>, grad_fn<span style="color:#f92672">=&lt;</span>MseLossBackward<span style="color:#f92672">&gt;</span>)
</span></span></code></pre></div><p>公式に従って計算し，上記の値が正しいか確認してみましょう．
平均2乗誤差は$0.2365$となり，一致していることが分かります．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(torch<span style="color:#f92672">.</span>sum((z <span style="color:#f92672">-</span> label) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">6</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor(<span style="color:#ae81ff">0.2365</span>, grad_fn<span style="color:#f92672">=&lt;</span>DivBackward0<span style="color:#f92672">&gt;</span>)
</span></span></code></pre></div><h2 id="勾配降下法">勾配降下法</h2>
<p>平均2乗誤差で表された損失関数$L$を微分（偏微分）し，
パーセプトロンの重み$(w_1, w_2)$やバイアス$(w_0)$に応じた <strong>傾き（勾配）</strong> を求めます．</p>
<p>$$
\frac{dL}{dw_0}, \frac{dL}{dw_1}, \frac{dL}{dw_2}
$$</p>
<p>正しい出力$\hat{z}$を得るために，導出した傾きに応じて重みやバイアスを微調整します．
この方法は <strong>勾配降下法</strong> と呼ばれます．</p>
<p>平均2乗誤差の計算グラフを<code>backward()</code>で微分します．
導出された傾きは下記のようになりました．</p>
<p>$$
\frac{dL}{dw_0} = -0.0264 \\
\frac{dL}{dw_1} = -0.0787 \\
\frac{dL}{dw_2} = -0.0788
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight) <span style="color:#75715e"># 重みw1、w2</span>
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>grad) <span style="color:#75715e"># 重みの偏微分　dL/dw1 dL/dw2</span>
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias) <span style="color:#75715e"># バイアス w0</span>
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>grad) <span style="color:#75715e"># バイアスの偏微分 dL/dw0</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Parameter containing:
</span></span><span style="display:flex;"><span>tensor([[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2890</span>,  <span style="color:#ae81ff">0.5321</span>]], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>tensor([[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.0787</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">0.0788</span>]])
</span></span><span style="display:flex;"><span>Parameter containing:
</span></span><span style="display:flex;"><span>tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.3343</span>], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.0264</span>])
</span></span></code></pre></div><p>導出した傾きに応じてパーセプトロンの重みやバイアスを下記の更新式に従って微調整します．
ここで，$\alpha=0.1$は <strong>学習率</strong> と呼ばれるパラメータで，学習の収束をコントールする役割を担っています．
この微調整により損失関数$L$を最小化することができます．</p>
<p>$$
w_0 = w_0 - \alpha \cdot \frac{dL}{dw_0} \\
w_1 = w_1 - \alpha \cdot \frac{dL}{dw_1} \\
w_2 = w_2 - \alpha \cdot \frac{dL}{dw_2}
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update</span>():
</span></span><span style="display:flex;"><span>    alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
</span></span><span style="display:flex;"><span>    weight <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight <span style="color:#f92672">-</span> alpha <span style="color:#f92672">*</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>grad
</span></span><span style="display:flex;"><span>    bias <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias <span style="color:#f92672">-</span> alpha <span style="color:#f92672">*</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>grad
</span></span><span style="display:flex;"><span>    network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> weight
</span></span><span style="display:flex;"><span>    network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> bias
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>update()
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Parameter containing:
</span></span><span style="display:flex;"><span>tensor([[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2811</span>,  <span style="color:#ae81ff">0.5399</span>]], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>Parameter containing:
</span></span><span style="display:flex;"><span>tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.3317</span>], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><p>それでは，1000回繰り返して重みとバイアスの更新を行います．
この結果，重みとバイアスは下記の値に収束しました．</p>
<p>$$
w_0 = -130.2439 \\
w_1 = 117.0642 \\
w_2 = 122.1144
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>loss_history <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>    z <span style="color:#f92672">=</span> network(x)
</span></span><span style="display:flex;"><span>    z <span style="color:#f92672">=</span> z<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MSELoss()
</span></span><span style="display:flex;"><span>    loss <span style="color:#f92672">=</span> criterion(z, label)
</span></span><span style="display:flex;"><span>    loss_history<span style="color:#f92672">.</span>append(loss<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    update()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight)
</span></span><span style="display:flex;"><span>print(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>Parameter containing:
</span></span><span style="display:flex;"><span>tensor([[<span style="color:#ae81ff">117.0642</span>, <span style="color:#ae81ff">122.1144</span>]], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>Parameter containing:
</span></span><span style="display:flex;"><span>tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">130.2439</span>], requires_grad<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><p>更新の過程における損失$L$（平均2乗誤差）の推移を可視化してみましょう．
100回程度の繰り返しで，$L \simeq 0$に収束していることが確認できます．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(loss_history)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;steps&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;loss&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/15339ad568810cd1f7544daa986521d7"><img src="https://i.gyazo.com/15339ad568810cd1f7544daa986521d7.png" alt="Image from Gyazo"></a></p>
<p>学習したパーセプトロンが正しく分類できているか確認しましょう．
前方の3つのサンプルの出力は$0$，後方の3つのサンプルの出力は$1$になっていることが確認できます．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>z <span style="color:#f92672">=</span> network(x)
</span></span><span style="display:flex;"><span>z <span style="color:#f92672">=</span> z<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(z)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#出力</span>
</span></span><span style="display:flex;"><span>tensor([<span style="color:#ae81ff">5.0410e-25</span>, <span style="color:#ae81ff">2.3279e-28</span>, <span style="color:#ae81ff">9.1925e-16</span>, <span style="color:#ae81ff">1.0000e+00</span>, <span style="color:#ae81ff">1.0000e+00</span>, <span style="color:#ae81ff">1.0000e+00</span>],
</span></span><span style="display:flex;"><span>       grad_fn<span style="color:#f92672">=&lt;</span>SelectBackward<span style="color:#f92672">&gt;</span>)
</span></span></code></pre></div><p>最後に決定境界を求めてみましょう．
途中出力$y$が$0$のときに決定境界となるため下記の式を解きます（シグモイド関数の出力が$0.5$のとき）．
導出された式は2つのカテゴリを分ける直線となっていることが分かります．</p>
<p>$$
0 = w_1 \cdot x_1 + w_2 \cdot x_2 + w_0 \\
x_2 = -\frac{w_1}{w_2} x_1 - \frac{w_0}{w_2}
$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>x_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">0.01</span>)
</span></span><span style="display:flex;"><span>y_ <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>w0 <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>w1 <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>w2 <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_:
</span></span><span style="display:flex;"><span>    y_<span style="color:#f92672">.</span>append(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">*</span> (w1 <span style="color:#f92672">/</span> w2) <span style="color:#f92672">*</span> x <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">*</span> (w0 <span style="color:#f92672">/</span> w2))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(x_, y_)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x1, x2, c<span style="color:#f92672">=</span>label)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x1&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;x2&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/604a316cdcfcf713f7fd797d5a556895"><img src="https://i.gyazo.com/604a316cdcfcf713f7fd797d5a556895.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>

<p>Google Colaboratoryで作成した <strong>chapter3.ipynb</strong> を保存し，
<strong>共有用のリンク</strong> と <strong>ノートブック（.ipynb）</strong> をダウンロードして提出してください．
提出の前に必ず下記の設定を行ってください．</p>
<ul>
<li>ノートブックの設定で「セルの出力を除外する」のチェックを外す</li>
<li>ノートブックの変更内容を保存して固定</li>
<li>共有設定で「学校法人椙山女学園大学」を「閲覧者」に設定</li>
</ul>
<h3>参考書籍</h3>








<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07GWHP9YM&linkId=08226226a8fb428fe7bc7d48e47ff8a0&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07FVJKP1L&linkId=9f5d740609362f2de596d41b9b060b30&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07VPDVNKW&linkId=ab58ead321f3b247b4b658408f167d43&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07SPZ4Z82&linkId=dcc9a4aec3676eac587eb38f0412ccdd&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter3/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
