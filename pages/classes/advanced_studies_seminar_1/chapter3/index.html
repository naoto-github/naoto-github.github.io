<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    パーセプトロンの学習 | MLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  
  
  
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="MLAB" />

  
  <link href="https://fonts.googleapis.com/css?family=M+PLUS+Rounded+1c:500&amp;subset=japanese" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">

  
  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v6.0"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  <meta property="og:title" content="パーセプトロンの学習" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter3/" />



  <meta property="og:image" content="https://i.gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c.png" />



  <meta property="og:site_name" content="MLAB" />



  <meta property="og:description" content="自動微分  PyTorchでは 自動微分 という機能が実装されており， テンソルで作成した式（ 計算グラフ と呼ぶ）の傾き（勾配）が保持されます． この自動微分はパーセプトロンの重みやバイアスの学習に欠かせない機能です．
ノートブックを作成し，ノートブックのタイトルをNN-3 に設定します． まずは，PyTorch，Numpy，Matplotlibをインポートします．
import torch import torch.nn as nn import numpy as np import matplotlib.pyplot as plt テンソルxを2.0で初期化します． このxを自動微分の対象とするためrequires_grad=Trueをオプションとして設定します．
x = torch.tensor([2.0], requires_grad=True) # x=2 print(x) #出力 tensor([2.], requires_grad=True) 定義したxを用いて計算グラフyを定義します． ここで，$x=2$であるため，$y=9$となります．
$$ y = x^2 &#43; 2x &#43; 1 $$
y = x * x &#43; 2 * x &#43; 1 print(y) #出力 tensor([9.], grad_fn=&lt;AddBackward0&gt;) yをxで微分します． 計算グラフが複数のテンソルで構成される場合は， 全てのテンソルに対する偏微分が計算されます． ここで，$x=2$であるため，$\frac{dy}{dx}=6$となります．" />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="パーセプトロンの学習" />



  <meta name="twitter:description" content="自動微分  PyTorchでは 自動微分 という機能が実装されており， テンソルで作成した式（ 計算グラフ と呼ぶ）の傾き（勾配）が保持されます． この自動微分はパーセプトロンの重みやバイアスの学習に欠かせない機能です．
ノートブックを作成し，ノートブックのタイトルをNN-3 に設定します． まずは，PyTorch，Numpy，Matplotlibをインポートします．
import torch import torch.nn as nn import numpy as np import matplotlib.pyplot as plt テンソルxを2.0で初期化します． このxを自動微分の対象とするためrequires_grad=Trueをオプションとして設定します．
x = torch.tensor([2.0], requires_grad=True) # x=2 print(x) #出力 tensor([2.], requires_grad=True) 定義したxを用いて計算グラフyを定義します． ここで，$x=2$であるため，$y=9$となります．
$$ y = x^2 &#43; 2x &#43; 1 $$
y = x * x &#43; 2 * x &#43; 1 print(y) #出力 tensor([9.], grad_fn=&lt;AddBackward0&gt;) yをxで微分します． 計算グラフが複数のテンソルで構成される場合は， 全てのテンソルに対する偏微分が計算されます． ここで，$x=2$であるため，$\frac{dy}{dx}=6$となります．" />



  <meta name="twitter:image" content="https://i.gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c.png" />



</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    <p class="nav-info">Mukai's Lab. at Sugiyama Women's University</p>    
    <a href="/">
    <h2 class="nav-title">
	     <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
	     <span>MLAB</span>
        

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/pages/classes/">授業資料</a>
  </li>
  
  
  
  <li>
    <a href="/pages/tech/">技術メモ</a>
  </li>
  
  
  <li>	
    <a href="https://sites.google.com/g.sugiyama-u.ac.jp/mlab?pli=1&authuser=1" target="_blank">学内専用</a>
  </li>  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    <div class="post-info">
  <span>written by</span>
  Naoto Mukai
  
  
  
  <span>on&nbsp;</span><time datetime="2020-06-30 22:05:29 &#43;0900 JST">June 30, 2020</time>
</div>

    <h1 class="post-title">パーセプトロンの学習</h1>
<div class="post-line"></div>

    

    <p><a href="https://gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c"><img src="https://i.gyazo.com/43dd58c62580a2ce4c9e99f22924aa5c.png" alt="Image from Gyazo"></a></p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  自動微分
</h1>

<p>PyTorchでは <strong>自動微分</strong> という機能が実装されており，
テンソルで作成した式（ <strong>計算グラフ</strong> と呼ぶ）の傾き（勾配）が保持されます．
この自動微分はパーセプトロンの重みやバイアスの学習に欠かせない機能です．</p>
<p>ノートブックを作成し，ノートブックのタイトルを<strong>NN-3</strong> に設定します．
まずは，PyTorch，Numpy，Matplotlibをインポートします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch
<span style="color:#f92672">import</span> torch.nn <span style="color:#f92672">as</span> nn
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
</code></pre></div><p>テンソル<code>x</code>を2.0で初期化します．
この<code>x</code>を自動微分の対象とするため<code>requires_grad=True</code>をオプションとして設定します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">2.0</span>], requires_grad<span style="color:#f92672">=</span>True) <span style="color:#75715e"># x=2</span>
<span style="color:#66d9ef">print</span>(x)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([<span style="color:#ae81ff">2.</span>], requires_grad<span style="color:#f92672">=</span>True)
</code></pre></div><p>定義した<code>x</code>を用いて計算グラフ<code>y</code>を定義します．
ここで，$x=2$であるため，$y=9$となります．</p>
<p>$$
y = x^2 + 2x + 1
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y <span style="color:#f92672">=</span> x <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
<span style="color:#66d9ef">print</span>(y)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([<span style="color:#ae81ff">9.</span>], grad_fn<span style="color:#f92672">=&lt;</span>AddBackward0<span style="color:#f92672">&gt;</span>)
</code></pre></div><p><code>y</code>を<code>x</code>で微分します．
計算グラフが複数のテンソルで構成される場合は，
全てのテンソルに対する偏微分が計算されます．
ここで，$x=2$であるため，$\frac{dy}{dx}=6$となります．</p>
<p>$$
\frac{dy}{dx} = 2x + 2
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y<span style="color:#f92672">.</span>backward() <span style="color:#75715e">#微分</span>
<span style="color:#66d9ef">print</span>(f<span style="color:#e6db74">&#34;dy/dx = {x.grad}&#34;</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
dy<span style="color:#f92672">/</span>dx <span style="color:#f92672">=</span> tensor([<span style="color:#ae81ff">6.</span>])
</code></pre></div><p>図で確認してみましょう．
微分は接線の傾きを求める操作です．
$y = x^2 + 2x + 1$の$x=2$における接線の傾きが$6$となります．</p>
<p><a href="https://gyazo.com/9e120824a1ab92d5d8a80f55914d1282"><img src="https://i.gyazo.com/9e120824a1ab92d5d8a80f55914d1282.png" alt="Image from Gyazo"></a></p>
<h1>
  <img class="head-image" src="/logo/logo.png">
  パーセプトロンの学習
</h1>

<h2 id="分類問題">分類問題</h2>
<p>パーセプトロンは <strong>分類</strong> や <strong>回帰</strong> と呼ばれる問題を解くことができます．
ここでは，サンプル$x=(x_1, x_2)$を2つのカテゴリ(0または1)に分類することに挑戦します．</p>
<p>例えば，リストの最初にある$(0.28, 0.34)$はカテゴリ$0$に分類されます．
同様にリストの最後の$(0.94, 0.91)$はカテゴリ$1$に分類されます．
このサンプルをパーセプトロンに学習させることで，任意のサンプルに対するカテゴリを推定します．
このようなサンプルデータは <strong>学習データ（教師データ，訓練データ）</strong> と呼ばれます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x1 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0.28</span>, <span style="color:#ae81ff">0.35</span>, <span style="color:#ae81ff">0.41</span>, <span style="color:#ae81ff">0.78</span>, <span style="color:#ae81ff">0.89</span>, <span style="color:#ae81ff">0.94</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
x2 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0.34</span>, <span style="color:#ae81ff">0.21</span>, <span style="color:#ae81ff">0.39</span>, <span style="color:#ae81ff">0.87</span>, <span style="color:#ae81ff">0.76</span>, <span style="color:#ae81ff">0.91</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack([x1, x2], <span style="color:#ae81ff">1</span>) <span style="color:#75715e">#入力</span>
label <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)  <span style="color:#75715e">#正解の出力</span>
<span style="color:#66d9ef">print</span>(x)
<span style="color:#66d9ef">print</span>(label)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([[<span style="color:#ae81ff">0.2800</span>, <span style="color:#ae81ff">0.3400</span>],
        [<span style="color:#ae81ff">0.3500</span>, <span style="color:#ae81ff">0.2100</span>],
        [<span style="color:#ae81ff">0.4100</span>, <span style="color:#ae81ff">0.3900</span>],
        [<span style="color:#ae81ff">0.7800</span>, <span style="color:#ae81ff">0.8700</span>],
        [<span style="color:#ae81ff">0.8900</span>, <span style="color:#ae81ff">0.7600</span>],
        [<span style="color:#ae81ff">0.9400</span>, <span style="color:#ae81ff">0.9100</span>]])
tensor([<span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">1.</span>])
</code></pre></div><p>学習データを可視化してみます．
左下の3つのサンプルがカテゴリ$0$，右上の3つのサンプルがカテゴリ$1$です．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>scatter(x1, x2, c<span style="color:#f92672">=</span>label)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x1&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y2&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/88cf1322f04c1beaa2d550f5e2a93d66"><img src="https://i.gyazo.com/88cf1322f04c1beaa2d550f5e2a93d66.png" alt="Image from Gyazo"></a></p>
<h2 id="損失関数誤差関数">損失関数（誤差関数）</h2>
<p>パーセプトロンに学習データを用いて <strong>学習</strong> させるには，
パーセプトロンの出力$z$と正しい出力（ここでは$0$または$1$）との
誤差を測る必要があります．</p>
<p>この誤差を測るための関数は <strong>損失関数（誤差関数）</strong> と呼ばれます．
損失関数には下記のような種類があります．</p>
<ul>
<li>平均2乗誤差(Mean Square Error : MSE)</li>
<li>交差エントロピー(Cross Entropy : CE)</li>
</ul>
<p>ここでは下記の式で表される平均2乗誤差を採用します．
ここで，$z_i$は$i$番目のパーセプトロンの出力，$\hat{z_i}$は正しい出力です．
また，$n$は学習データのサンプル数です．</p>
<p>$$
MSE = \frac{1}{n} \sum_i (z_i - \hat{z_i})^2
$$</p>
<p>それでは，2入力・1出力の単純パーセプトロンを作成します．
活性化関数にはシグモイド関数を採用します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 単純パーセプトロン</span>
network <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>),
    nn<span style="color:#f92672">.</span>Sigmoid()
)
<span style="color:#66d9ef">print</span>(network)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Sequential(
  (<span style="color:#ae81ff">0</span>): Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, bias<span style="color:#f92672">=</span>True)
  (<span style="color:#ae81ff">1</span>): Sigmoid()
)
</code></pre></div><p>学習データをパーセプトロンに入力し，出力を確認してみます．
パーセプトロンの重みやバイアスはランダムな値で初期化されているため，
正解の出力とは大きく異ることが分かります．
例えば，$(0.28, 0.34)$を入力すると，$0.4417$が出力されています（正解の出力は$0$）．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">z <span style="color:#f92672">=</span> network(x)
z <span style="color:#f92672">=</span> z<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>] <span style="color:#75715e"># リストに変形</span>
<span style="color:#66d9ef">print</span>(z)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([<span style="color:#ae81ff">0.4417</span>, <span style="color:#ae81ff">0.4198</span>, <span style="color:#ae81ff">0.4390</span>, <span style="color:#ae81ff">0.4758</span>, <span style="color:#ae81ff">0.4533</span>, <span style="color:#ae81ff">0.4696</span>],
       grad_fn<span style="color:#f92672">=&lt;</span>SelectBackward<span style="color:#f92672">&gt;</span>)	   
</code></pre></div><p>平均2乗誤差の計算グラフを<code>nn.MSELoss()</code>で作成します．
この計算グラフにパーセプトロンの出力$z$と，正しい出力$\hat{z}$(ここでは<code>label</code>)を与えると，
平均2乗誤差は$0.2365$と計算されました．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MSELoss()
loss <span style="color:#f92672">=</span> criterion(z, label)
<span style="color:#66d9ef">print</span>(loss)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor(<span style="color:#ae81ff">0.2365</span>, grad_fn<span style="color:#f92672">=&lt;</span>MseLossBackward<span style="color:#f92672">&gt;</span>)

</code></pre></div><p>公式に従って計算し，上記の値が正しいか確認してみましょう．
平均2乗誤差は$0.2365$となり，一致していることが分かります．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(torch<span style="color:#f92672">.</span>sum((z <span style="color:#f92672">-</span> label) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> <span style="color:#ae81ff">6</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor(<span style="color:#ae81ff">0.2365</span>, grad_fn<span style="color:#f92672">=&lt;</span>DivBackward0<span style="color:#f92672">&gt;</span>)
</code></pre></div><h2 id="勾配降下法">勾配降下法</h2>
<p>平均2乗誤差$L$を微分（偏微分）し，
パーセプトロンの重み$(w_1, w_2)$やバイアス$(w_0)$に応じた <strong>傾き（勾配）</strong> を求めます．</p>
<p>$$
\frac{dL}{dw_0}, \frac{dL}{dw_1}, \frac{dL}{dw_2}
$$</p>
<p>正しい出力$\hat{z}$を得るために，導出した傾きに応じて重みやバイアスを微調整します．
この方法は <strong>勾配降下法</strong> と呼ばれます．</p>
<p>平均2乗誤差の計算グラフを<code>backward()</code>で微分します．
導出された傾きは下記のようになりました．</p>
<p>$$
\frac{dL}{dw_0} = -0.0264 \\<br>
\frac{dL}{dw_1} = -0.0787 \\<br>
\frac{dL}{dw_2} = -0.0788
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loss<span style="color:#f92672">.</span>backward()
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>grad)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>grad)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Parameter containing:
tensor([[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2890</span>,  <span style="color:#ae81ff">0.5321</span>]], requires_grad<span style="color:#f92672">=</span>True)
tensor([[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.0787</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">0.0788</span>]])
Parameter containing:
tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.3343</span>], requires_grad<span style="color:#f92672">=</span>True)
tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.0264</span>])
</code></pre></div><p>導出した傾きに応じてパーセプトロンの重みやバイアスを下記の更新式に従って微調整します．
ここで，$\alpha=0.1$は <strong>学習率</strong> と呼ばれるパラメータで，学習の収束をコントールする役割を担っています．
この微調整により平均2乗誤差$L$を最小化することができます．</p>
<p>$$
w_0 = w_0 - \alpha \cdot \frac{dL}{dw_0} \\<br>
w_1 = w_1 - \alpha \cdot \frac{dL}{dw_1} \\<br>
w_2 = w_2 - \alpha \cdot \frac{dL}{dw_2}
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">update</span>():
    alpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
    weight <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight <span style="color:#f92672">-</span> alpha <span style="color:#f92672">*</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>grad
    bias <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias <span style="color:#f92672">-</span> alpha <span style="color:#f92672">*</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>grad
    network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">=</span> weight
    network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data <span style="color:#f92672">=</span> bias

update()
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Parameter containing:
tensor([[<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2811</span>,  <span style="color:#ae81ff">0.5399</span>]], requires_grad<span style="color:#f92672">=</span>True)
Parameter containing:
tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.3317</span>], requires_grad<span style="color:#f92672">=</span>True)
</code></pre></div><p>それでは，1000回繰り返して重みとバイアスの更新を行います．
この結果，重みとバイアスは下記の値に収束しました．</p>
<p>$$
w_0 = -130.2439 \\<br>
w_1 = 117.0642 \\<br>
w_2 = 122.1144
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loss_history <span style="color:#f92672">=</span> []

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1000</span>):
    z <span style="color:#f92672">=</span> network(x)
    z <span style="color:#f92672">=</span> z<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]

    criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MSELoss()
    loss <span style="color:#f92672">=</span> criterion(z, label)
    loss_history<span style="color:#f92672">.</span>append(loss<span style="color:#f92672">.</span>data)

    loss<span style="color:#f92672">.</span>backward()

    update()

<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight)
<span style="color:#66d9ef">print</span>(network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
Parameter containing:
tensor([[<span style="color:#ae81ff">117.0642</span>, <span style="color:#ae81ff">122.1144</span>]], requires_grad<span style="color:#f92672">=</span>True)
Parameter containing:
tensor([<span style="color:#f92672">-</span><span style="color:#ae81ff">130.2439</span>], requires_grad<span style="color:#f92672">=</span>True)
</code></pre></div><p>更新の過程における損失（平均2乗誤差）の推移を可視化してみましょう．
100回程度の繰り返しで，$MSE \simeq 0$に収束していることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>plot(loss_history)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;steps&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;loss&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/15339ad568810cd1f7544daa986521d7"><img src="https://i.gyazo.com/15339ad568810cd1f7544daa986521d7.png" alt="Image from Gyazo"></a></p>
<p>学習したパーセプトロンが正しく分類できているか確認しましょう．
前方の3つのサンプルの出力は$0$，後方の3つのサンプルの出力は$1$になっていることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">z <span style="color:#f92672">=</span> network(x)
z <span style="color:#f92672">=</span> z<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">0</span>]
<span style="color:#66d9ef">print</span>(z)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#出力</span>
tensor([<span style="color:#ae81ff">5.0410e-25</span>, <span style="color:#ae81ff">2.3279e-28</span>, <span style="color:#ae81ff">9.1925e-16</span>, <span style="color:#ae81ff">1.0000e+00</span>, <span style="color:#ae81ff">1.0000e+00</span>, <span style="color:#ae81ff">1.0000e+00</span>],
       grad_fn<span style="color:#f92672">=&lt;</span>SelectBackward<span style="color:#f92672">&gt;</span>)
</code></pre></div><p>最後に決定境界を求めてみましょう．
途中出力$y$が$0$のときに決定境界となるため下記の式を解きます（シグモイド関数の出力が$0.5$のとき）．
導出された式は2つのカテゴリを分ける直線となっていることが分かります．</p>
<p>$$
0 = w_1 \cdot x_1 + w_2 \cdot x_2 + w_0 \\<br>
x_2 = -\frac{w_1}{w_2} x_1 - \frac{w_0}{w_2}
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x_ <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">0.01</span>)
y_ <span style="color:#f92672">=</span> []

w0 <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>bias<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>]
w1 <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">0</span>]
w2 <span style="color:#f92672">=</span> network[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>weight<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>][<span style="color:#ae81ff">1</span>]

<span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_:
    y_<span style="color:#f92672">.</span>append(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">*</span> (w1 <span style="color:#f92672">/</span> w2) <span style="color:#f92672">*</span> x <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span> <span style="color:#f92672">*</span> (w0 <span style="color:#f92672">/</span> w2))

plt<span style="color:#f92672">.</span>plot(x_, y_)
plt<span style="color:#f92672">.</span>scatter(x1, x2, c<span style="color:#f92672">=</span>label)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x1&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;x2&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/604a316cdcfcf713f7fd797d5a556895"><img src="https://i.gyazo.com/604a316cdcfcf713f7fd797d5a556895.png" alt="Image from Gyazo"></a></p>
<h3>参考書籍</h3>








<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07GWHP9YM&linkId=08226226a8fb428fe7bc7d48e47ff8a0&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07FVJKP1L&linkId=9f5d740609362f2de596d41b9b060b30&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07VPDVNKW&linkId=ab58ead321f3b247b4b658408f167d43&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07SPZ4Z82&linkId=dcc9a4aec3676eac587eb38f0412ccdd&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>



    

    <div class="horizontal">

  
  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter3/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fmukai-lab.info%2Fwww%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
  
  
  <div style="padding: 6px; margin-top:1px">
    <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-show-count="false">Tweet</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
  </div>

  
  
</div>



  </div>

  <div class="pagination">
    <a href="/" class="top" ><span>Top</span></a>
    <a href='javascript:history.back()' class="top" style="margin-left: 30px"><span>Back</span></a>
  </div>

  

  
  

  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; <time datetime="2021-01-10 21:58:29.90322 &#43;0900 JST m=&#43;0.187561709">2021</time> Naoto Mukai. Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.</span>
  </div>
</footer>


    </body>
</html>
