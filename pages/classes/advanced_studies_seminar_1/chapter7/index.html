<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    深層学習のデータセット | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  
  <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  
  
  

  <meta property="og:title" content="深層学習のデータセット" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter7/" />



  <meta property="og:image" content="https://i.gyazo.com/55ca5cca5f64ac110f400770373ed474.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="データセットの紹介 TorchvisionにはCIFAR-10以外にも様々なデータセットが用意されています． ここでは，MNIST ，Fashion-MNIST ，KMNIST ，COCO ， Cityscapes を取り上げて紹介します．
import torchvision import matplotlib.pyplot as plt MNIST MNISTは 手書きの数字文字 のデータセットです． グレースケール画像で，サイズは$28 \times 28$です．
dataset = torchvision.datasets.MNIST(root=&#34;./data&#34;, download=True) image, label = dataset[0] print(label) plt.imshow(image, cmap=&#34;gray&#34;) Fashion-MNIST Fashion-MNISTは 衣服などの ファッション のデータセットです． グレースケール画像で，サイズは$28 \times 28$です．
dataset = torchvision.datasets.FashionMNIST(root=&#34;./data&#34;, download=True) image, label = dataset[0] print(label) plt.imshow(image, cmap=&#34;gray&#34;) KMNIST KMNISTは くずし字（ひらがなや漢字） のデータセットです． グレースケール画像で，サイズは$28 \times 28$です．
dataset = torchvision.datasets.KMNIST(root=&#34;./data&#34;, download=True) image, label = dataset[0] print(label) plt.imshow(image, cmap=&#34;gray&#34;) EMNIST EMNISTは，手書きアルファベット のデータセットです（spolit=&quot;letters&quot;を指定）． ラベル1がA，ラベル26がZを表します（0から始まらないことに注意）． グレースケール画像で，サイズは$28 \times 28$です．" />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="深層学習のデータセット" />



  <meta name="twitter:description" content="データセットの紹介 TorchvisionにはCIFAR-10以外にも様々なデータセットが用意されています． ここでは，MNIST ，Fashion-MNIST ，KMNIST ，COCO ， Cityscapes を取り上げて紹介します．
import torchvision import matplotlib.pyplot as plt MNIST MNISTは 手書きの数字文字 のデータセットです． グレースケール画像で，サイズは$28 \times 28$です．
dataset = torchvision.datasets.MNIST(root=&#34;./data&#34;, download=True) image, label = dataset[0] print(label) plt.imshow(image, cmap=&#34;gray&#34;) Fashion-MNIST Fashion-MNISTは 衣服などの ファッション のデータセットです． グレースケール画像で，サイズは$28 \times 28$です．
dataset = torchvision.datasets.FashionMNIST(root=&#34;./data&#34;, download=True) image, label = dataset[0] print(label) plt.imshow(image, cmap=&#34;gray&#34;) KMNIST KMNISTは くずし字（ひらがなや漢字） のデータセットです． グレースケール画像で，サイズは$28 \times 28$です．
dataset = torchvision.datasets.KMNIST(root=&#34;./data&#34;, download=True) image, label = dataset[0] print(label) plt.imshow(image, cmap=&#34;gray&#34;) EMNIST EMNISTは，手書きアルファベット のデータセットです（spolit=&quot;letters&quot;を指定）． ラベル1がA，ラベル26がZを表します（0から始まらないことに注意）． グレースケール画像で，サイズは$28 \times 28$です．" />



  <meta name="twitter:image" content="https://i.gyazo.com/55ca5cca5f64ac110f400770373ed474.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    
    <h1 class="post-title">深層学習のデータセット</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/55ca5cca5f64ac110f400770373ed474"><img src="https://i.gyazo.com/55ca5cca5f64ac110f400770373ed474.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  データセットの紹介
</h1>

<p>Torchvisionには<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>以外にも様々な<a href="https://pytorch.org/docs/stable/torchvision/datasets.html">データセット</a>が用意されています．
ここでは，<strong>MNIST</strong> ，<strong>Fashion-MNIST</strong> ，<strong>KMNIST</strong> ，<strong>COCO</strong> ， <strong>Cityscapes</strong> を取り上げて紹介します．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span></code></pre></div><h2 id="mnist">MNIST</h2>
<p><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>は <strong>手書きの数字文字</strong> のデータセットです．
グレースケール画像で，サイズは$28 \times 28$です．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>MNIST(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(label)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(image, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gray&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/d44f447952ce627aa20297e8e190b836"><img src="https://i.gyazo.com/d44f447952ce627aa20297e8e190b836.png" alt="Image from Gyazo"></a></p>
<h2 id="fashion-mnist">Fashion-MNIST</h2>
<p><a href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a>は
衣服などの <strong>ファッション</strong> のデータセットです．
グレースケール画像で，サイズは$28 \times 28$です．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>FashionMNIST(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(label)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(image, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gray&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/045a700957e6cb561e5714e86501525f"><img src="https://i.gyazo.com/045a700957e6cb561e5714e86501525f.png" alt="Image from Gyazo"></a></p>
<h2 id="kmnist">KMNIST</h2>
<p><a href="https://github.com/rois-codh/kmnist">KMNIST</a>は <strong>くずし字（ひらがなや漢字）</strong> のデータセットです．
グレースケール画像で，サイズは$28 \times 28$です．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>KMNIST(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(label)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(image, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gray&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/ab408ddd45c9e52513986ebd2767e162"><img src="https://i.gyazo.com/ab408ddd45c9e52513986ebd2767e162.png" alt="Image from Gyazo"></a></p>
<h2 id="emnist">EMNIST</h2>
<p><a href="https://www.nist.gov/itl/products-and-services/emnist-dataset">EMNIST</a>は，<strong>手書きアルファベット</strong> のデータセットです（<code>spolit=&quot;letters&quot;</code>を指定）．
ラベル<code>1</code>が<code>A</code>，ラベル<code>26</code>が<code>Z</code>を表します（<code>0</code>から始まらないことに注意）．
グレースケール画像で，サイズは$28 \times 28$です．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>EMNIST(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, split<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;letters&#34;</span>, download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>image, label <span style="color:#f92672">=</span> dataset[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>print(label)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>imshow(image, cmap<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gray&#34;</span>)
</span></span></code></pre></div><p><a href="https://gyazo.com/2481cd0f9fed71fcc19c2342d46587fe"><img src="https://i.gyazo.com/2481cd0f9fed71fcc19c2342d46587fe.png" alt="Image from Gyazo"></a></p>
<h2 id="coco">COCO</h2>
<p><a href="https://cocodataset.org/">COCO</a>は物体検出やセグメンテーションなどに利用されるデータセットです．
33万枚以上の画像で構成され，80種類のラベルが存在します．
画像のアノテーションはJSON形式で配布されています．</p>
<h2 id="cityscapes">Cityscapes</h2>
<p><a href="https://www.cityscapes-dataset.com/">Cityscapes</a>は，人や車両のセグメンテーションなどに利用されるデータセットです．
50の市街における5000枚の高精度なアノテーション付きの画像と，20000枚の粗いアノテーション付きの画像が提供されます．</p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>

<p>Google Colaboratoryで，任意のデータセットを，
畳み込みニューラルネットワークで学習し，学習データに対する正解率を算出してください．
下記はMNISTの手書き数字文字のデータセットの例です（「0」，「1」，「2」の3種類のみを対象）．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># データセットの読込（Tensor）</span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>MNIST(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data&#34;</span>, transform<span style="color:#f92672">=</span>transforms<span style="color:#f92672">.</span>ToTensor())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 0,1,2のみを対象とする</span>
</span></span><span style="display:flex;"><span>my_dataset <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> image, label <span style="color:#f92672">in</span> dataset:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">or</span> label <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>:
</span></span><span style="display:flex;"><span>        my_dataset<span style="color:#f92672">.</span>append((image, label))
</span></span></code></pre></div><p>手書き数字画像はグレースケール（1次元）であり，そのサイズは$28 \times 28$であることに注意してください．
畳み込みニューラルネットワークは次のように定義すると良いです（最初の畳み込み層の入力チャネルが$1$，全結合層の入力数は$16 \times 4 \times 4=256$）．</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 画像はグレースケール（1次元）</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 画像サイズ 28x28 -&gt; 24x24 -&gt;12x12 -&gt; 8x8 -&gt; 4x4</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Net</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        super(Net, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">6</span>, (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>)) <span style="color:#75715e">#入力チャネル，出力チャネル，フィルタサイズ</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">16</span>, (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>)) <span style="color:#75715e">#入力チャネル，出力チャネル，フィルタサイズ</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">16</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">64</span>) <span style="color:#75715e">#入力数，出力数</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>) <span style="color:#75715e">#入力数，出力数</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>max_pool2d(F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>conv1(x)), <span style="color:#ae81ff">2</span>) <span style="color:#75715e">#2x2でMAXプーリング</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>max_pool2d(F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>conv2(x)), <span style="color:#ae81ff">2</span>) <span style="color:#75715e">#2x2でMAXプーリング</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">16</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span>) <span style="color:#75715e">#1次元に整形</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc1(x))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(self<span style="color:#f92672">.</span>fc2(x), dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>network <span style="color:#f92672">=</span> Net()
</span></span><span style="display:flex;"><span>print(network)
</span></span></code></pre></div><p>ノートブックのタイトルを<strong>chapter7.ipynb</strong> として保存し，
<strong>共有用のリンク</strong> と <strong>ノートブック（.ipynb）</strong> をダウンロードして提出してください．
提出の前に必ず下記の設定を行ってください．</p>
<ul>
<li>ノートブックの設定で「セルの出力を除外する」のチェックを外す</li>
<li>ノートブックの変更内容を保存して固定</li>
<li>共有設定で「学校法人椙山女学園大学」を「閲覧者」に設定</li>
</ul>
<h3>参考書籍</h3>








<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07GWHP9YM&linkId=08226226a8fb428fe7bc7d48e47ff8a0&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07FVJKP1L&linkId=9f5d740609362f2de596d41b9b060b30&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07VPDVNKW&linkId=ab58ead321f3b247b4b658408f167d43&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B07SPZ4Z82&linkId=dcc9a4aec3676eac587eb38f0412ccdd&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
    </iframe>

<!--
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  クラウド環境
</h1>


これまで深層学習の仕組みを学んできましたが，
最適化が必要な手法（損失関数，最適化関数など）や
パラメータ（重み，バイアス，学習率など）が多く存在することが分かりました．
これらは， **ハイパーパラメータ** と呼ばれ，
学習データと評価データを基に，試行錯誤を繰り返しながら決定するしか方法がなく，
調整に膨大な時間を必要とします．

深層学習の計算を短縮する一つの方法として，
**GPU(Graphics Processing Unit)** の利用があります．
一般にコンピュータの計算には **CPU(Central Processing Unit)** が用いられますが，
深層学習は単純な行列計算が多く，並列計算が得意なGPUの方が適しています．
[株式会社KABUKUの報告](https://www.kabuku.co.jp/developers/gpu-performance-for-deep-learning)では，
手書き文字データセットのMNISTに対する畳み込みニューラルネットワークの学習において，
CPUは1147.53秒，GPUは58.75sと約20倍の差があったことが示されています．

しかし，GPUは高価である上に，[CUDA(Compute Unified Device Architecture)](https://developer.nvidia.com/cuda-toolkit)などの
専用のツールキットを導入する必要があり，初学者にはハードルが高いです．
そこで，GPUが利用可能なクラウドサービスを利用してみましょう．
代表的なクラウドサービスは下記です．

- [Google Colaboratory](https://colab.research.google.com/)
- [Amazon Web Services](https://aws.amazon.com/jp/)
- [Microsoft Azure](https://azure.microsoft.com/)

この中でも，[Google Colaboratory](https://colab.research.google.com/)は特に注目です．
Jupyter Notebookと似た使用感であり，12時間まではGPUを無料で利用できます．
ブラウザ上で動作するウェブアプリであり，データをGoogle Driveに保存することも可能です．

<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  Google Colaboratoryで深層学習
</h1>


それでは，[Google Colaboratory](https://colab.research.google.com/)で
手書き文字データセットのMNISTの学習を試してみましょう．
Google Colaboratoryにアクセスしたら，**ランタイムのタイプを変更** をクリックし，
**ハードウェアアクセラレータ** を**GPU** に変更します( **None** はCPU)．

[![Image from Gyazo](https://i.gyazo.com/f0c6cbb51d736a43610b86d85fde9ff8.png)](https://gyazo.com/f0c6cbb51d736a43610b86d85fde9ff8)

まずはライブラリを導入します．
今回は計算時間を計測するため`time`ライブラリを追加します．

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import time
```

MNISTのデータセットをダウンロードします．
これを，そのままバッチサイズ$n=64$のミニバッチ学習に用います．

```python
dataset = torchvision.datasets.MNIST(root="./data", download=True, transform=transforms.ToTensor())
loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=64)
```

4層の畳み込みニューラルネットワークを定義します．
2層の畳み込み層と2層の結合層で構成されています．
最初の結合層の入力数は$16 \times 4 \times 4=256$です．
このとき，`to(device)`でGPUで計算することを宣言します．

```python
class Net(nn.Module):
	def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        self.fc1 = nn.Linear(16 * 4 * 4, 64)
        self.fc2 = nn.Linear(64, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, 16 * 4 * 4)
        x = F.relu(self.fc1(x))
        x = F.softmax(self.fc2(x), dim=1)
        return x

device = "cuda" if torch.cuda.is_available() else "cpu"
network = Net().to(device) #GPUで計算
```

損失関数は ソフトマックス交差エントロピー ， 最適化関数は Adam を採用します．

```python
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(network.parameters())
```
10エポックのミニバッチ学習を行い，計算時間を計測します．
ここでも，`images`と`labels`は`to(device)`でGPUで計算することを宣言します．

```python
loss_history = []

network.train() #学習モード

time_start = time.time()

for epoch in range(10):

    loss_epoch = 0

    for i, (images, labels) in enumerate(loader):

        images = images.to(device) #GPUで計算
        labels = labels.to(device) #GPUで計算

        optimizer.zero_grad()
        z = network(images)

        loss = criterion(z, labels)
        loss.backward()

        loss_epoch += loss.item()

        optimizer.step()

    print(f"{epoch} {loss_epoch / i}")
    loss_history.append(loss_epoch / i)

time_end = time.time()
elapsed_time = time_end - time_start
print(f"{elapsed_time:.2f} sec.")
```

CPUは **183.36秒** ，GPUは **96.55秒** となり，計算時間が約半分に短縮されることが確認できました．

```python
# 出力[CPUで計算]
0 1.7720158409283535
1 1.6003098847899138
2 1.5854766999899133
3 1.5807246369257044
4 1.5493033736339883
5 1.4842953522915265
6 1.4814846912595734
7 1.4795333463837776
8 1.4774807449847682
9 1.4766922878735602
183.36 sec.

# 出力[GPUで計算]
0 1.6751040738064045
1 1.591748113438821
2 1.5490432127817209
3 1.4937925009233848
4 1.4887989914658992
5 1.4852294785744862
6 1.4827559923031541
7 1.481329872488594
8 1.4796693687632345
9 1.4787192031693432
96.55 sec.
```

学習データに対する正解率を確認すると，98.56\%という非常に高い精度で分類できたことが分かります（評価用データではないことに注意）．

```python
counter = 0
for image, label in dataset:
    image = torch.unsqueeze(image, 0)
    image = image.to(device) #GPUで計算
    z = network(image)
    t = torch.argmax(z)
    counter = counter+1 if (t == label) else counter

acc = counter / len(dataset)
print(acc)
```

```python
#出力
0.9855666666666667
```
-->


    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/advanced_studies_seminar_1/chapter7/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
