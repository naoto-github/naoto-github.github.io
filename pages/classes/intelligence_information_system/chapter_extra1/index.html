<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    オーバーフィッティングと交差検証 | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  
  <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  
  
  

  <meta property="og:title" content="オーバーフィッティングと交差検証" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter_extra1/" />



  <meta property="og:image" content="https://i.gyazo.com/db7bf0839f23b52de8b31a4998ca3559.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="ノートブックの作成Colabにアクセスし，新規にノートブックを作成してください． また，numpy，matplotlib.pyplot，random，scikit-learn を導入しておいてください．
import numpy as np import matplotlib.pyplot as plt import random from sklearn.model_selection import KFold オーバーフィッティング（過学習）オーバーフィッティング とは 過学習 または 過剰適合 と呼ばれることもある現象で， サンプルデータに過剰に適合してしまい， データ全体に対しての汎用的な能力を失った状態を指します． ここでは，回帰問題を例に挙げて，オーバーフィッティングを再現してみましょう．
まずは，$x^3 - 2x$に従った40点のデータを生成します． これに，ノイズとなる乱数を加え，対象のデータ全体とします．
x = np.arange(-2, 2, 0.1) # 40点を生成 y = x ** 3 - 2* x r = np.random.rand(len(y)) * 2 # 乱数を生成 y = y &#43; r # 乱数を加算 data = np.stack([x, y]) plt.scatter(data[0], data[1]) plt." />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="オーバーフィッティングと交差検証" />



  <meta name="twitter:description" content="ノートブックの作成Colabにアクセスし，新規にノートブックを作成してください． また，numpy，matplotlib.pyplot，random，scikit-learn を導入しておいてください．
import numpy as np import matplotlib.pyplot as plt import random from sklearn.model_selection import KFold オーバーフィッティング（過学習）オーバーフィッティング とは 過学習 または 過剰適合 と呼ばれることもある現象で， サンプルデータに過剰に適合してしまい， データ全体に対しての汎用的な能力を失った状態を指します． ここでは，回帰問題を例に挙げて，オーバーフィッティングを再現してみましょう．
まずは，$x^3 - 2x$に従った40点のデータを生成します． これに，ノイズとなる乱数を加え，対象のデータ全体とします．
x = np.arange(-2, 2, 0.1) # 40点を生成 y = x ** 3 - 2* x r = np.random.rand(len(y)) * 2 # 乱数を生成 y = y &#43; r # 乱数を加算 data = np.stack([x, y]) plt.scatter(data[0], data[1]) plt." />



  <meta name="twitter:image" content="https://i.gyazo.com/db7bf0839f23b52de8b31a4998ca3559.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    
    <h1 class="post-title">オーバーフィッティングと交差検証</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/db7bf0839f23b52de8b31a4998ca3559"><img src="https://i.gyazo.com/db7bf0839f23b52de8b31a4998ca3559.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  ノートブックの作成
</h1>

<p>Colabにアクセスし，新規にノートブックを作成してください．
また，<strong>numpy</strong>，<strong>matplotlib.pyplot</strong>，<strong>random</strong>，<strong>scikit-learn</strong> を導入しておいてください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> random
<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> KFold
</code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  オーバーフィッティング（過学習）
</h1>

<p><strong>オーバーフィッティング</strong> とは
<strong>過学習</strong> または <strong>過剰適合</strong> と呼ばれることもある現象で，
サンプルデータに過剰に適合してしまい，
データ全体に対しての汎用的な能力を失った状態を指します．
ここでは，回帰問題を例に挙げて，オーバーフィッティングを再現してみましょう．</p>
<p>まずは，$x^3 - 2x$に従った40点のデータを生成します．
これに，ノイズとなる乱数を加え，対象のデータ全体とします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0.1</span>) <span style="color:#75715e"># 40点を生成</span>

y <span style="color:#f92672">=</span> x <span style="color:#f92672">**</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">2</span><span style="color:#f92672">*</span> x
r <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(len(y)) <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span> <span style="color:#75715e"># 乱数を生成</span>
y <span style="color:#f92672">=</span> y <span style="color:#f92672">+</span> r <span style="color:#75715e"># 乱数を加算</span>

data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([x, y])
plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/5d1b9055f3f0960c6f81bd7439d5d7bb"><img src="https://i.gyazo.com/5d1b9055f3f0960c6f81bd7439d5d7bb.png" alt="Image from Gyazo"></a></p>
<p>このデータ全体から，20点をランダムに抽出します．
これをサンプルデータとして回帰の学習に用いることにします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">sample <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(random<span style="color:#f92672">.</span>sample(list(data<span style="color:#f92672">.</span>transpose()), <span style="color:#ae81ff">20</span>))<span style="color:#f92672">.</span>transpose() <span style="color:#75715e"># 20点をランダム抽出</span>

plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
</code></pre></div><p><a href="https://gyazo.com/68290e04426dac731ffcb6c61844a13f"><img src="https://i.gyazo.com/68290e04426dac731ffcb6c61844a13f.png" alt="Image from Gyazo"></a></p>
<p>回帰式の係数の導出にはNumpyの<code>polyfit</code>を用います．
多項式回帰の次数$d$を変えて回帰式と2乗誤差を求めるため，
新たに<code>regression</code>という関数を定義します．
関数<code>regression</code>の返値は回帰式のY軸の値と2乗誤差のタプルです．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">regression</span>(data, sample, d): 
    w <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>polyfit(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>], d) <span style="color:#75715e">#回帰式の係数</span>
    
    y_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range((d<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)):
        y_ <span style="color:#f92672">+=</span> w[i] <span style="color:#f92672">*</span> (data[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">**</span> (d <span style="color:#f92672">-</span> i))
        
    e <span style="color:#f92672">=</span> sum((data[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> y_) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#75715e"># ２乗誤差</span>
    
    <span style="color:#66d9ef">return</span> y_, e
</code></pre></div><p>最初に次数$d=1$の回帰式（回帰直線）を求めます．
1本の直線で全体の傾向を近似していることがわかります．</p>
<!-- 2乗誤差は約80.1です． -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y, e <span style="color:#f92672">=</span> regression(data, sample, <span style="color:#ae81ff">1</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Error: &#34;</span> <span style="color:#f92672">+</span> str(e))

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], y)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/9548493f8d147a2cf16d0caeeda729ae"><img src="https://i.gyazo.com/9548493f8d147a2cf16d0caeeda729ae.png" alt="Image from Gyazo"></a></p>
<p>次に次数$d=3$の回帰式を求めます．
データにはノイズが加わっていますが，
真の関数である$x^3 - 2x$を，よく近似できていることがわかります．</p>
<!-- 2乗誤差は約11.4です． -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y, e <span style="color:#f92672">=</span> regression(data, sample, <span style="color:#ae81ff">3</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Error: &#34;</span> <span style="color:#f92672">+</span> str(e))

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], y)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/4f65ae5cc9c6b47b49d3d6c7f20e827c"><img src="https://i.gyazo.com/4f65ae5cc9c6b47b49d3d6c7f20e827c.png" alt="Image from Gyazo"></a></p>
<p>次に次数$d=10$の回帰式を求めます．
一般に次数を上げると近似の精度が上がります．
グラフを確認すると，確かにサンプルデータに対しては，
誤差を最小化することができています．
しかし，データ全体に対してはどうでしょうか．
上述の$d=3$より近似精度が落ちていないでしょうか．</p>
<!-- 2乗誤差は約31.0であり，$d=3$よりも誤差が大きくなってしまっています． -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y, e <span style="color:#f92672">=</span> regression(data, sample, <span style="color:#ae81ff">10</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Error: &#34;</span> <span style="color:#f92672">+</span> str(e))

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], y)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/a0a9796309339c97c9df3f5db34c6aac"><img src="https://i.gyazo.com/a0a9796309339c97c9df3f5db34c6aac.png" alt="Image from Gyazo"></a></p>
<p>最後に，次数$d$に伴う2乗誤差の推移を可視化してみましょう．
次数が増えるとサンプルデータに対する2乗誤差は減少するのに対し，
データ全体に対しては2乗誤差が増加してしまうことがわかります．
これが <strong>オーバーフィッティング</strong> です．
これは回帰問題に限らず，サンプルデータを用いて学習する手法では，
起こり得る現象です．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dimension <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>)

errors_all <span style="color:#f92672">=</span> [] <span style="color:#75715e"># データ全体に対する2乗誤差</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> dimension:
    y, e <span style="color:#f92672">=</span> regression(data, sample, i)
    errors_all<span style="color:#f92672">.</span>append(e)
    
errors_sample <span style="color:#f92672">=</span> [] <span style="color:#75715e"># サンプルに対する2乗誤差</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> dimension:
    y, e <span style="color:#f92672">=</span> regression(sample, sample, i)
    errors_sample<span style="color:#f92672">.</span>append(e)
  
plt<span style="color:#f92672">.</span>plot(dimension, errors_all, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;all&#34;</span>)
plt<span style="color:#f92672">.</span>plot(dimension, errors_sample, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sample&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;dimension&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;error&#34;</span>)
plt<span style="color:#f92672">.</span>legend()
</code></pre></div><p><a href="https://gyazo.com/e5c82f094eb68f9ad2a84193c500668b"><img src="https://i.gyazo.com/e5c82f094eb68f9ad2a84193c500668b.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  交差検証（クロスバリデーション）
</h1>

<p>オーバーフィッティングの影響を減らし，回帰式の妥当な精度を得ることを目的として，
<strong>交差検証（Cross-Validation）</strong> と呼ばれる方法が用いられます．
特に十分なデータセットが用意できないときに，汎用性を向上させる手段として，
有効な方法とされています．</p>
<p>ここでは，機械学習でよく用いられる <strong>k-分割交差検証（k-fold cross validation）</strong> を取り上げます．
この方法では，データセットをk個に分割し， <strong>k-1個</strong> を学習に，残りの <strong>1個</strong> をテストに用います．
<code>KFold</code>関数に分割数$k=5$を指定して分割します（データの順番もシャッフルします）．
この結果，5パターンの学習用とテスト用のサンプルが生成されます．
各サンプルは，学習用に32，テスト用に8のデータが用意されていることがわかります．</p>
<p><strong>[IN:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">kf <span style="color:#f92672">=</span> KFold(n_splits<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, shuffle<span style="color:#f92672">=</span>True, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>) <span style="color:#75715e">#k-分割交差検証（k=5）</span>
    
<span style="color:#66d9ef">for</span> train_set, test_set <span style="color:#f92672">in</span> kf<span style="color:#f92672">.</span>split(data[<span style="color:#ae81ff">0</span>]):
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;train_set: &#34;</span><span style="color:#f92672">+</span>  str(train_set) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34; test_set: &#34;</span> <span style="color:#f92672">+</span>  str(test_set))
</code></pre></div><p><strong>[OUT:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_set: [ <span style="color:#ae81ff">0</span>  <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">5</span>  <span style="color:#ae81ff">6</span>  <span style="color:#ae81ff">8</span> <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">11</span> <span style="color:#ae81ff">12</span> <span style="color:#ae81ff">13</span> <span style="color:#ae81ff">14</span> <span style="color:#ae81ff">15</span> <span style="color:#ae81ff">16</span> <span style="color:#ae81ff">17</span> <span style="color:#ae81ff">18</span> <span style="color:#ae81ff">19</span> <span style="color:#ae81ff">22</span> <span style="color:#ae81ff">24</span> <span style="color:#ae81ff">26</span> <span style="color:#ae81ff">27</span> <span style="color:#ae81ff">28</span> <span style="color:#ae81ff">29</span>
 <span style="color:#ae81ff">30</span> <span style="color:#ae81ff">32</span> <span style="color:#ae81ff">33</span> <span style="color:#ae81ff">35</span> <span style="color:#ae81ff">36</span> <span style="color:#ae81ff">37</span> <span style="color:#ae81ff">38</span> <span style="color:#ae81ff">39</span>] test_set: [ <span style="color:#ae81ff">7</span>  <span style="color:#ae81ff">9</span> <span style="color:#ae81ff">20</span> <span style="color:#ae81ff">21</span> <span style="color:#ae81ff">23</span> <span style="color:#ae81ff">25</span> <span style="color:#ae81ff">31</span> <span style="color:#ae81ff">34</span>]
train_set: [ <span style="color:#ae81ff">0</span>  <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">6</span>  <span style="color:#ae81ff">7</span>  <span style="color:#ae81ff">8</span>  <span style="color:#ae81ff">9</span> <span style="color:#ae81ff">12</span> <span style="color:#ae81ff">15</span> <span style="color:#ae81ff">17</span> <span style="color:#ae81ff">18</span> <span style="color:#ae81ff">19</span> <span style="color:#ae81ff">20</span> <span style="color:#ae81ff">21</span> <span style="color:#ae81ff">22</span> <span style="color:#ae81ff">23</span> <span style="color:#ae81ff">24</span> <span style="color:#ae81ff">25</span> <span style="color:#ae81ff">26</span> <span style="color:#ae81ff">27</span> <span style="color:#ae81ff">28</span> <span style="color:#ae81ff">29</span> <span style="color:#ae81ff">31</span>
 <span style="color:#ae81ff">32</span> <span style="color:#ae81ff">33</span> <span style="color:#ae81ff">34</span> <span style="color:#ae81ff">35</span> <span style="color:#ae81ff">36</span> <span style="color:#ae81ff">37</span> <span style="color:#ae81ff">38</span> <span style="color:#ae81ff">39</span>] test_set: [ <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">5</span> <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">11</span> <span style="color:#ae81ff">13</span> <span style="color:#ae81ff">14</span> <span style="color:#ae81ff">16</span> <span style="color:#ae81ff">30</span>]
train_set: [ <span style="color:#ae81ff">0</span>  <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">5</span>  <span style="color:#ae81ff">7</span>  <span style="color:#ae81ff">8</span>  <span style="color:#ae81ff">9</span> <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">11</span> <span style="color:#ae81ff">12</span> <span style="color:#ae81ff">13</span> <span style="color:#ae81ff">14</span> <span style="color:#ae81ff">16</span> <span style="color:#ae81ff">17</span> <span style="color:#ae81ff">19</span> <span style="color:#ae81ff">20</span> <span style="color:#ae81ff">21</span> <span style="color:#ae81ff">22</span> <span style="color:#ae81ff">23</span> <span style="color:#ae81ff">24</span> <span style="color:#ae81ff">25</span> <span style="color:#ae81ff">28</span>
 <span style="color:#ae81ff">29</span> <span style="color:#ae81ff">30</span> <span style="color:#ae81ff">31</span> <span style="color:#ae81ff">32</span> <span style="color:#ae81ff">34</span> <span style="color:#ae81ff">36</span> <span style="color:#ae81ff">38</span> <span style="color:#ae81ff">39</span>] test_set: [ <span style="color:#ae81ff">6</span> <span style="color:#ae81ff">15</span> <span style="color:#ae81ff">18</span> <span style="color:#ae81ff">26</span> <span style="color:#ae81ff">27</span> <span style="color:#ae81ff">33</span> <span style="color:#ae81ff">35</span> <span style="color:#ae81ff">37</span>]
train_set: [ <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">3</span>  <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">5</span>  <span style="color:#ae81ff">6</span>  <span style="color:#ae81ff">7</span>  <span style="color:#ae81ff">9</span> <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">11</span> <span style="color:#ae81ff">13</span> <span style="color:#ae81ff">14</span> <span style="color:#ae81ff">15</span> <span style="color:#ae81ff">16</span> <span style="color:#ae81ff">18</span> <span style="color:#ae81ff">19</span> <span style="color:#ae81ff">20</span> <span style="color:#ae81ff">21</span> <span style="color:#ae81ff">23</span> <span style="color:#ae81ff">24</span> <span style="color:#ae81ff">25</span> <span style="color:#ae81ff">26</span> <span style="color:#ae81ff">27</span> <span style="color:#ae81ff">29</span>
 <span style="color:#ae81ff">30</span> <span style="color:#ae81ff">31</span> <span style="color:#ae81ff">33</span> <span style="color:#ae81ff">34</span> <span style="color:#ae81ff">35</span> <span style="color:#ae81ff">36</span> <span style="color:#ae81ff">37</span> <span style="color:#ae81ff">39</span>] test_set: [ <span style="color:#ae81ff">0</span>  <span style="color:#ae81ff">8</span> <span style="color:#ae81ff">12</span> <span style="color:#ae81ff">17</span> <span style="color:#ae81ff">22</span> <span style="color:#ae81ff">28</span> <span style="color:#ae81ff">32</span> <span style="color:#ae81ff">38</span>]
train_set: [ <span style="color:#ae81ff">0</span>  <span style="color:#ae81ff">4</span>  <span style="color:#ae81ff">5</span>  <span style="color:#ae81ff">6</span>  <span style="color:#ae81ff">7</span>  <span style="color:#ae81ff">8</span>  <span style="color:#ae81ff">9</span> <span style="color:#ae81ff">10</span> <span style="color:#ae81ff">11</span> <span style="color:#ae81ff">12</span> <span style="color:#ae81ff">13</span> <span style="color:#ae81ff">14</span> <span style="color:#ae81ff">15</span> <span style="color:#ae81ff">16</span> <span style="color:#ae81ff">17</span> <span style="color:#ae81ff">18</span> <span style="color:#ae81ff">20</span> <span style="color:#ae81ff">21</span> <span style="color:#ae81ff">22</span> <span style="color:#ae81ff">23</span> <span style="color:#ae81ff">25</span> <span style="color:#ae81ff">26</span> <span style="color:#ae81ff">27</span> <span style="color:#ae81ff">28</span>
 <span style="color:#ae81ff">30</span> <span style="color:#ae81ff">31</span> <span style="color:#ae81ff">32</span> <span style="color:#ae81ff">33</span> <span style="color:#ae81ff">34</span> <span style="color:#ae81ff">35</span> <span style="color:#ae81ff">37</span> <span style="color:#ae81ff">38</span>] test_set: [ <span style="color:#ae81ff">1</span>  <span style="color:#ae81ff">2</span>  <span style="color:#ae81ff">3</span> <span style="color:#ae81ff">19</span> <span style="color:#ae81ff">24</span> <span style="color:#ae81ff">29</span> <span style="color:#ae81ff">36</span> <span style="color:#ae81ff">39</span>]
</code></pre></div><p>次に，<code>KFold</code>関数を利用して，多項式回帰の2乗誤差を求める<code>validate</code>関数を定義します．
5パターンのデータセットで，それぞれ2乗誤差を求め，その <strong>平均値</strong> を最終的な評価とします．
例えば，分割数$k=5$で，3次の多項式回帰の2乗誤差の平均は <strong>2.78</strong> となりました．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">validate</span>(k, dimension):
    kf <span style="color:#f92672">=</span> KFold(n_splits<span style="color:#f92672">=</span>k, shuffle<span style="color:#f92672">=</span>True, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>)
    errors <span style="color:#f92672">=</span> []
    
    <span style="color:#66d9ef">for</span> train_set, test_set <span style="color:#f92672">in</span> kf<span style="color:#f92672">.</span>split(data[<span style="color:#ae81ff">0</span>]):
        train <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([data[<span style="color:#ae81ff">0</span>][train_set], data[<span style="color:#ae81ff">1</span>][train_set]])
        test  <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([data[<span style="color:#ae81ff">0</span>][test_set],  data[<span style="color:#ae81ff">1</span>][test_set]])
        y, e <span style="color:#f92672">=</span> regression(test, train, dimension)
        errors<span style="color:#f92672">.</span>append(e)
        
    avg <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(errors) <span style="color:#75715e"># ２乗誤差の平均</span>
    <span style="color:#66d9ef">return</span> avg
</code></pre></div><p><strong>[IN:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">avg <span style="color:#f92672">=</span> validate(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">3</span>) <span style="color:#75715e"># 5分割， 3次の多項式回帰</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Average Error: &#34;</span> <span style="color:#f92672">+</span> str(avg))
</code></pre></div><p><strong>[OUT:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">Average Error: <span style="color:#ae81ff">2.781161227904894</span>
</code></pre></div><p>最後に，k-分割交差検証を利用して，次数$d$に伴う2乗誤差の推移を可視化してみましょう．
全体的な傾向はk-分割交差検証を用いない場合と同様ですが，
オーバーフィッティングの影響が小さくなるため，
次数が増えても2乗誤差は極端に増加していません．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dimension <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">1</span>)

errors_avg <span style="color:#f92672">=</span> []
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> dimension:
    e <span style="color:#f92672">=</span> validate(<span style="color:#ae81ff">5</span>, i)
    errors_avg<span style="color:#f92672">.</span>append(e)
    
plt<span style="color:#f92672">.</span>plot(dimension, errors_avg, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;average&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;dimension&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;error&#34;</span>)
plt<span style="color:#f92672">.</span>legend()
</code></pre></div><p><a href="https://gyazo.com/ca9e6c07656ba67003547944de93c427"><img src="https://i.gyazo.com/ca9e6c07656ba67003547944de93c427.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>

<p>下記のデータセットを利用し，$k=5$のk-分割交差検証で多項式回帰の精度を評価しなさい．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#f92672">-</span><span style="color:#ae81ff">2.00000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.90000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.80000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.70000000e+00</span>,
       <span style="color:#f92672">-</span><span style="color:#ae81ff">1.60000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.50000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.40000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.30000000e+00</span>,
       <span style="color:#f92672">-</span><span style="color:#ae81ff">1.20000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.10000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.00000000e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">9.00000000e-01</span>,
       <span style="color:#f92672">-</span><span style="color:#ae81ff">8.00000000e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">7.00000000e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">6.00000000e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">5.00000000e-01</span>,
       <span style="color:#f92672">-</span><span style="color:#ae81ff">4.00000000e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">3.00000000e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">2.00000000e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.00000000e-01</span>,
        <span style="color:#ae81ff">1.77635684e-15</span>,  <span style="color:#ae81ff">1.00000000e-01</span>,  <span style="color:#ae81ff">2.00000000e-01</span>,  <span style="color:#ae81ff">3.00000000e-01</span>,
        <span style="color:#ae81ff">4.00000000e-01</span>,  <span style="color:#ae81ff">5.00000000e-01</span>,  <span style="color:#ae81ff">6.00000000e-01</span>,  <span style="color:#ae81ff">7.00000000e-01</span>,
        <span style="color:#ae81ff">8.00000000e-01</span>,  <span style="color:#ae81ff">9.00000000e-01</span>,  <span style="color:#ae81ff">1.00000000e+00</span>,  <span style="color:#ae81ff">1.10000000e+00</span>,
        <span style="color:#ae81ff">1.20000000e+00</span>,  <span style="color:#ae81ff">1.30000000e+00</span>,  <span style="color:#ae81ff">1.40000000e+00</span>,  <span style="color:#ae81ff">1.50000000e+00</span>,
        <span style="color:#ae81ff">1.60000000e+00</span>,  <span style="color:#ae81ff">1.70000000e+00</span>,  <span style="color:#ae81ff">1.80000000e+00</span>,  <span style="color:#ae81ff">1.90000000e+00</span>])
		
y2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([ <span style="color:#ae81ff">4.39898556e+00</span>,  <span style="color:#ae81ff">3.93435081e+00</span>,  <span style="color:#ae81ff">2.61498259e+00</span>,  <span style="color:#ae81ff">2.72044213e+00</span>,
        <span style="color:#ae81ff">1.30362037e+00</span>,  <span style="color:#ae81ff">2.08098975e+00</span>,  <span style="color:#ae81ff">1.85633410e+00</span>,  <span style="color:#ae81ff">1.44865881e+00</span>,
        <span style="color:#ae81ff">7.29089005e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">9.42380345e-02</span>,  <span style="color:#ae81ff">8.39806492e-01</span>,  <span style="color:#ae81ff">9.13725511e-01</span>,
       <span style="color:#f92672">-</span><span style="color:#ae81ff">6.89556978e-02</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.88622122e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">4.17447107e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">8.50096595e-02</span>,
       <span style="color:#f92672">-</span><span style="color:#ae81ff">5.10447688e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.18019152e-03</span>,  <span style="color:#ae81ff">1.36162277e-01</span>,  <span style="color:#ae81ff">8.31331709e-01</span>,
        <span style="color:#ae81ff">9.37694167e-02</span>,  <span style="color:#ae81ff">1.68726072e+00</span>,  <span style="color:#ae81ff">4.71255186e-01</span>,  <span style="color:#ae81ff">2.02384997e+00</span>,
        <span style="color:#ae81ff">1.12543648e+00</span>,  <span style="color:#ae81ff">2.23950532e+00</span>,  <span style="color:#ae81ff">2.69476804e+00</span>,  <span style="color:#ae81ff">1.50769218e+00</span>,
        <span style="color:#ae81ff">2.86140345e+00</span>,  <span style="color:#ae81ff">2.46208705e+00</span>,  <span style="color:#ae81ff">2.46640709e+00</span>,  <span style="color:#ae81ff">2.40690140e+00</span>,
        <span style="color:#ae81ff">1.29052071e+00</span>,  <span style="color:#ae81ff">7.78084009e-01</span>,  <span style="color:#ae81ff">1.01201918e+00</span>,  <span style="color:#ae81ff">5.94619852e-01</span>,
        <span style="color:#ae81ff">1.27863784e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">4.80496436e-01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.75028230e+00</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">2.54273399e+00</span>])

data2 <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([x2, y2])
</code></pre></div><p><a href="https://gyazo.com/c3b122c99c004d9f7ba915d117858e92"><img src="https://i.gyazo.com/c3b122c99c004d9f7ba915d117858e92.png" alt="Image from Gyazo"></a></p>
<p><a href="https://gyazo.com/4589eebf892e43a067313ce66fa87b9e"><img src="https://i.gyazo.com/4589eebf892e43a067313ce66fa87b9e.png" alt="Image from Gyazo"></a></p>
<p>課題を完成させたら，ノートブックを保存し，
<strong>共有用のリンク</strong> と <strong>ノートブック（.ipynb）</strong> をダウンロードして提出してください．
このとき，必ず事前に下記の設定を行ってから提出してください．</p>
<ul>
<li>ノートブックの設定で「セルの出力を除外する」のチェックを外す</li>
<li>ノートブックの変更内容を保存して固定</li>
<li>共有設定で「学校法人椙山女学園大学」を「閲覧者」に設定</li>
</ul>
<!-- 作成したノートブックを **HTML(.html)** 形式でダウンロードし提出しなさい． -->

<h3>参考書籍</h3>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4274222446&linkId=1a63210b6dc95e90156695289116cb1b&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B078767Y56&linkId=cd73876214aec3d9b72777ab73920051&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4802611641&linkId=e77970ab2740fac9fdeb8b877668c257&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4839963525&linkId=14f05f671ddd917b204596b6b535981e&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>



    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter_extra1/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
