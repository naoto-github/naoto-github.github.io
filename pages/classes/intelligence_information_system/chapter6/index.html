<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    リッジ回帰とラッソ回帰 | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  
  <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  
  
  

  <meta property="og:title" content="リッジ回帰とラッソ回帰" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter6/" />



  <meta property="og:image" content="https://i.gyazo.com/86408a0058b76f50f92890075700baf7.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="ノートブックの作成  Colabにアクセスし，新規にノートブックを作成してください． ノートブックのタイトルは chapter6 とします． また，numpy，random, matplotlib.pyplot，scipy.optimizeを導入しておいてください．
import numpy as np import random import matplotlib.pyplot as plt from scipy.optimize import minimize オーバーフィッティング（過学習）  オーバーフィッティング とは 過学習 または 過剰適合 と呼ばれることもある現象で， サンプルデータに過剰に適合してしまい， データ全体に対しての汎用的な能力を失った状態を指します． ここでは，回帰問題を例に挙げて，オーバーフィッティングを再現してみましょう．
ここでは，$x^3 - 2x$にノイズとなる乱数を加えた40点のデータを生成します．
x = np.array([-2. ,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1. ,-0.9,-0.8,-0.7, -0.6,-0.5,-0.4,-0.3,-0.2,-0.1, 0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]) y = np.array([-3.75,-2.28,-1.16,-1.08,-0.89,-0.08, 0.58, 1.69, 1." />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="リッジ回帰とラッソ回帰" />



  <meta name="twitter:description" content="ノートブックの作成  Colabにアクセスし，新規にノートブックを作成してください． ノートブックのタイトルは chapter6 とします． また，numpy，random, matplotlib.pyplot，scipy.optimizeを導入しておいてください．
import numpy as np import random import matplotlib.pyplot as plt from scipy.optimize import minimize オーバーフィッティング（過学習）  オーバーフィッティング とは 過学習 または 過剰適合 と呼ばれることもある現象で， サンプルデータに過剰に適合してしまい， データ全体に対しての汎用的な能力を失った状態を指します． ここでは，回帰問題を例に挙げて，オーバーフィッティングを再現してみましょう．
ここでは，$x^3 - 2x$にノイズとなる乱数を加えた40点のデータを生成します．
x = np.array([-2. ,-1.9,-1.8,-1.7,-1.6,-1.5,-1.4,-1.3,-1.2,-1.1,-1. ,-0.9,-0.8,-0.7, -0.6,-0.5,-0.4,-0.3,-0.2,-0.1, 0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]) y = np.array([-3.75,-2.28,-1.16,-1.08,-0.89,-0.08, 0.58, 1.69, 1." />



  <meta name="twitter:image" content="https://i.gyazo.com/86408a0058b76f50f92890075700baf7.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    
    <h1 class="post-title">リッジ回帰とラッソ回帰</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/86408a0058b76f50f92890075700baf7"><img src="https://i.gyazo.com/86408a0058b76f50f92890075700baf7.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  ノートブックの作成
</h1>

<p>Colabにアクセスし，新規にノートブックを作成してください．
ノートブックのタイトルは <strong>chapter6</strong> とします．
また，<strong>numpy</strong>，<strong>random</strong>, <strong>matplotlib.pyplot</strong>，<strong>scipy.optimize</strong>を導入しておいてください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> random
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">from</span> scipy.optimize <span style="color:#f92672">import</span> minimize
</code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  オーバーフィッティング（過学習）
</h1>

<p><strong>オーバーフィッティング</strong> とは
<strong>過学習</strong> または <strong>過剰適合</strong> と呼ばれることもある現象で，
サンプルデータに過剰に適合してしまい，
データ全体に対しての汎用的な能力を失った状態を指します．
ここでは，回帰問題を例に挙げて，オーバーフィッティングを再現してみましょう．</p>
<p>ここでは，$x^3 - 2x$にノイズとなる乱数を加えた40点のデータを生成します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#f92672">-</span><span style="color:#ae81ff">2.</span> ,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.9</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.8</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.7</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.6</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.4</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.3</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.2</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.</span> ,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.9</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.8</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.7</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">0.6</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.4</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.3</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0.</span> , <span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">0.3</span>, <span style="color:#ae81ff">0.4</span>, <span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">0.6</span>, <span style="color:#ae81ff">0.7</span>, <span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">0.9</span>, <span style="color:#ae81ff">1.</span> , <span style="color:#ae81ff">1.1</span>, <span style="color:#ae81ff">1.2</span>, <span style="color:#ae81ff">1.3</span>, <span style="color:#ae81ff">1.4</span>, <span style="color:#ae81ff">1.5</span>, <span style="color:#ae81ff">1.6</span>, <span style="color:#ae81ff">1.7</span>, <span style="color:#ae81ff">1.8</span>, <span style="color:#ae81ff">1.9</span>])
y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#f92672">-</span><span style="color:#ae81ff">3.75</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">2.28</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.16</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.08</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.89</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.08</span>, <span style="color:#ae81ff">0.58</span>, <span style="color:#ae81ff">1.69</span>, <span style="color:#ae81ff">1.6</span> , <span style="color:#ae81ff">2.17</span>, <span style="color:#ae81ff">2.61</span>, <span style="color:#ae81ff">1.42</span>, <span style="color:#ae81ff">1.33</span>, <span style="color:#ae81ff">1.26</span>, <span style="color:#ae81ff">2.46</span>, <span style="color:#ae81ff">1.5</span> , <span style="color:#ae81ff">1.42</span>, <span style="color:#ae81ff">1.69</span>, <span style="color:#ae81ff">0.6</span> , <span style="color:#ae81ff">1.76</span>, <span style="color:#ae81ff">0.55</span>, <span style="color:#ae81ff">1.33</span>, <span style="color:#ae81ff">0.63</span>, <span style="color:#ae81ff">0.93</span>, <span style="color:#ae81ff">0.24</span>, <span style="color:#ae81ff">0.66</span>, <span style="color:#ae81ff">0.08</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.47</span>, <span style="color:#ae81ff">0.58</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.76</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.85</span>, <span style="color:#ae81ff">0.5</span> ,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.6</span> , <span style="color:#ae81ff">1.53</span>, <span style="color:#ae81ff">1.63</span>, <span style="color:#ae81ff">1.46</span>, <span style="color:#ae81ff">0.94</span>, <span style="color:#ae81ff">3.41</span>, <span style="color:#ae81ff">2.99</span>, <span style="color:#ae81ff">5.03</span>])
data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([x, y])

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/5e34493f423bc568448803201da42141"><img src="https://i.gyazo.com/5e34493f423bc568448803201da42141.png" alt="Image from Gyazo"></a></p>
<p>このデータ全体から，ランダムに抽出した20点を回帰の学習に用いることにします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#f92672">-</span><span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.2</span>, <span style="color:#ae81ff">0.</span> , <span style="color:#ae81ff">1.9</span>, <span style="color:#ae81ff">0.4</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.3</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">2.</span> ,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.5</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.7</span>, <span style="color:#ae81ff">0.2</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.6</span>, <span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">1.1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.5</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.3</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.</span> , <span style="color:#ae81ff">0.6</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.1</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.9</span>])
y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([ <span style="color:#ae81ff">1.33</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.6</span> , <span style="color:#ae81ff">0.55</span>, <span style="color:#ae81ff">5.03</span>, <span style="color:#ae81ff">0.24</span>, <span style="color:#ae81ff">1.69</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">3.75</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">0.08</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">1.08</span>, <span style="color:#ae81ff">0.63</span>, <span style="color:#ae81ff">2.46</span>, <span style="color:#ae81ff">1.33</span>, <span style="color:#ae81ff">0.5</span> , <span style="color:#ae81ff">1.5</span> , <span style="color:#ae81ff">1.69</span>, <span style="color:#ae81ff">1.76</span>, <span style="color:#ae81ff">2.61</span>, <span style="color:#ae81ff">0.08</span>, <span style="color:#ae81ff">2.17</span>,<span style="color:#f92672">-</span><span style="color:#ae81ff">2.28</span>])
sample <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([x, y])

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/255b17fc7e9017e7e7c845e6dce99556"><img src="https://i.gyazo.com/255b17fc7e9017e7e7c845e6dce99556.png" alt="Image from Gyazo"></a></p>
<p>回帰式の係数の導出にはNumpyの<code>polyfit</code>を用います．
多項式基底の次数$d$を変えて回帰式と2乗誤差を求めるため，
新たに<code>regression</code>という関数を定義します．
関数<code>regression</code>の返値は回帰式のY軸の値と2乗誤差のタプルです．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">regression</span>(data, sample, d):

    <span style="color:#75715e"># サンプルで回帰式の係数</span>
    w <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>polyfit(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>], d)

    <span style="color:#75715e"># f(x)を算出</span>
    fx <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range((d<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)):
        fx <span style="color:#f92672">+=</span> w[i] <span style="color:#f92672">*</span> (data[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">**</span> (d <span style="color:#f92672">-</span> i))

    <span style="color:#75715e"># 2乗誤差</span>
    e <span style="color:#f92672">=</span> sum((data[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> fx) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>)

    <span style="color:#66d9ef">return</span> fx, e
</code></pre></div><p>最初に次数$d=1$の回帰式（回帰直線）を求めます．
1本の直線で全体の傾向を近似していることがわかります．</p>
<!-- 2乗誤差は約80.1です． -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fx, e <span style="color:#f92672">=</span> regression(data, sample, <span style="color:#ae81ff">1</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Error: &#34;</span> <span style="color:#f92672">+</span> str(e))

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], fx)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/01c4647ce3a1a05509f7ead277923e17"><img src="https://i.gyazo.com/01c4647ce3a1a05509f7ead277923e17.png" alt="Image from Gyazo"></a></p>
<p>次に次数$d=3$の回帰式を求めます．
データにはノイズが加わっていますが，
真の関数である$x^3 - 2x$を，よく近似できていることがわかります．</p>
<!-- 2乗誤差は約11.4です． -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fx, e <span style="color:#f92672">=</span> regression(data, sample, <span style="color:#ae81ff">3</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Error: &#34;</span> <span style="color:#f92672">+</span> str(e))

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], fx)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/b94c467d60dce35009a805e31a8af13b"><img src="https://i.gyazo.com/b94c467d60dce35009a805e31a8af13b.png" alt="Image from Gyazo"></a></p>
<p>次に次数$d=10$の回帰式を求めます．
一般に次数を上げると近似の精度が上がります．
グラフを確認すると，確かにサンプルデータに対しては，
誤差を最小化することができています．
しかし，データ全体に対してはどうでしょうか．
上述の$d=3$より近似精度が落ちていないでしょうか．</p>
<!-- 2乗誤差は約31.0であり，$d=3$よりも誤差が大きくなってしまっています． -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fx, e <span style="color:#f92672">=</span> regression(data, sample, <span style="color:#ae81ff">10</span>)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;Error: &#34;</span> <span style="color:#f92672">+</span> str(e))

plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], fx)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/bf70a85175e392b167259b0baa4d6fcc"><img src="https://i.gyazo.com/bf70a85175e392b167259b0baa4d6fcc.png" alt="Image from Gyazo"></a></p>
<p>最後に，次数$d$に伴う2乗誤差の推移を可視化してみましょう．
次数が増えるとサンプルデータに対する2乗誤差は減少するのに対し，
データ全体に対しては2乗誤差が増加してしまうことがわかります．
これが <strong>オーバーフィッティング</strong> です．
これは回帰問題に限らず，サンプルデータを用いて学習する手法では，
起こり得る現象です．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dimension <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">1</span>)

errors_all <span style="color:#f92672">=</span> [] <span style="color:#75715e"># データ全体に対する2乗誤差</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> dimension:
    fx, e <span style="color:#f92672">=</span> regression(data, sample, i)
    errors_all<span style="color:#f92672">.</span>append(e)

errors_sample <span style="color:#f92672">=</span> [] <span style="color:#75715e"># サンプルに対する2乗誤差</span>
<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> dimension:
    fx, e <span style="color:#f92672">=</span> regression(sample, sample, i)
    errors_sample<span style="color:#f92672">.</span>append(e)

plt<span style="color:#f92672">.</span>plot(dimension, errors_all, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;all&#34;</span>)
plt<span style="color:#f92672">.</span>plot(dimension, errors_sample, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sample&#34;</span>)
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;dimension&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;error&#34;</span>)
plt<span style="color:#f92672">.</span>legend()
</code></pre></div><p><a href="https://gyazo.com/9d89d212e8a79d1421884c65e456a278"><img src="https://i.gyazo.com/9d89d212e8a79d1421884c65e456a278.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  正則化
</h1>

<p>オーバーフィッティングを回避する方法の一つに正則化（Regularization）があります．
学習したモデルが複雑になりすぎないように，目的関数（誤差関数）に制約を設ける方法が一般的です．
回帰においては，<strong>リッジ回帰（L2ノルム）</strong> と <strong>ラッソ回帰（L1ノルム）</strong> がよく知られています．
ノルムを理解するには冬眠氏のブログ「<a href="https://toeming.hatenablog.com/entry/2020/04/03/000925">正則化をなるべく丁寧に理解する - 理屈編 -</a>」
がとても参考になります．</p>
<h2 id="平均二乗誤差正則化なし">平均二乗誤差（正則化なし）</h2>
<p>ここでは，上述のように次数$d=10$の多項式基底を考えます．
多項式基底の回帰式$f(x)$を次の関数で定義します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 多項式基底</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">polynominal</span>(w, x, d):

  fx <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
  <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(d):
    fx <span style="color:#f92672">+=</span> w[i] <span style="color:#f92672">*</span> (x <span style="color:#f92672">**</span> i)

  <span style="color:#66d9ef">return</span> fx
</code></pre></div><p>目的関数として平均二乗誤差（Mean Square Error: MSE）を定義します．
$y$と$f(x)$の二乗誤差の平均値です．</p>
<p>$$MSE=\frac{1}{N} \sum_{n=0}^{N-1} (y_n - f(x_n))^2$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 平均二乗誤差</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">mse</span>(w, x, y, d):

  y_ <span style="color:#f92672">=</span> polynominal(w, x, d)
  error <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum((y <span style="color:#f92672">-</span> y_) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> len(y_)

  <span style="color:#66d9ef">return</span> error
</code></pre></div><p><strong>minimize</strong> 関数を利用して，平均二乗誤差を最小化する重み $w$ を算出します．
このとき次数$d$は10に設定します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">d <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span> <span style="color:#75715e"># 次数</span>
w_init <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones(d)
result <span style="color:#f92672">=</span> minimize(mse, w_init, args<span style="color:#f92672">=</span>(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>], d), method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;powell&#34;</span>)
w <span style="color:#f92672">=</span> result<span style="color:#f92672">.</span>x
</code></pre></div><p>算出された重み$w$を用いて，回帰式をグラフで表します．
<strong>polyfit</strong> と同様に正則化を加えていない状態では，
オーバーフィッティングが生じていることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], polynominal(w, data[<span style="color:#ae81ff">0</span>], d))
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/13341fe1ba1b4d65b251fa46bf7d16a5"><img src="https://i.gyazo.com/13341fe1ba1b4d65b251fa46bf7d16a5.png" alt="Image from Gyazo"></a></p>
<h2 id="リッジ回帰">リッジ回帰</h2>
<p>次にリッジ回帰（Ridge Regression）で回帰式を求めます．
リッジ回帰では，目的変数として，平均二乗誤差に<strong>L2ノルムの正則化項</strong>を加算します．
L2ノルムはユークリッド距離を表しており，ここでは重みベクトル$w$の長さを表します（平方根は計算しないけど）．
正則化により，重みは過剰に大きくならないように制約されます．
ここで，$\lambda$は正則化のバランスを調整する係数です．</p>
<p>$$RIDGE=\frac{1}{N} \sum_{n=0}^{N-1} (y_n - f(x_n))^2 + \lambda \sum_{d=0}^{D-1} w_d^2$$</p>
<p>リッジ回帰の目的関数を定義します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 正則化を加えた平均二乗誤差（リッジ回帰）</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">ridge</span>(w, x, y, d, lam):

  y_ <span style="color:#f92672">=</span> polynominal(w, x, d)
  error <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum((y <span style="color:#f92672">-</span> y_) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> len(y_) <span style="color:#f92672">+</span> lam <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>sum(w <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>)

  <span style="color:#66d9ef">return</span> error
</code></pre></div><p>先程と同様に <strong>minimize</strong> 関数で，リッジ回帰の目的関数を最小化する重み$w$を算出します．
このとき，次数$d=10$，正則化の係数$\lambda=1$に設定しています．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">d <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span> <span style="color:#75715e"># 次数</span>
lam <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#75715e"># 正則化項の係数</span>
w_init <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones(d)
result <span style="color:#f92672">=</span> minimize(ridge, w_init, args<span style="color:#f92672">=</span>(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>], d, lam), method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;powell&#34;</span>)
w <span style="color:#f92672">=</span> result<span style="color:#f92672">.</span>x
</code></pre></div><p>算出された重み$w$を用いて，回帰式をグラフで表します．
オーバーフィッティングが回避され，全体の傾向を近似した回帰式が導出されていることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], polynominal(w, data[<span style="color:#ae81ff">0</span>], d))
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/f2eae35fe6b0e3005989bfd0f7254323"><img src="https://i.gyazo.com/f2eae35fe6b0e3005989bfd0f7254323.png" alt="Image from Gyazo"></a></p>
<h2 id="ラッソ回帰">ラッソ回帰</h2>
<p>最後にラッソ回帰（Lasso Regression）で回帰式を求めます．
ラッソ回帰では，目的変数として，平均二乗誤差に<strong>L1ノルムの正則化項</strong>を加算します．
L1ノルムはマンハッタン距離を表しており，ここでは重みベクトル$w$の絶対値の和で求められます．
正則化により，不要な変数の重みが0になるように調整されます（特徴量選択と考えることもできる）．
ここで，$\lambda$は正則化のバランスを調整する係数です．</p>
<p>$$LASSO=\frac{1}{N} \sum_{n=0}^{N-1} (y_n - f(x_n))^2 + \lambda \sum_{d=0}^{D-1} |w_d|$$</p>
<p>ラッソ回帰の目的関数を定義します．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 正則化を加えた平均二乗誤差（ラッソ回帰）</span>
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">lasso</span>(w, x, y, d, lam):

  y_ <span style="color:#f92672">=</span> polynominal(w, x, d)
  error <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum((y <span style="color:#f92672">-</span> y_) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> len(y_) <span style="color:#f92672">+</span> lam <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>sum(np<span style="color:#f92672">.</span>abs(w))

  <span style="color:#66d9ef">return</span> error
</code></pre></div><p>先程と同様に <strong>minimize</strong> 関数で，ラッソ回帰の目的関数を最小化する重み$w$を算出します．
このとき，次数$d=10$，正則化の係数$\lambda=1$に設定しています．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">d <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span> <span style="color:#75715e"># 次数</span>
lam <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#75715e"># 正則化項の重み</span>
w_init <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones(d)
result <span style="color:#f92672">=</span> minimize(lasso, w_init, args<span style="color:#f92672">=</span>(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>], d, lam), method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;powell&#34;</span>)
w <span style="color:#f92672">=</span> result<span style="color:#f92672">.</span>x
</code></pre></div><p>算出された重み$w$を用いて，回帰式をグラフで表します．
オーバーフィッティングが回避され，全体の傾向を近似した回帰式が導出されていることが確認できます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">plt<span style="color:#f92672">.</span>scatter(data[<span style="color:#ae81ff">0</span>], data[<span style="color:#ae81ff">1</span>] )
plt<span style="color:#f92672">.</span>scatter(sample[<span style="color:#ae81ff">0</span>], sample[<span style="color:#ae81ff">1</span>])
plt<span style="color:#f92672">.</span>plot(data[<span style="color:#ae81ff">0</span>], polynominal(w, data[<span style="color:#ae81ff">0</span>], d))
plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</code></pre></div><p><a href="https://gyazo.com/be93d5055b00f951a527a4a641398fea"><img src="https://i.gyazo.com/be93d5055b00f951a527a4a641398fea.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>

<p>$x^3 - 3x + 3$に従った40点を生成し，そこからランダムに20点を抽出する．
この20点をラッソ回帰で学習した回帰式を求めてください．
このとき，回帰式は10次の多項式基底とします．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># 40点を生成</span>
x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>arange(<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0.1</span>)
y <span style="color:#f92672">=</span> x <span style="color:#f92672">**</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">-</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">*</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">3</span>
r <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(len(y)) <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span> <span style="color:#75715e"># 乱数を生成</span>
y <span style="color:#f92672">=</span> y <span style="color:#f92672">+</span> r <span style="color:#75715e"># 乱数を加算</span>
data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>stack([x, y])

<span style="color:#75715e"># 20点をランダム抽出</span>
sample <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(random<span style="color:#f92672">.</span>sample(list(data<span style="color:#f92672">.</span>transpose()), <span style="color:#ae81ff">20</span>))<span style="color:#f92672">.</span>transpose()
</code></pre></div><p><a href="https://gyazo.com/4cdb5e44847ab0d389b5ff3fb20f424d"><img src="https://i.gyazo.com/4cdb5e44847ab0d389b5ff3fb20f424d.png" alt="Image from Gyazo"></a>
【正則化なし】</p>
<p><a href="https://gyazo.com/7702d72e09c0dcdf422ebbc35d5abae7"><img src="https://i.gyazo.com/7702d72e09c0dcdf422ebbc35d5abae7.png" alt="Image from Gyazo"></a>
【ラッソ回帰】</p>
<p>課題を完成させたら，<strong>chapter6.ipynb</strong> を保存し，
<strong>共有用のリンク</strong> と <strong>ノートブック（.ipynb）</strong> をダウンロードして提出してください．
このとき，必ず事前に下記の設定を行ってから提出してください．</p>
<ul>
<li>ノートブックの設定で「セルの出力を除外する」のチェックを外す</li>
<li>ノートブックの変更内容を保存して固定</li>
<li>共有設定で「学校法人椙山女学園大学」を「閲覧者」に設定</li>
</ul>

<h3>参考書籍</h3>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4274222446&linkId=1a63210b6dc95e90156695289116cb1b&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B078767Y56&linkId=cd73876214aec3d9b72777ab73920051&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4802611641&linkId=e77970ab2740fac9fdeb8b877668c257&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4839963525&linkId=14f05f671ddd917b204596b6b535981e&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>



    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter6/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
