<!DOCTYPE html>
<html lang="ja">
    <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    分類④・k近傍法 | mLAB
  </title>

  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  <link rel="stylesheet" href="/css/custom.css">
  <link rel="stylesheet" href="/css/syntax.css">
  
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="mLAB" />

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Kosugi&display=swap" rel="stylesheet">

  
  <script src="https://kit.fontawesome.com/0c97f11cd6.js" crossorigin="anonymous"></script>

  
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js"></script>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css"/>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css"/>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/jquery.slicknav.js"></script>
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/SlickNav/1.0.10/slicknav.min.css" />

  
  <div id="fb-root"></div>
  <script async defer crossorigin="anonymous" src="https://connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v9.0"></script>  
  
  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	     tex2jax: {
	        inlineMath: [['$','$']]
        }
    });
  </script>

  
  

  
  <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
  
  
  

  <meta property="og:title" content="分類④・k近傍法" />



  <meta property="og:type" content="article" />



  <meta property="og:url" content="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter9/" />



  <meta property="og:image" content="https://i.gyazo.com/76fc4bb780f5f884c744cba59c0e9c2e.png" />



  <meta property="og:site_name" content="mLAB" />



  <meta property="og:description" content="ノートブックの作成Anacondaを導入していない場合は，機械学習ライブラリ scikit-learn をpipでインストールする必要があります． インストールしたフォルダで，PowerShellを起動し，下記のコマンドを実行してください．
&gt; .\Scripts\pip install scikit-learn Jupyter Notebook を起動し，新規にノートブックを作成してください． ノートブックのタイトルは Notebook9 とします． ノートブックの作成方法は第１回の資料を参照してください． また，numpy，matplotlib.pyplot を導入しておいてください．
import numpy as np import matplotlib.pyplot as plt データの準備あらかじめ用意された機械学習のための データセット を利用することができます． ここでは，scikit-learn ライブラリに収録されている アヤメ（iris） のデータセットを用います． アヤメは草地に生息している植物であり， setosa， versicolor， virginica などの種類があります（和名はよく分かりませんでした）． このデータセットには，上記３種類のアヤメの， がく片の長さ（Sepal Length） ，がく片の幅（Sepal Width） ， 花弁の長さ（Petal Length） ，花弁の幅（Petal Width） を計測したデータが含まれています．

各種類に50のサンプルがあり，例えば，最初のデータは[5.1,3.5,1.4, 0.2]となっています． これは，がく片の長さが5.1cm，がく片の幅が3.5cm，花弁の長さが1.4cm，花弁の幅が0.2cmを表しています． ラベルは0,1,2のいずれかで与えられ，それぞれsetosa，virsicolor, virginicaを表しています． 最初のサンプルのラベルは0であるため，これは setosa であることがわかります．
[In:]
from sklearn.datasets import load_iris iris = load_iris() print(iris." />



  
  
<meta name="twitter:card" content="summary" />

<meta name="twitter:site" content="@nmukai1978" />


  <meta name="twitter:title" content="分類④・k近傍法" />



  <meta name="twitter:description" content="ノートブックの作成Anacondaを導入していない場合は，機械学習ライブラリ scikit-learn をpipでインストールする必要があります． インストールしたフォルダで，PowerShellを起動し，下記のコマンドを実行してください．
&gt; .\Scripts\pip install scikit-learn Jupyter Notebook を起動し，新規にノートブックを作成してください． ノートブックのタイトルは Notebook9 とします． ノートブックの作成方法は第１回の資料を参照してください． また，numpy，matplotlib.pyplot を導入しておいてください．
import numpy as np import matplotlib.pyplot as plt データの準備あらかじめ用意された機械学習のための データセット を利用することができます． ここでは，scikit-learn ライブラリに収録されている アヤメ（iris） のデータセットを用います． アヤメは草地に生息している植物であり， setosa， versicolor， virginica などの種類があります（和名はよく分かりませんでした）． このデータセットには，上記３種類のアヤメの， がく片の長さ（Sepal Length） ，がく片の幅（Sepal Width） ， 花弁の長さ（Petal Length） ，花弁の幅（Petal Width） を計測したデータが含まれています．

各種類に50のサンプルがあり，例えば，最初のデータは[5.1,3.5,1.4, 0.2]となっています． これは，がく片の長さが5.1cm，がく片の幅が3.5cm，花弁の長さが1.4cm，花弁の幅が0.2cmを表しています． ラベルは0,1,2のいずれかで与えられ，それぞれsetosa，virsicolor, virginicaを表しています． 最初のサンプルのラベルは0であるため，これは setosa であることがわかります．
[In:]
from sklearn.datasets import load_iris iris = load_iris() print(iris." />



  <meta name="twitter:image" content="https://i.gyazo.com/76fc4bb780f5f884c744cba59c0e9c2e.png" />


  
</head>

    <body>
        <nav class="nav">
  <div class="nav-container">
    
    <a href="/">
    <h2 class="nav-title">
      <img src="https://mukai-lab.info/favicon/favicon-48x48.png" align="top"/>
      <span>mLAB</span>
      

<ul id="menu">
  
  
  <li>
    <a href="/">Top</a>
  </li>
  
  
  
  <li>
    <a href="/classes/">Classes</a>
  </li>
  
  
  
  <li>
    <a href="/posts/">Comics</a>
  </li>
  
  
</ul>

<script>
  $(function(){
    $("#menu").slicknav({
      label: "メニュー"
    });
  });
</script>



    </h2>
    </a>
  </div>
</nav>

        

<main>
  <div class="post">
    
    <h1 class="post-title">分類④・k近傍法</h1>
<div class="post-line"></div>
    
    

    <p><a href="https://gyazo.com/76fc4bb780f5f884c744cba59c0e9c2e"><img src="https://i.gyazo.com/76fc4bb780f5f884c744cba59c0e9c2e.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  ノートブックの作成
</h1>

<p>Anacondaを導入していない場合は，機械学習ライブラリ <strong>scikit-learn</strong> を<code>pip</code>でインストールする必要があります．
インストールしたフォルダで，<strong>PowerShell</strong>を起動し，下記のコマンドを実行してください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-txt" data-lang="txt">&gt; .\Scripts\pip install scikit-learn
</code></pre></div><p><strong>Jupyter Notebook</strong> を起動し，新規にノートブックを作成してください．
ノートブックのタイトルは <strong>Notebook9</strong> とします．
ノートブックの作成方法は<a href="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter1/">第１回の資料</a>を参照してください．
また，<strong>numpy</strong>，<strong>matplotlib.pyplot</strong> を導入しておいてください．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
</code></pre></div><h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  データの準備
</h1>

<p>あらかじめ用意された機械学習のための <strong>データセット</strong> を利用することができます．
ここでは，<strong>scikit-learn</strong> ライブラリに収録されている <strong>アヤメ（iris）</strong> のデータセットを用います．
アヤメは草地に生息している植物であり，
<strong>setosa</strong>， <strong>versicolor</strong>， <strong>virginica</strong> などの種類があります（和名はよく分かりませんでした）．
このデータセットには，上記３種類のアヤメの，
<strong>がく片の長さ（Sepal Length）</strong> ，<strong>がく片の幅（Sepal Width）</strong> ，
<strong>花弁の長さ（Petal Length）</strong> ，<strong>花弁の幅（Petal Width）</strong> を計測したデータが含まれています．</p>
<p><a title="Qwert1234 [Public domain], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Iris_sanguinea_01.JPG"><img width="256" alt="Iris sanguinea 01" src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Iris_sanguinea_01.JPG/256px-Iris_sanguinea_01.JPG"></a></p>
<p>各種類に50のサンプルがあり，例えば，最初のデータは[5.1,3.5,1.4, 0.2]となっています．
これは，がく片の長さが5.1cm，がく片の幅が3.5cm，花弁の長さが1.4cm，花弁の幅が0.2cmを表しています．
ラベルは0,1,2のいずれかで与えられ，それぞれsetosa，virsicolor, virginicaを表しています．
最初のサンプルのラベルは0であるため，これは <strong>setosa</strong> であることがわかります．</p>
<p><strong>[In:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_iris
iris <span style="color:#f92672">=</span> load_iris()
<span style="color:#66d9ef">print</span>(iris<span style="color:#f92672">.</span>feature_names) <span style="color:#75715e">#フィールド名</span>
<span style="color:#66d9ef">print</span>(iris<span style="color:#f92672">.</span>data[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>]) <span style="color:#75715e">#フィールド・データ</span>
<span style="color:#66d9ef">print</span>(iris<span style="color:#f92672">.</span>target_names) <span style="color:#75715e">#ラベル名</span>
<span style="color:#66d9ef">print</span>(iris<span style="color:#f92672">.</span>target[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>]) <span style="color:#75715e">#ラベル・データ</span>
</code></pre></div><p><strong>[Out:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[<span style="color:#e6db74">&#39;sepal length (cm)&#39;</span>, <span style="color:#e6db74">&#39;sepal width (cm)&#39;</span>, <span style="color:#e6db74">&#39;petal length (cm)&#39;</span>, <span style="color:#e6db74">&#39;petal width (cm)&#39;</span>]
[[<span style="color:#ae81ff">5.1</span> <span style="color:#ae81ff">3.5</span> <span style="color:#ae81ff">1.4</span> <span style="color:#ae81ff">0.2</span>]
 [<span style="color:#ae81ff">4.9</span> <span style="color:#ae81ff">3.</span>  <span style="color:#ae81ff">1.4</span> <span style="color:#ae81ff">0.2</span>]
 [<span style="color:#ae81ff">4.7</span> <span style="color:#ae81ff">3.2</span> <span style="color:#ae81ff">1.3</span> <span style="color:#ae81ff">0.2</span>]
 [<span style="color:#ae81ff">4.6</span> <span style="color:#ae81ff">3.1</span> <span style="color:#ae81ff">1.5</span> <span style="color:#ae81ff">0.2</span>]
 [<span style="color:#ae81ff">5.</span>  <span style="color:#ae81ff">3.6</span> <span style="color:#ae81ff">1.4</span> <span style="color:#ae81ff">0.2</span>]]
[<span style="color:#e6db74">&#39;setosa&#39;</span> <span style="color:#e6db74">&#39;versicolor&#39;</span> <span style="color:#e6db74">&#39;virginica&#39;</span>]
[<span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">0</span>]
</code></pre></div><p>ここでは，簡単化のため，<strong>がく片の長さ</strong> と <strong>がく片の幅</strong> のみ対象とします．
散布図をプロットしてみると，versicolorとvirginicaの分類は難しそうだということがわかります．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">length <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>data[:,<span style="color:#ae81ff">0</span>]
width <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>data[:,<span style="color:#ae81ff">1</span>]
target <span style="color:#f92672">=</span> iris<span style="color:#f92672">.</span>target
setosa <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(target <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)
versicolor <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(target <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>)
virginica <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(target <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>)
plt<span style="color:#f92672">.</span>scatter(length[setosa],width[setosa], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;setosa&#34;</span>)
plt<span style="color:#f92672">.</span>scatter(length[versicolor],width[versicolor], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;versicolor&#34;</span>)
plt<span style="color:#f92672">.</span>scatter(length[virginica],width[virginica], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;virginica&#34;</span>)
plt<span style="color:#f92672">.</span>legend()
</code></pre></div><p><a href="https://gyazo.com/989c9d270c98b93dff33bef8d0bcf660"><img src="https://i.gyazo.com/989c9d270c98b93dff33bef8d0bcf660.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  学習データとテストデータ
</h1>

<p>今回はデータセットに含まれる150のサンプルを
<strong>学習データ（訓練データ）</strong> と <strong>テストデータ（評価データ）</strong> に分けることにします．
このように，対象のサンプルを学習用とテスト用に分けて，
回帰や分類の妥当性の検証に用いる方法を <strong>交差検証</strong> と呼びます．
サンプルを分ける際は，偏りがないように，無作為に抽出することが必要です．
ここでは，numpyの <strong>shuffle</strong> 関数を用いて，サンプルをシャッフルした後で，
前方の100のサンプルを学習データ，後方の50のサンプルをテストデータとします．
シャッフルの結果は，実行する度に変化することに注意してください．</p>
<p><strong>[In:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">z <span style="color:#f92672">=</span> list(zip(length, width, target)) <span style="color:#75715e">#要素を一つのリストにまとめる</span>
np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>shuffle(z) <span style="color:#75715e">#シャッフル</span>
length,width,target <span style="color:#f92672">=</span> zip(<span style="color:#f92672">*</span>z) <span style="color:#75715e">#要素を分割する</span>
length <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(length)
width <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(width)
target <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(target)
<span style="color:#66d9ef">print</span>(length[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>])
<span style="color:#66d9ef">print</span>(width[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>])
<span style="color:#66d9ef">print</span>(target[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>])
</code></pre></div><p><strong>[Out:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[<span style="color:#ae81ff">6.2</span> <span style="color:#ae81ff">6.3</span> <span style="color:#ae81ff">5.2</span> <span style="color:#ae81ff">5.4</span> <span style="color:#ae81ff">5.8</span>]
[<span style="color:#ae81ff">2.2</span> <span style="color:#ae81ff">2.5</span> <span style="color:#ae81ff">3.5</span> <span style="color:#ae81ff">3.</span>  <span style="color:#ae81ff">2.7</span>]
[<span style="color:#ae81ff">1</span> <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">0</span> <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">1</span>]
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">l_length <span style="color:#f92672">=</span> length[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">100</span>] <span style="color:#75715e">#学習データ</span>
l_width <span style="color:#f92672">=</span> width[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">100</span>]
l_target <span style="color:#f92672">=</span> target[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">100</span>]
t_length <span style="color:#f92672">=</span> length[<span style="color:#ae81ff">100</span>:<span style="color:#ae81ff">150</span>] <span style="color:#75715e">#テストデータ</span>
t_width <span style="color:#f92672">=</span> width[<span style="color:#ae81ff">100</span>:<span style="color:#ae81ff">150</span>]
t_target <span style="color:#f92672">=</span> target[<span style="color:#ae81ff">100</span>:<span style="color:#ae81ff">150</span>]
</code></pre></div><p>それでは，100の学習データと，1つのテストデータを散布図にプロットしてみます．
図中の赤いサンプルがテストデータです．
このテストデータが，どのカテゴリ（setosa，versicolor，virginica）に分類されるかを考えます．</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">setosa <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(l_target <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)
versicolor <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(l_target <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>)
virginica <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>where(l_target <span style="color:#f92672">==</span> <span style="color:#ae81ff">2</span>)
plt<span style="color:#f92672">.</span>scatter(l_length[setosa], l_width[setosa], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;setosa&#34;</span>)
plt<span style="color:#f92672">.</span>scatter(l_length[versicolor], l_width[versicolor], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;versicolor&#34;</span>)
plt<span style="color:#f92672">.</span>scatter(l_length[virginica], l_width[virginica], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;virginica&#34;</span>)
plt<span style="color:#f92672">.</span>scatter(t_length[<span style="color:#ae81ff">0</span>], t_width[<span style="color:#ae81ff">0</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;test&#34;</span>) <span style="color:#75715e">#テスト用のデータ</span>
plt<span style="color:#f92672">.</span>legend()
</code></pre></div><p><a href="https://gyazo.com/7b3248f8124ac284984f67b843470caf"><img src="https://i.gyazo.com/7b3248f8124ac284984f67b843470caf.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  k近傍法
</h1>

<p>今回取り上げる手法は <strong>k近傍法（k-Nearest Neighbor: k-NN）</strong> です．
これまでに解説した，<strong>線形判別分析（LDA）</strong> や <strong>ロジスティック回帰</strong> に比べると，
とっても単純な仕組みで動作しますが，サンプル数が十分にあれば，高い精度を得られるとされています．
また，ロジスティック回帰など，$w_1 \cdot x + w_0$といった特定の関数（分布）に従うことを前提に，
最適なパラメータを導出する手法は <strong>パラメトリック</strong> な手法と呼ばれるのに対し，
k近傍法は，特定の関数（分布）の前提を持たないことから <strong>ノンパラメトリック</strong> な手法と呼ばれます．
加えて，パラメータの導出など事前の計算が不要なことから <strong>怠惰学習</strong> とも呼ばれます（なんだか不名誉な印象ですね）．</p>
<p>それでは，k近傍法の仕組みを見ていきましょう．
まずは，分類対象であるテスト用のサンプルから，距離的に近いサンプルを$k$個抽出します．
距離は様々に定義することが出来ますが，ここでは <strong>ユークリッド距離</strong> を採用します．
ユークリッド距離はnumpyの <strong>norm</strong> 関数で求めることができます．
<strong>map</strong> 関数を利用して「テスト用のサンプル」と「他の全てのサンプル」の間の距離を計算しています．</p>
<p><strong>[In:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">v <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>c_[l_length <span style="color:#f92672">-</span> t_length[<span style="color:#ae81ff">0</span>], l_width <span style="color:#f92672">-</span> t_width[<span style="color:#ae81ff">0</span>]] <span style="color:#75715e">#ベクトルで表現</span>
d <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(list(map(<span style="color:#66d9ef">lambda</span> x: np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(x), v))) <span style="color:#75715e">#ユークリッド距離の計算</span>
<span style="color:#66d9ef">print</span>(v[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>])
<span style="color:#66d9ef">print</span>(d[<span style="color:#ae81ff">0</span>:<span style="color:#ae81ff">5</span>])
</code></pre></div><p><strong>[Out:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">[[ <span style="color:#ae81ff">0.1</span>  <span style="color:#ae81ff">0.</span> ]
 [<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>  <span style="color:#ae81ff">0.</span> ]
 [ <span style="color:#ae81ff">0.1</span>  <span style="color:#ae81ff">0.1</span>]
 [<span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>  <span style="color:#ae81ff">0.1</span>]
 [<span style="color:#f92672">-</span><span style="color:#ae81ff">0.2</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">0.1</span>]]
[<span style="color:#ae81ff">0.1</span>        <span style="color:#ae81ff">0.1</span>        <span style="color:#ae81ff">0.14142136</span> <span style="color:#ae81ff">0.14142136</span> <span style="color:#ae81ff">0.2236068</span> ]
</code></pre></div><p>次に，求めた距離を基準として，学習データを昇順でソートします．
この結果，ソートされたリストの <strong>[0:k]</strong> が，距離が近い$k$個のサンプルとなります．
ここでは，$K=5$とした結果，そのラベルは$2,1,2,1,1$となったことが分かります（$1$はversicolor，$2$はvirginica）．</p>
<p><strong>[In:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">z <span style="color:#f92672">=</span> list(zip(d, l_length, l_width, l_target)) <span style="color:#75715e">#要素を一つのリストにまとめる</span>
z<span style="color:#f92672">.</span>sort() <span style="color:#75715e">#昇順でソート</span>
d,l_length,l_width,l_target <span style="color:#f92672">=</span> zip(<span style="color:#f92672">*</span>z) <span style="color:#75715e">#要素を分割する</span>
d <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(d)
l_length <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(l_length)
l_width <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(l_width)
l_target <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(l_target)
k <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
<span style="color:#66d9ef">print</span>(d[<span style="color:#ae81ff">0</span>:k])
<span style="color:#66d9ef">print</span>(l_target[<span style="color:#ae81ff">0</span>:k])
</code></pre></div><p><strong>[Out:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">[<span style="color:#ae81ff">0.1</span>        <span style="color:#ae81ff">0.1</span>        <span style="color:#ae81ff">0.14142136</span> <span style="color:#ae81ff">0.14142136</span> <span style="color:#ae81ff">0.2236068</span> ]
[<span style="color:#ae81ff">2</span> <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">2</span> <span style="color:#ae81ff">1</span> <span style="color:#ae81ff">1</span>]
</code></pre></div><p>この$k=5$個のサンプルで，ラベルの多数決（最頻値）を行います．
このケースでは，多数決の結果， <strong>1(Versicolor)</strong> が最も多く，3個の出現頻度であったことがわかります．
よって，このテスト用のサンプルを <strong>1(Versicolor)</strong> に分類します．
このようにk近傍法では，事前に学習は不要であり，多数決という単純な仕組みで結果を得ます．</p>
<p><strong>[In:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#f92672">import</span> scipy.stats <span style="color:#f92672">as</span> stats
value,number <span style="color:#f92672">=</span> stats<span style="color:#f92672">.</span>mode(l_target[<span style="color:#ae81ff">0</span>:k]) <span style="color:#75715e">#最頻値</span>
<span style="color:#66d9ef">print</span>(value)
<span style="color:#66d9ef">print</span>(number)
</code></pre></div><p><strong>[Out:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">[<span style="color:#ae81ff">1</span>] <span style="color:#75715e">#最頻値（Versicolor）</span>
[<span style="color:#ae81ff">3</span>] <span style="color:#75715e">#出現回数</span>
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">k <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
plt<span style="color:#f92672">.</span>scatter(l_length[<span style="color:#ae81ff">0</span>:k], l_width[<span style="color:#ae81ff">0</span>:k], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;learning&#34;</span>)
plt<span style="color:#f92672">.</span>scatter(t_length[<span style="color:#ae81ff">0</span>], t_width[<span style="color:#ae81ff">0</span>], label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;test&#34;</span>)
plt<span style="color:#f92672">.</span>legend()

<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(k):
    plt<span style="color:#f92672">.</span>annotate(l_target[i], (l_length[i], l_width[i]))
</code></pre></div><p><a href="https://gyazo.com/63de60b2197a4974f4f5828e8fd767e1"><img src="https://i.gyazo.com/63de60b2197a4974f4f5828e8fd767e1.png" alt="Image from Gyazo"></a></p>
<h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  分類精度
</h1>

<p>最後に分類精度を確認しておきましょう．
分類精度を評価するための基準も様々に存在しますが，
今回は <strong>正解率（Accuracy）</strong> のみに注目します（この他にも <strong>適合率（Precision）</strong> ，<strong>再現率（Recall）</strong> などがあります）．
正解率は，テストデータのうち，予測結果が正解であった割合です．
ここでは，50個のテストデータのうち，35個が正解，15個が不正解であったため，
正解率は$35/(35 + 15) = 0.7$となります（この値は交差検証のデータに依存します）．</p>
<p><strong>[In:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python">positive <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
negative <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> zip(t_length, t_width, t_target):
    v <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>c_[l_length<span style="color:#f92672">-</span> t[<span style="color:#ae81ff">0</span>], l_width <span style="color:#f92672">-</span> t[<span style="color:#ae81ff">1</span>]]
    d <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(list(map(<span style="color:#66d9ef">lambda</span> x: np<span style="color:#f92672">.</span>linalg<span style="color:#f92672">.</span>norm(x), v)))

    z <span style="color:#f92672">=</span> list(zip(d, l_length, l_width, l_target))
    z<span style="color:#f92672">.</span>sort()
    d,l_length,l_width,l_target <span style="color:#f92672">=</span> zip(<span style="color:#f92672">*</span>z)
    d <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(d)
    l_length <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(l_length)
    l_width <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(l_width)
    l_target <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(l_target)

    k <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
    value,number <span style="color:#f92672">=</span> stats<span style="color:#f92672">.</span>mode(l_target[<span style="color:#ae81ff">0</span>:k]) <span style="color:#75715e">#最頻値</span>

    <span style="color:#66d9ef">if</span> value <span style="color:#f92672">==</span> t[<span style="color:#ae81ff">2</span>]:
        positive <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        negative <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>

<span style="color:#66d9ef">print</span>(positive) <span style="color:#75715e">#正解数</span>
<span style="color:#66d9ef">print</span>(negative) <span style="color:#75715e">#不正解数</span>
<span style="color:#66d9ef">print</span>(positive <span style="color:#f92672">/</span> (positive <span style="color:#f92672">+</span> negative)) <span style="color:#75715e">#正解率</span>
</code></pre></div><p><strong>[Out:]</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-Python" data-lang="Python"><span style="color:#ae81ff">35</span>
<span style="color:#ae81ff">15</span>
<span style="color:#ae81ff">0.7</span>
</code></pre></div><!-- <h1 style="padding-left:40px; line-height: 30px; background: url(http://mukai-lab.info/logo/logo.png) no-repeat">
  課題
</h1>
 -->
<!-- $k$を1〜20まで変化させたときの正解率を調べ，折れ線グラフで示してください（結果は交差検証のデータに依存）． -->
<!-- [![Image from Gyazo](https://i.gyazo.com/69044a62cec25ee9f90477b1afc598a4.png)](https://gyazo.com/69044a62cec25ee9f90477b1afc598a4) -->
<!-- 作成したノートブックを **HTML(.html)** 形式でダウンロードし提出しなさい． -->

<h3>参考書籍</h3>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4274222446&linkId=1a63210b6dc95e90156695289116cb1b&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=B078767Y56&linkId=cd73876214aec3d9b72777ab73920051&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4802611641&linkId=e77970ab2740fac9fdeb8b877668c257&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>

<iframe style="width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&t=naotoassociat-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4839963525&linkId=14f05f671ddd917b204596b6b535981e&bc1=f8f8f8&lt1=_blank&fc1=333333&lc1=0066c0&bg1=f8f8f8&f=ifr">
</iframe>



    

    
    <div id="sns-box" style="display:flex; justify-content:center; align-items: center;">

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-via="nmukai1978" data-hashtags="mlab" data-dnt="true" data-show-count="false"></a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

  <div class="fb-share-button" data-href="https://mukai-lab.info/pages/classes/intelligence_information_system/chapter9/" data-layout="button" data-size="small"><a target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fmukai-lab.info%2F&amp;src=sdkpreparse" class="fb-xfbml-parse-ignore">シェア</a></div>
    
</div>


    <div class="pagination">
      <a href="/"><span>Top</span></a>
      <a href='javascript:history.back()' style="margin-left: 30px"><span>Back</span></a>
    </div>
    
  </div>

  
  <div>

  <div style="margin-top:20px; border-top: solid 10px #007B50; border-bottom: solid 10px #007B50;">
    <p>
      愛知県名古屋市にある椙山女学園大学 文化情報学部 向研究室の公式サイトです．
      専門は情報科学であり，人工知能やデータベースなどの技術要素を指導しています．
      この公式サイトでは，授業で使用している教材を公開すると共に，
      ベールに包まれた女子大教員のミステリアスな日常を４コマ漫画でお伝えしていきます．
      サイトに関するご意見やご質問は<a href="https://www.facebook.com/nmukai1978">Facebook</a>または<a href="https://twitter.com/nmukai1978">Twitter</a>でお問い合わせください．
    </p>
  </div>  

</div>

  
  
  

    
  

  
  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-77390013-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</main>


        <footer>
  <div>
    <span>&copy; 2016 Naoto Mukai All Rights Reserved.</span> 
  </div>
</footer>


    </body>
</html>
